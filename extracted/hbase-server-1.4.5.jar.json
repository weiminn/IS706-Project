{"hbase-server-1.4.5.jar": [["org.apache.hadoop.hbase.backup.FailedArchiveException", "org.apache.hadoop.hbase.backup.FailedArchiveException(java.lang.String, java.util.Collection<org.apache.hadoop.fs.Path>)"], ["java.lang.String", "org.apache.hadoop.hbase.backup.FailedArchiveException.getMessage()"], ["boolean", "org.apache.hadoop.hbase.backup.HFileArchiver$2.accept(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.backup.HFileArchiver$File", "org.apache.hadoop.hbase.backup.HFileArchiver$File(org.apache.hadoop.fs.FileSystem)"], ["boolean", "org.apache.hadoop.hbase.backup.HFileArchiver$File.moveAndClose(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.backup.HFileArchiver$File.getFileSystem()"], ["java.lang.String", "org.apache.hadoop.hbase.backup.HFileArchiver$File.toString()"], ["boolean", "org.apache.hadoop.hbase.client.VersionInfoUtil.currentClientHasMinimumVersion(int, int)"], ["boolean", "org.apache.hadoop.hbase.client.VersionInfoUtil.hasMinimumVersion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$VersionInfo, int, int)"], ["org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination(org.apache.hadoop.hbase.CoordinatedStateManager, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination.checkClosingState(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.coordination.CloseRegionCoordination$CloseRegionDetails)"], ["void", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination.setClosedState(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.coordination.CloseRegionCoordination$CloseRegionDetails)"], ["org.apache.hadoop.hbase.coordination.CloseRegionCoordination$CloseRegionDetails", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination.parseFromProtoRequest(org.apache.hadoop.hbase.protobuf.generated.AdminProtos$CloseRegionRequest)"], ["org.apache.hadoop.hbase.coordination.CloseRegionCoordination$CloseRegionDetails", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination.getDetaultDetails()"], ["org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$GetDataAsyncCallback", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$GetDataAsyncCallback(org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$GetDataAsyncCallback.processResult(int, java.lang.String, java.lang.Object, byte[], org.apache.zookeeper.data.Stat)"], ["org.apache.hadoop.hbase.coprocessor.AggregateImplementation", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation()"], ["void", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation.getMax(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateResponse>)"], ["void", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation.getMin(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateResponse>)"], ["void", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation.getSum(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateResponse>)"], ["void", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation.getRowNum(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateResponse>)"], ["void", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation.getAvg(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateResponse>)"], ["void", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation.getStd(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateResponse>)"], ["void", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation.getMedian(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AggregateProtos$AggregateResponse>)"], ["com.google.protobuf.Service", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation.getService()"], ["void", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.AggregateImplementation.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint", "org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint()"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint.process(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.RowProcessorProtos$ProcessRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.RowProcessorProtos$ProcessResponse>)"], ["com.google.protobuf.Service", "org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint.getService()"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher", "org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher(java.lang.String)"], ["org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher", "org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher()"], ["java.lang.String", "org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.getName()"], ["synchronized", "org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.void receive(org.apache.hadoop.hbase.errorhandling.ForeignException)"], ["synchronized", "org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.void rethrowException()"], ["synchronized", "org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.boolean hasException()"], ["synchronized", "org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.org.apache.hadoop.hbase.errorhandling.ForeignException getException()"], ["synchronized", "org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.void addListener(org.apache.hadoop.hbase.errorhandling.ForeignExceptionListener)"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.executor.EventHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.executor.EventType)"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.executor.EventHandler.prepare()"], ["void", "org.apache.hadoop.hbase.executor.EventHandler.run()"], ["org.apache.hadoop.hbase.executor.EventType", "org.apache.hadoop.hbase.executor.EventHandler.getEventType()"], ["int", "org.apache.hadoop.hbase.executor.EventHandler.getPriority()"], ["long", "org.apache.hadoop.hbase.executor.EventHandler.getSeqid()"], ["int", "org.apache.hadoop.hbase.executor.EventHandler.compareTo(java.lang.Runnable)"], ["synchronized", "org.apache.hadoop.hbase.executor.EventHandler.org.apache.hadoop.hbase.executor.EventHandler$EventHandlerListener getListener()"], ["synchronized", "org.apache.hadoop.hbase.executor.EventHandler.void setListener(org.apache.hadoop.hbase.executor.EventHandler$EventHandlerListener)"], ["java.lang.String", "org.apache.hadoop.hbase.executor.EventHandler.toString()"], ["java.lang.String", "org.apache.hadoop.hbase.executor.EventHandler.getInformativeName()"], ["int", "org.apache.hadoop.hbase.executor.EventHandler.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.executor.ExecutorService", "org.apache.hadoop.hbase.executor.ExecutorService(java.lang.String)"], ["void", "org.apache.hadoop.hbase.executor.ExecutorService.startExecutorService(java.lang.String, int)"], ["void", "org.apache.hadoop.hbase.executor.ExecutorService.shutdown()"], ["java.util.concurrent.ThreadPoolExecutor", "org.apache.hadoop.hbase.executor.ExecutorService.getExecutorThreadPool(org.apache.hadoop.hbase.executor.ExecutorType)"], ["void", "org.apache.hadoop.hbase.executor.ExecutorService.startExecutorService(org.apache.hadoop.hbase.executor.ExecutorType, int)"], ["void", "org.apache.hadoop.hbase.executor.ExecutorService.submit(org.apache.hadoop.hbase.executor.EventHandler)"], ["void", "org.apache.hadoop.hbase.executor.ExecutorService.registerListener(org.apache.hadoop.hbase.executor.EventType, org.apache.hadoop.hbase.executor.EventHandler$EventHandlerListener)"], ["org.apache.hadoop.hbase.executor.EventHandler$EventHandlerListener", "org.apache.hadoop.hbase.executor.ExecutorService.unregisterListener(org.apache.hadoop.hbase.executor.EventType)"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.executor.ExecutorService$ExecutorStatus>", "org.apache.hadoop.hbase.executor.ExecutorService.getAllExecutorStatuses()"], ["org.apache.hadoop.hbase.generated.master.snapshotsStats_jsp", "org.apache.hadoop.hbase.generated.master.snapshotsStats_jsp()"], ["java.lang.Object", "org.apache.hadoop.hbase.generated.master.snapshotsStats_jsp.getDependants()"], ["void", "org.apache.hadoop.hbase.generated.master.snapshotsStats_jsp._jspService(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight$WeightComparator", "org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight$WeightComparator()"], ["int", "org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight$WeightComparator.compare(org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight, org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight)"], ["int", "org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight$WeightComparator.compare(java.lang.Object, java.lang.Object)"], ["java.lang.String", "org.apache.hadoop.hbase.HealthReport.toString()"], ["int", "org.apache.hadoop.hbase.HealthReport.hashCode()"], ["boolean", "org.apache.hadoop.hbase.HealthReport.equals(java.lang.Object)"], ["org.apache.hadoop.hbase.http.ClickjackingPreventionFilter", "org.apache.hadoop.hbase.http.ClickjackingPreventionFilter()"], ["void", "org.apache.hadoop.hbase.http.ClickjackingPreventionFilter.init(javax.servlet.FilterConfig)"], ["void", "org.apache.hadoop.hbase.http.ClickjackingPreventionFilter.doFilter(javax.servlet.ServletRequest, javax.servlet.ServletResponse, javax.servlet.FilterChain)"], ["void", "org.apache.hadoop.hbase.http.ClickjackingPreventionFilter.destroy()"], ["org.apache.hadoop.hbase.http.HttpRequestLog", "org.apache.hadoop.hbase.http.HttpRequestLog()"], ["org.mortbay.jetty.RequestLog", "org.apache.hadoop.hbase.http.HttpRequestLog.getRequestLog(java.lang.String)"], ["org.apache.hadoop.hbase.http.InfoServer", "org.apache.hadoop.hbase.http.InfoServer(java.lang.String, java.lang.String, int, boolean, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.http.InfoServer.addServlet(java.lang.String, java.lang.String, java.lang.Class<? extends javax.servlet.http.HttpServlet>)"], ["void", "org.apache.hadoop.hbase.http.InfoServer.setAttribute(java.lang.String, java.lang.Object)"], ["void", "org.apache.hadoop.hbase.http.InfoServer.start()"], ["int", "org.apache.hadoop.hbase.http.InfoServer.getPort()"], ["void", "org.apache.hadoop.hbase.http.InfoServer.stop()"], ["org.apache.hadoop.hbase.http.NoCacheFilter", "org.apache.hadoop.hbase.http.NoCacheFilter()"], ["void", "org.apache.hadoop.hbase.http.NoCacheFilter.init(javax.servlet.FilterConfig)"], ["void", "org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(javax.servlet.ServletRequest, javax.servlet.ServletResponse, javax.servlet.FilterChain)"], ["void", "org.apache.hadoop.hbase.http.NoCacheFilter.destroy()"], ["org.apache.hadoop.hbase.io.FileLink", "org.apache.hadoop.hbase.io.FileLink(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path...)"], ["org.apache.hadoop.hbase.io.FileLink", "org.apache.hadoop.hbase.io.FileLink(java.util.Collection<org.apache.hadoop.fs.Path>)"], ["org.apache.hadoop.fs.Path[]", "org.apache.hadoop.hbase.io.FileLink.getLocations()"], ["java.lang.String", "org.apache.hadoop.hbase.io.FileLink.toString()"], ["boolean", "org.apache.hadoop.hbase.io.FileLink.exists(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.io.FileLink.getAvailablePath(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.fs.FileStatus", "org.apache.hadoop.hbase.io.FileLink.getFileStatus(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.fs.FSDataInputStream", "org.apache.hadoop.hbase.io.FileLink.open(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.fs.FSDataInputStream", "org.apache.hadoop.hbase.io.FileLink.open(org.apache.hadoop.fs.FileSystem, int)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.io.FileLink.getBackReferencesDir(org.apache.hadoop.fs.Path, java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.io.FileLink.getBackReferenceFileName(org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.io.FileLink.isBackReferencesDir(org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.io.FileLink.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.io.FileLink.hashCode()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.toString()"], ["long", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.length()"], ["org.apache.hadoop.hbase.io.hfile.HFileScanner", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getScanner(boolean, boolean)"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getFirstKey()"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getFirstRowKey()"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getLastRowKey()"], ["long", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getEntries()"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getComparator()"], ["org.apache.hadoop.hbase.io.compress.Compression$Algorithm", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getCompressionAlgorithm()"], ["long", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.indexSize()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getName()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getDataBlockIndexReader()"], ["org.apache.hadoop.hbase.io.hfile.FixedFileTrailer", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getTrailer()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.isPrimaryReplicaReader()"], ["void", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.setPrimaryReplicaReader(boolean)"], ["org.apache.hadoop.hbase.io.hfile.HFile$FileInfo", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.loadFileInfo()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getPath()"], ["org.apache.hadoop.hbase.io.encoding.DataBlockEncoding", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getDataBlockEncoding()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.getConf()"], ["void", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.setConf(org.apache.hadoop.conf.Configuration)"], ["java.util.Map", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.loadFileInfo()"], ["org.apache.hadoop.hbase.io.hfile.BlockWithScanInfo", "org.apache.hadoop.hbase.io.hfile.BlockWithScanInfo(org.apache.hadoop.hbase.io.hfile.HFileBlock, org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock", "org.apache.hadoop.hbase.io.hfile.BlockWithScanInfo.getHFileBlock()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.io.hfile.BlockWithScanInfo.getNextIndexedKey()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$1.compare(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.BlockCacheKey)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$1.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$StatisticsThread", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$StatisticsThread(org.apache.hadoop.hbase.io.hfile.bucket.BucketCache)"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$StatisticsThread.run()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.CachedEntryQueue$1.compare(java.util.Map$Entry<org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry>, java.util.Map$Entry<org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry>)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.CachedEntryQueue$1.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.io.hfile.ChecksumUtil", "org.apache.hadoop.hbase.io.hfile.ChecksumUtil()"], ["void", "org.apache.hadoop.hbase.io.hfile.ChecksumUtil.generateExceptionForChecksumFailureForTest(boolean)"], ["int", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getTrailerSize()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.toString()"], ["org.apache.hadoop.hbase.io.hfile.FixedFileTrailer", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.readFromStream(org.apache.hadoop.fs.FSDataInputStream, long)"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.expectMajorVersion(int)"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.expectMinorVersion(int)"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.expectAtLeastMajorVersion(int)"], ["long", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getFileInfoOffset()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setFileInfoOffset(long)"], ["long", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getLoadOnOpenDataOffset()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setLoadOnOpenOffset(long)"], ["int", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getDataIndexCount()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setDataIndexCount(int)"], ["int", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getMetaIndexCount()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setMetaIndexCount(int)"], ["long", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getTotalUncompressedBytes()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setTotalUncompressedBytes(long)"], ["long", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getEntryCount()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setEntryCount(long)"], ["org.apache.hadoop.hbase.io.compress.Compression$Algorithm", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getCompressionCodec()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setCompressionCodec(org.apache.hadoop.hbase.io.compress.Compression$Algorithm)"], ["int", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getNumDataIndexLevels()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setNumDataIndexLevels(int)"], ["long", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getLastDataBlockOffset()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setLastDataBlockOffset(long)"], ["long", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getFirstDataBlockOffset()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setFirstDataBlockOffset(long)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getComparatorClassName()"], ["int", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getMajorVersion()"], ["int", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getMinorVersion()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setComparatorClass(java.lang.Class<? extends org.apache.hadoop.hbase.KeyValue$KVComparator>)"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.createComparator(java.lang.String)"], ["long", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getUncompressedDataIndexSize()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setUncompressedDataIndexSize(long)"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.getEncryptionKey()"], ["void", "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.setEncryptionKey(byte[])"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.HFileBlock$PrefetchedHeader.toString()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlockIndex", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.getMaxChunkSize(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.getMinIndexNumEntries(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl(org.apache.hadoop.hbase.io.encoding.DataBlockEncoding)"], ["org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoder", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.createFromFileInfo(org.apache.hadoop.hbase.io.hfile.HFile$FileInfo)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.saveMetadata(org.apache.hadoop.hbase.io.hfile.HFile$Writer)"], ["org.apache.hadoop.hbase.io.encoding.DataBlockEncoding", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.getDataBlockEncoding()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.useEncodedScanner(boolean)"], ["org.apache.hadoop.hbase.io.encoding.DataBlockEncoding", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.getEffectiveEncodingInCache(boolean)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.encode(org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext, java.io.DataOutputStream)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.useEncodedScanner()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.toString()"], ["org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.newDataBlockEncodingContext(byte[], org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["org.apache.hadoop.hbase.io.encoding.HFileBlockDecodingContext", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.newDataBlockDecodingContext(org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.startBlockEncoding(org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext, java.io.DataOutputStream)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.endBlockEncoding(org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext, java.io.DataOutputStream, byte[], org.apache.hadoop.hbase.io.hfile.BlockType)"], ["org.apache.hadoop.hbase.io.hfile.HFileReaderV2", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.hfile.FixedFileTrailer, org.apache.hadoop.hbase.io.FSDataInputStreamWrapper, long, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.fs.HFileSystem, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.HFileScanner", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getScanner(boolean, boolean, boolean)"], ["java.nio.ByteBuffer", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getMetaBlock(java.lang.String, boolean)"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(long, long, boolean, boolean, boolean, boolean, org.apache.hadoop.hbase.io.hfile.BlockType, org.apache.hadoop.hbase.io.encoding.DataBlockEncoding)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.hasMVCCInfo()"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getLastKey()"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.midkey()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.close()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.close(boolean)"], ["org.apache.hadoop.hbase.io.encoding.DataBlockEncoding", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getEffectiveEncodingInCache(boolean)"], ["java.io.DataInput", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getGeneralBloomFilterMetadata()"], ["java.io.DataInput", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getDeleteBloomFilterMetadata()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.isFileInfoLoaded()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getMajorVersion()"], ["org.apache.hadoop.hbase.io.hfile.HFileContext", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getFileContext()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2.unbufferStream()"], ["org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread(org.apache.hadoop.hbase.io.hfile.LruBlockCache)"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread.run()"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread.evict()"], ["java.lang.Thread", "org.apache.hadoop.hbase.io.hfile.PrefetchExecutor$1.newThread(java.lang.Runnable)"], ["org.apache.hadoop.hbase.io.WALLink", "org.apache.hadoop.hbase.io.WALLink(org.apache.hadoop.conf.Configuration, java.lang.String, java.lang.String)"], ["org.apache.hadoop.hbase.io.WALLink", "org.apache.hadoop.hbase.io.WALLink(org.apache.hadoop.fs.Path, java.lang.String, java.lang.String)"], ["org.apache.hadoop.hbase.io.WALLink", "org.apache.hadoop.hbase.io.WALLink(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.ipc.EmptyServiceNameException", "org.apache.hadoop.hbase.ipc.EmptyServiceNameException()"], ["org.apache.hadoop.hbase.ipc.MetricsHBaseServer", "org.apache.hadoop.hbase.ipc.MetricsHBaseServer(java.lang.String, org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapper)"], ["void", "org.apache.hadoop.hbase.ipc.MetricsHBaseServer.exception(java.lang.Throwable)"], ["org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource", "org.apache.hadoop.hbase.ipc.MetricsHBaseServer.getMetricsSource()"], ["org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapper", "org.apache.hadoop.hbase.ipc.MetricsHBaseServer.getHBaseServerWrapper()"], ["java.lang.String", "org.apache.hadoop.hbase.ipc.RpcServer$Call.toString()"], ["boolean", "org.apache.hadoop.hbase.ipc.RpcServer$Call.hasPriority()"], ["int", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getPriority()"], ["boolean", "org.apache.hadoop.hbase.ipc.RpcServer$Call.isClientCellBlockSupported()"], ["long", "org.apache.hadoop.hbase.ipc.RpcServer$Call.disconnectSince()"], ["long", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getResponseExceptionSize()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer$Call.incrementResponseExceptionSize(long)"], ["long", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getSize()"], ["long", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getResponseCellSize()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer$Call.incrementResponseCellSize(long)"], ["long", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getResponseBlockSize()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer$Call.incrementResponseBlockSize(long)"], ["long", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getDeadline()"], ["synchronized", "org.apache.hadoop.hbase.ipc.RpcServer$Call.void sendResponseIfReady()"], ["org.apache.hadoop.security.UserGroupInformation", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getRemoteUser()"], ["org.apache.hadoop.hbase.security.User", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getRequestUser()"], ["java.lang.String", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getRequestUserName()"], ["java.net.InetAddress", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getRemoteAddress()"], ["org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$VersionInfo", "org.apache.hadoop.hbase.ipc.RpcServer$Call.getClientVersionInfo()"], ["boolean", "org.apache.hadoop.hbase.ipc.RpcServer$Call.isRetryImmediatelySupported()"], ["org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor(java.lang.String, int, int, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor(java.lang.String, int, int, float, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor(java.lang.String, int, int, float, float, int)"], ["org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor(java.lang.String, int, int, float, float, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor(java.lang.String, int, int, float, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable, java.lang.Class<? extends java.util.concurrent.BlockingQueue>, java.lang.Object...)"], ["org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor(java.lang.String, int, int, float, float, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable, java.lang.Class<? extends java.util.concurrent.BlockingQueue>, java.lang.Object...)"], ["org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor(java.lang.String, int, int, float, float, java.lang.Class<? extends java.util.concurrent.BlockingQueue>, java.lang.Object[], java.lang.Class<? extends java.util.concurrent.BlockingQueue>, java.lang.Object[])"], ["org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor(java.lang.String, int, int, int, int, java.lang.Class<? extends java.util.concurrent.BlockingQueue>, java.lang.Object[], java.lang.Class<? extends java.util.concurrent.BlockingQueue>, java.lang.Object[])"], ["org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor(java.lang.String, int, int, int, int, float, java.lang.Class<? extends java.util.concurrent.BlockingQueue>, java.lang.Object[], java.lang.Class<? extends java.util.concurrent.BlockingQueue>, java.lang.Object[])"], ["boolean", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.dispatch(org.apache.hadoop.hbase.ipc.CallRunner)"], ["int", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.getWriteQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.getReadQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.getScanQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.getActiveHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.getActiveWriteHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.getActiveReadHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.getActiveScanHandlerCount()"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread", "org.apache.hadoop.hbase.LocalHBaseCluster$2.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.LocalHBaseCluster$2.run()"], ["org.apache.hadoop.hbase.mapred.HRegionPartitioner", "org.apache.hadoop.hbase.mapred.HRegionPartitioner()"], ["void", "org.apache.hadoop.hbase.mapred.HRegionPartitioner.configure(org.apache.hadoop.mapred.JobConf)"], ["int", "org.apache.hadoop.hbase.mapred.HRegionPartitioner.getPartition(org.apache.hadoop.hbase.io.ImmutableBytesWritable, V2, int)"], ["int", "org.apache.hadoop.hbase.mapred.HRegionPartitioner.getPartition(java.lang.Object, java.lang.Object, int)"], ["org.apache.hadoop.hbase.mapred.TableInputFormat", "org.apache.hadoop.hbase.mapred.TableInputFormat()"], ["void", "org.apache.hadoop.hbase.mapred.TableInputFormat.configure(org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.TableInputFormat.validateInput(org.apache.hadoop.mapred.JobConf)"], ["org.apache.hadoop.hbase.mapred.TableRecordReaderImpl", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl()"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.restart(byte[])"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.init()"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.setHTable(org.apache.hadoop.hbase.client.Table)"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.setInputColumns(byte[][])"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.setStartRow(byte[])"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.setEndRow(byte[])"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.setRowFilter(org.apache.hadoop.hbase.filter.Filter)"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.close()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.createKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.createValue()"], ["long", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.getPos()"], ["float", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.getProgress()"], ["boolean", "org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.next(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result)"], ["org.apache.hadoop.hbase.mapreduce.CopyTable", "org.apache.hadoop.hbase.mapreduce.CopyTable(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.mapreduce.Job", "org.apache.hadoop.hbase.mapreduce.CopyTable.createSubmittableJob(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.CopyTable.main(java.lang.String[])"], ["int", "org.apache.hadoop.hbase.mapreduce.CopyTable.run(java.lang.String[])"], ["org.apache.hadoop.hbase.mapreduce.HashTable$TableHash", "org.apache.hadoop.hbase.mapreduce.HashTable$TableHash()"], ["org.apache.hadoop.hbase.mapreduce.HashTable$TableHash", "org.apache.hadoop.hbase.mapreduce.HashTable$TableHash.read(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path)"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.HashTable$TableHash.toString()"], ["org.apache.hadoop.hbase.mapreduce.HashTable$TableHash$Reader", "org.apache.hadoop.hbase.mapreduce.HashTable$TableHash.newReader(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.ImmutableBytesWritable)"], ["org.apache.hadoop.hbase.mapreduce.HRegionPartitioner", "org.apache.hadoop.hbase.mapreduce.HRegionPartitioner()"], ["int", "org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.getPartition(org.apache.hadoop.hbase.io.ImmutableBytesWritable, VALUE, int)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.getConf()"], ["void", "org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.setConf(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.getPartition(java.lang.Object, java.lang.Object, int)"], ["org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparablePartitioner", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparablePartitioner()"], ["int", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparablePartitioner.getPartition(org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable, org.apache.hadoop.hbase.KeyValue, int)"], ["int", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparablePartitioner.getPartition(java.lang.Object, java.lang.Object, int)"], ["byte[]", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$1.bulkFamily(byte[])"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$1.bulkHFile(byte[], org.apache.hadoop.fs.FileStatus)"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$1.bulkHFile(java.lang.Object, org.apache.hadoop.fs.FileStatus)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$1.bulkFamily(byte[])"], ["org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$LoadQueueItem", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$LoadQueueItem(byte[], org.apache.hadoop.fs.Path)"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$LoadQueueItem.toString()"], ["org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat", "org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat()"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.checkOutputSpecs(org.apache.hadoop.mapreduce.JobContext)"], ["org.apache.hadoop.mapreduce.OutputCommitter", "org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.getOutputCommitter(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["org.apache.hadoop.mapreduce.RecordWriter<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Mutation>", "org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl", "org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl()"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl.setInput(org.apache.hadoop.conf.Configuration, java.util.Map<java.lang.String, java.util.Collection<org.apache.hadoop.hbase.client.Scan>>, org.apache.hadoop.fs.Path)"], ["java.util.Map<java.lang.String, java.util.Collection<org.apache.hadoop.hbase.client.Scan>>", "org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl.getSnapshotsToScans(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl.setSnapshotToScans(org.apache.hadoop.conf.Configuration, java.util.Map<java.lang.String, java.util.Collection<org.apache.hadoop.hbase.client.Scan>>)"], ["java.util.Map<java.lang.String, org.apache.hadoop.fs.Path>", "org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl.getSnapshotDirs(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl.setSnapshotDirs(org.apache.hadoop.conf.Configuration, java.util.Map<java.lang.String, org.apache.hadoop.fs.Path>)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl.restoreSnapshots(org.apache.hadoop.conf.Configuration, java.util.Map<java.lang.String, org.apache.hadoop.fs.Path>, org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.mapreduce.PutCombiner", "org.apache.hadoop.hbase.mapreduce.PutCombiner()"], ["org.apache.hadoop.hbase.mapreduce.RowCounter", "org.apache.hadoop.hbase.mapreduce.RowCounter()"], ["org.apache.hadoop.mapreduce.Job", "org.apache.hadoop.hbase.mapreduce.RowCounter.createSubmittableJob(org.apache.hadoop.conf.Configuration, java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.RowCounter.main(java.lang.String[])"], ["org.apache.hadoop.hbase.mapreduce.TableInputFormat", "org.apache.hadoop.hbase.mapreduce.TableInputFormat()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.mapreduce.TableInputFormat.getConf()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableInputFormat.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.client.Scan", "org.apache.hadoop.hbase.mapreduce.TableInputFormat.createScanFromConfiguration(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableInputFormat.addColumns(org.apache.hadoop.hbase.client.Scan, byte[][])"], ["void", "org.apache.hadoop.hbase.mapreduce.TableInputFormat.configureSplitTable(org.apache.hadoop.mapreduce.Job, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionRecordReader.initialize(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionRecordReader.nextKeyValue()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionRecordReader.getCurrentKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionRecordReader.getCurrentValue()"], ["float", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionRecordReader.getProgress()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionRecordReader.close()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionRecordReader.getCurrentValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionRecordReader.getCurrentKey()"], ["org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat()"], ["org.apache.hadoop.mapreduce.RecordReader<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.createRecordReader(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.setInput(org.apache.hadoop.mapreduce.Job, java.lang.String, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.setInput(org.apache.hadoop.mapreduce.Job, java.lang.String, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.RegionSplitter$SplitAlgorithm, int)"], ["org.apache.hadoop.hbase.mapreduce.TextSortReducer", "org.apache.hadoop.hbase.mapreduce.TextSortReducer()"], ["long", "org.apache.hadoop.hbase.mapreduce.TextSortReducer.getTs()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TextSortReducer.getSkipBadLines()"], ["org.apache.hadoop.mapreduce.Counter", "org.apache.hadoop.hbase.mapreduce.TextSortReducer.getBadLineCount()"], ["void", "org.apache.hadoop.hbase.mapreduce.TextSortReducer.incrementBadLineCount(int)"], ["org.apache.hadoop.hbase.master.AssignCallable", "org.apache.hadoop.hbase.master.AssignCallable(org.apache.hadoop.hbase.master.AssignmentManager, org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["java.lang.Object", "org.apache.hadoop.hbase.master.AssignCallable.call()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$10.process()"], ["org.apache.hadoop.hbase.master.AssignmentManager", "org.apache.hadoop.hbase.master.AssignmentManager(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.master.ServerManager, org.apache.hadoop.hbase.master.LoadBalancer, org.apache.hadoop.hbase.executor.ExecutorService, org.apache.hadoop.hbase.master.MetricsMaster, org.apache.hadoop.hbase.master.TableLockManager)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.registerListener(org.apache.hadoop.hbase.master.AssignmentListener)"], ["boolean", "org.apache.hadoop.hbase.master.AssignmentManager.unregisterListener(org.apache.hadoop.hbase.master.AssignmentListener)"], ["org.apache.hadoop.hbase.TableStateManager", "org.apache.hadoop.hbase.master.AssignmentManager.getTableStateManager()"], ["org.apache.hadoop.hbase.master.RegionStates", "org.apache.hadoop.hbase.master.AssignmentManager.getRegionStates()"], ["org.apache.hadoop.hbase.master.RegionPlan", "org.apache.hadoop.hbase.master.AssignmentManager.getRegionReopenPlan(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.addPlan(java.lang.String, org.apache.hadoop.hbase.master.RegionPlan)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.addPlans(java.util.Map<java.lang.String, org.apache.hadoop.hbase.master.RegionPlan>)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.setRegionsToReopen(java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["org.apache.hadoop.hbase.util.Pair<java.lang.Integer, java.lang.Integer>", "org.apache.hadoop.hbase.master.AssignmentManager.getReopenStatus(org.apache.hadoop.hbase.TableName)"], ["boolean", "org.apache.hadoop.hbase.master.AssignmentManager.isFailoverCleanupDone()"], ["java.util.concurrent.locks.Lock", "org.apache.hadoop.hbase.master.AssignmentManager.acquireRegionLock(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.removeClosedRegion(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.nodeDataChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.nodeDeleted(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.nodeChildrenChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.regionOffline(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.offlineDisabledRegion(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.assign(org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.assign(org.apache.hadoop.hbase.HRegionInfo, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.assign(org.apache.hadoop.hbase.master.RegionState, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.checkIfShouldMoveSystemRegionAsync()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.unassign(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.unassign(org.apache.hadoop.hbase.HRegionInfo, boolean, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.unassign(org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.deleteClosingOrClosedNode(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName)"], ["int", "org.apache.hadoop.hbase.master.AssignmentManager.getNumRegionsOpened()"], ["boolean", "org.apache.hadoop.hbase.master.AssignmentManager.waitForAssignment(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.assignMeta(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.assign(java.util.Map<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName>)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.assign(java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.updateRegionsInTransitionMetrics()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.waitOnRegionToClearRegionsInTransition(org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.master.AssignmentManager.waitOnRegionToClearRegionsInTransition(org.apache.hadoop.hbase.HRegionInfo, long)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.invokeAssign(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.invokeAssign(org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["org.apache.hadoop.hbase.master.AssignmentManager$ServerHostRegion", "org.apache.hadoop.hbase.master.AssignmentManager.isCarryingMeta(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.master.AssignmentManager$ServerHostRegion", "org.apache.hadoop.hbase.master.AssignmentManager.isCarryingMetaReplica(org.apache.hadoop.hbase.ServerName, int)"], ["org.apache.hadoop.hbase.master.AssignmentManager$ServerHostRegion", "org.apache.hadoop.hbase.master.AssignmentManager.isCarryingMetaReplica(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.balance(org.apache.hadoop.hbase.master.RegionPlan)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.stop()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.shutdown()"], ["java.util.Map<java.lang.String, java.util.concurrent.atomic.AtomicInteger>", "org.apache.hadoop.hbase.master.AssignmentManager.getFailedOpenTracker()"], ["org.apache.hadoop.hbase.master.LoadBalancer", "org.apache.hadoop.hbase.master.AssignmentManager.getBalancer()"], ["java.util.Map<org.apache.hadoop.hbase.ServerName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>>", "org.apache.hadoop.hbase.master.AssignmentManager.getSnapShotOfAssignment(java.util.Collection<org.apache.hadoop.hbase.HRegionInfo>)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.setTestSkipSplitHandling(boolean)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager.setTestSkipMergeHandling(boolean)"], ["int", "org.apache.hadoop.hbase.master.ClusterStatusPublisher$1.compare(java.util.Map$Entry<org.apache.hadoop.hbase.ServerName, java.lang.Integer>, java.util.Map$Entry<org.apache.hadoop.hbase.ServerName, java.lang.Integer>)"], ["int", "org.apache.hadoop.hbase.master.ClusterStatusPublisher$1.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.master.DeadServer", "org.apache.hadoop.hbase.master.DeadServer()"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.boolean cleanPreviousInstance(org.apache.hadoop.hbase.ServerName)"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.boolean isDeadServer(org.apache.hadoop.hbase.ServerName)"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.boolean areDeadServersInProgress()"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.void add(org.apache.hadoop.hbase.ServerName)"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.void notifyServer(org.apache.hadoop.hbase.ServerName)"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.void finish(org.apache.hadoop.hbase.ServerName)"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.int size()"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.boolean isEmpty()"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.void cleanAllPreviousInstances(org.apache.hadoop.hbase.ServerName)"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.java.lang.String toString()"], ["java.util.List<org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.ServerName, java.lang.Long>>", "org.apache.hadoop.hbase.master.DeadServer.copyDeadServersSince(long)"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.java.util.Date getTimeOfDeath(org.apache.hadoop.hbase.ServerName)"], ["synchronized", "org.apache.hadoop.hbase.master.DeadServer.boolean removeDeadServer(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.master.handler.DisableTableHandler", "org.apache.hadoop.hbase.master.handler.DisableTableHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.master.AssignmentManager, org.apache.hadoop.hbase.master.TableLockManager, boolean)"], ["org.apache.hadoop.hbase.master.handler.DisableTableHandler", "org.apache.hadoop.hbase.master.handler.DisableTableHandler.prepare()"], ["java.lang.String", "org.apache.hadoop.hbase.master.handler.DisableTableHandler.toString()"], ["void", "org.apache.hadoop.hbase.master.handler.DisableTableHandler.process()"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.master.handler.DisableTableHandler.prepare()"], ["int", "org.apache.hadoop.hbase.master.HMaster$12.compare(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerName)"], ["int", "org.apache.hadoop.hbase.master.HMaster$12.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMaster", "org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMaster(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.CoordinatedStateManager)"], ["void", "org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMaster.run()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$102.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$109.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$115.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$21.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$28.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$35.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$41.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$42.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$50.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$57.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$75.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$77.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$85.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$92.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.master.MasterCoprocessorHost$CoprocessorOperation", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$CoprocessorOperation()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$CoprocessorOperation.postEnvCall(org.apache.hadoop.hbase.master.MasterCoprocessorHost$MasterEnvironment)"], ["org.apache.hadoop.hbase.master.MasterCoprocessorHost$MasterEnvironment", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$MasterEnvironment(java.lang.Class<?>, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.master.MasterServices)"], ["org.apache.hadoop.hbase.master.MasterServices", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$MasterEnvironment.getMasterServices()"], ["org.apache.hadoop.hbase.metrics.MetricRegistry", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$MasterEnvironment.getMetricRegistryForMaster()"], ["org.apache.hadoop.hbase.master.MetricsAssignmentManager", "org.apache.hadoop.hbase.master.MetricsAssignmentManager()"], ["org.apache.hadoop.hbase.master.MetricsAssignmentManagerSource", "org.apache.hadoop.hbase.master.MetricsAssignmentManager.getMetricsProcSource()"], ["void", "org.apache.hadoop.hbase.master.MetricsAssignmentManager.updateAssignmentTime(long)"], ["void", "org.apache.hadoop.hbase.master.MetricsAssignmentManager.updateBulkAssignTime(long)"], ["void", "org.apache.hadoop.hbase.master.MetricsAssignmentManager.updateRITCount(int)"], ["void", "org.apache.hadoop.hbase.master.MetricsAssignmentManager.updateRITCountOverThreshold(int)"], ["void", "org.apache.hadoop.hbase.master.MetricsAssignmentManager.updateRITOldestAge(long)"], ["void", "org.apache.hadoop.hbase.master.MetricsAssignmentManager.updateRitDuration(long)"], ["org.apache.hadoop.hbase.master.MetricsMaster", "org.apache.hadoop.hbase.master.MetricsMaster(org.apache.hadoop.hbase.master.MetricsMasterWrapper)"], ["org.apache.hadoop.hbase.master.MetricsMasterSource", "org.apache.hadoop.hbase.master.MetricsMaster.getMetricsSource()"], ["org.apache.hadoop.hbase.master.MetricsMasterProcSource", "org.apache.hadoop.hbase.master.MetricsMaster.getMetricsProcSource()"], ["void", "org.apache.hadoop.hbase.master.MetricsMaster.incrementRequests(long)"], ["org.apache.hadoop.hbase.master.normalizer.SplitNormalizationPlan", "org.apache.hadoop.hbase.master.normalizer.SplitNormalizationPlan(org.apache.hadoop.hbase.HRegionInfo, byte[])"], ["org.apache.hadoop.hbase.master.normalizer.NormalizationPlan$PlanType", "org.apache.hadoop.hbase.master.normalizer.SplitNormalizationPlan.getType()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.master.normalizer.SplitNormalizationPlan.getRegionInfo()"], ["void", "org.apache.hadoop.hbase.master.normalizer.SplitNormalizationPlan.setRegionInfo(org.apache.hadoop.hbase.HRegionInfo)"], ["byte[]", "org.apache.hadoop.hbase.master.normalizer.SplitNormalizationPlan.getSplitPoint()"], ["void", "org.apache.hadoop.hbase.master.normalizer.SplitNormalizationPlan.setSplitPoint(byte[])"], ["java.lang.String", "org.apache.hadoop.hbase.master.normalizer.SplitNormalizationPlan.toString()"], ["void", "org.apache.hadoop.hbase.master.normalizer.SplitNormalizationPlan.execute(org.apache.hadoop.hbase.client.Admin)"], ["void", "org.apache.hadoop.hbase.master.OfflineCallback.processResult(int, java.lang.String, java.lang.Object, java.lang.String)"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure$1.run()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.isOnlineSchemaChangeAllowed(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.checkTableModifiable(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.deleteColumnFamilyFromFileSystem(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>, byte[])"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.reOpenAllRegions(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["<T extends java.lang.Comparable<T>> org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$IterableList.prepend(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>, org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>)"], ["<T extends java.lang.Comparable<T>> org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$IterableList.append(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>, org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>)"], ["<T extends java.lang.Comparable<T>> org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$IterableList.appendList(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>, org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue(TKey)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue(TKey, int)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.isSuspended()"], ["synchronized", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.boolean isLocked()"], ["synchronized", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.boolean hasExclusiveLock()"], ["synchronized", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.boolean trySharedLock()"], ["synchronized", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.void releaseSharedLock()"], ["synchronized", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.boolean tryExclusiveLock(long)"], ["synchronized", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.void releaseExclusiveLock()"], ["synchronized", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.boolean isAvailable()"], ["int", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.compareKey(TKey)"], ["int", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.compareTo(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<TKey>)"], ["java.lang.String", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue.toString()"], ["org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure()"], ["org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.HTableDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.deserializeStateData(java.io.InputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.abort(java.lang.Object)"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure$2.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure$2.run()"], ["org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure()"], ["org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, boolean)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["void", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.deserializeStateData(java.io.InputStream)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.abort(java.lang.Object)"], ["java.util.Map<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName>", "org.apache.hadoop.hbase.master.RegionStates.getRegionAssignments()"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.org.apache.hadoop.hbase.ServerName getRegionServerOfRegion(org.apache.hadoop.hbase.HRegionInfo)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.int getRegionsInTransitionCount()"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.boolean isRegionInTransition(org.apache.hadoop.hbase.HRegionInfo)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.boolean isRegionInTransition(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.boolean isRegionsInTransition()"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.boolean isMetaRegionInTransition()"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.boolean isRegionOnline(org.apache.hadoop.hbase.HRegionInfo)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.boolean isRegionOffline(org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.master.RegionStates.isRegionInState(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.master.RegionState$State...)"], ["boolean", "org.apache.hadoop.hbase.master.RegionStates.isRegionInState(java.lang.String, org.apache.hadoop.hbase.master.RegionState$State...)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.void waitForUpdate(long)"], ["org.apache.hadoop.hbase.master.RegionState", "org.apache.hadoop.hbase.master.RegionStates.getRegionTransitionState(org.apache.hadoop.hbase.HRegionInfo)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.org.apache.hadoop.hbase.master.RegionState getRegionTransitionState(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.RegionStates.createRegionStates(java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["org.apache.hadoop.hbase.master.RegionState", "org.apache.hadoop.hbase.master.RegionStates.createRegionState(org.apache.hadoop.hbase.HRegionInfo)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.org.apache.hadoop.hbase.master.RegionState createRegionState(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.master.RegionState$State, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.master.RegionState", "org.apache.hadoop.hbase.master.RegionStates.setRegionStateTOCLOSED(byte[], org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.master.RegionState", "org.apache.hadoop.hbase.master.RegionStates.setRegionStateTOCLOSED(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.master.RegionState", "org.apache.hadoop.hbase.master.RegionStates.updateRegionState(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.master.RegionState$State)"], ["org.apache.hadoop.hbase.master.RegionState", "org.apache.hadoop.hbase.master.RegionStates.updateRegionState(org.apache.hadoop.hbase.RegionTransition, org.apache.hadoop.hbase.master.RegionState$State)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.org.apache.hadoop.hbase.master.RegionState transitionOpenFromPendingOpenOrOpeningOnServer(org.apache.hadoop.hbase.RegionTransition, org.apache.hadoop.hbase.master.RegionState, org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.master.RegionState", "org.apache.hadoop.hbase.master.RegionStates.updateRegionState(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.master.RegionState$State, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.RegionStates.regionOnline(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.RegionStates.regionOnline(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, long)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.void logSplit(org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.RegionStates.logSplit(org.apache.hadoop.hbase.HRegionInfo)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.void clearLastAssignment(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.RegionStates.regionOffline(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.RegionStates.regionOffline(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.master.RegionState$State)"], ["java.util.Map<org.apache.hadoop.hbase.master.RegionState$State, java.util.List<org.apache.hadoop.hbase.HRegionInfo>>", "org.apache.hadoop.hbase.master.RegionStates.getRegionByStateOfTable(org.apache.hadoop.hbase.TableName)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.void waitOnRegionToClearRegionsInTransition(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.RegionStates.tableDeleted(org.apache.hadoop.hbase.TableName)"], ["synchronized", "org.apache.hadoop.hbase.master.RegionStates.void deleteRegion(org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.master.RegionStates.isRegionInRegionStates(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.master.SplitLogManager$ResubmitDirective[]", "org.apache.hadoop.hbase.master.SplitLogManager$ResubmitDirective.values()"], ["org.apache.hadoop.hbase.master.SplitLogManager$ResubmitDirective", "org.apache.hadoop.hbase.master.SplitLogManager$ResubmitDirective.valueOf(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.master.SplitLogManager$Task.toString()"], ["org.apache.hadoop.hbase.master.SplitLogManager$Task", "org.apache.hadoop.hbase.master.SplitLogManager$Task()"], ["boolean", "org.apache.hadoop.hbase.master.SplitLogManager$Task.isOrphan()"], ["boolean", "org.apache.hadoop.hbase.master.SplitLogManager$Task.isUnassigned()"], ["void", "org.apache.hadoop.hbase.master.SplitLogManager$Task.heartbeatNoDetails(long)"], ["void", "org.apache.hadoop.hbase.master.SplitLogManager$Task.heartbeat(long, int, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.SplitLogManager$Task.setUnassigned()"], ["org.apache.hadoop.hbase.master.UnAssignCallable", "org.apache.hadoop.hbase.master.UnAssignCallable(org.apache.hadoop.hbase.master.AssignmentManager, org.apache.hadoop.hbase.HRegionInfo)"], ["java.lang.Object", "org.apache.hadoop.hbase.master.UnAssignCallable.call()"], ["org.apache.hadoop.hbase.migration.NamespaceUpgrade", "org.apache.hadoop.hbase.migration.NamespaceUpgrade()"], ["void", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.init()"], ["void", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.upgradeTableDirs()"], ["void", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.deleteRoot()"], ["void", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.migrateDotDirs()"], ["void", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.makeNamespaceDirs()"], ["void", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.migrateTables()"], ["void", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.migrateSnapshots()"], ["void", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.migrateMeta()"], ["void", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.migrateACL()"], ["boolean", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.verifyNSUpgrade(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["int", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.migration.NamespaceUpgrade.getConf()"], ["void", "org.apache.hadoop.hbase.monitoring.TaskMonitor$MonitorRunnable.run()"], ["org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager", "org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager()"], ["void", "org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager.isStopped()"], ["void", "org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager.initialize(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.master.MetricsMaster)"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager.getProcedureSignature()"], ["void", "org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager.execProcedure(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$ProcedureDescription)"], ["synchronized", "org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager.boolean isProcedureDone(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$ProcedureDescription)"], ["org.apache.hadoop.hbase.procedure.ProcedureManager", "org.apache.hadoop.hbase.procedure.ProcedureManager()"], ["boolean", "org.apache.hadoop.hbase.procedure.ProcedureManager.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.procedure.ProcedureManager.hashCode()"], ["org.apache.hadoop.hbase.procedure.Subprocedure$SubprocedureImpl", "org.apache.hadoop.hbase.procedure.Subprocedure$SubprocedureImpl(org.apache.hadoop.hbase.procedure.ProcedureMember, java.lang.String, org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher, long, long)"], ["void", "org.apache.hadoop.hbase.procedure.Subprocedure$SubprocedureImpl.acquireBarrier()"], ["byte[]", "org.apache.hadoop.hbase.procedure.Subprocedure$SubprocedureImpl.insideBarrier()"], ["void", "org.apache.hadoop.hbase.procedure.Subprocedure$SubprocedureImpl.cleanup(java.lang.Exception)"], ["java.lang.Object", "org.apache.hadoop.hbase.procedure.Subprocedure$SubprocedureImpl.call()"], ["org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil", "org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil()"], ["void", "org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.replicateWALEntry(org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingInterface, org.apache.hadoop.hbase.wal.WAL$Entry[], java.lang.String, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.protobuf.generated.AdminProtos$ReplicateWALEntryRequest, org.apache.hadoop.hbase.CellScanner>", "org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.buildReplicateWALEntryRequest(org.apache.hadoop.hbase.wal.WAL$Entry[])"], ["org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.protobuf.generated.AdminProtos$ReplicateWALEntryRequest, org.apache.hadoop.hbase.CellScanner>", "org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.buildReplicateWALEntryRequest(org.apache.hadoop.hbase.wal.WAL$Entry[], byte[], java.lang.String, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.quotas.QuotaLimiter", "org.apache.hadoop.hbase.quotas.QuotaLimiterFactory.fromThrottle(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Throttle)"], ["org.apache.hadoop.hbase.quotas.QuotaLimiter", "org.apache.hadoop.hbase.quotas.QuotaLimiterFactory.update(org.apache.hadoop.hbase.quotas.QuotaLimiter, org.apache.hadoop.hbase.quotas.QuotaLimiter)"], ["org.apache.hadoop.hbase.quotas.RateLimiter", "org.apache.hadoop.hbase.quotas.RateLimiter()"], ["synchronized", "org.apache.hadoop.hbase.quotas.RateLimiter.void set(long, java.util.concurrent.TimeUnit)"], ["java.lang.String", "org.apache.hadoop.hbase.quotas.RateLimiter.toString()"], ["synchronized", "org.apache.hadoop.hbase.quotas.RateLimiter.void update(org.apache.hadoop.hbase.quotas.RateLimiter)"], ["synchronized", "org.apache.hadoop.hbase.quotas.RateLimiter.boolean isBypass()"], ["synchronized", "org.apache.hadoop.hbase.quotas.RateLimiter.long getLimit()"], ["synchronized", "org.apache.hadoop.hbase.quotas.RateLimiter.long getAvailable()"], ["boolean", "org.apache.hadoop.hbase.quotas.RateLimiter.canExecute()"], ["synchronized", "org.apache.hadoop.hbase.quotas.RateLimiter.boolean canExecute(long)"], ["void", "org.apache.hadoop.hbase.quotas.RateLimiter.consume()"], ["synchronized", "org.apache.hadoop.hbase.quotas.RateLimiter.void consume(long)"], ["long", "org.apache.hadoop.hbase.quotas.RateLimiter.waitInterval()"], ["synchronized", "org.apache.hadoop.hbase.quotas.RateLimiter.long waitInterval(long)"], ["org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction", "org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction(org.apache.hadoop.hbase.regionserver.RSRpcServices)"], ["org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction", "org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction(org.apache.hadoop.hbase.regionserver.RSRpcServices, java.lang.Class<? extends org.apache.hadoop.hbase.regionserver.RSRpcServices>)"], ["int", "org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.getPriority(org.apache.hadoop.hbase.protobuf.generated.RPCProtos$RequestHeader, com.google.protobuf.Message, org.apache.hadoop.hbase.security.User)"], ["long", "org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.getDeadline(org.apache.hadoop.hbase.protobuf.generated.RPCProtos$RequestHeader, com.google.protobuf.Message)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy", "org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.StoreConfigInformation)"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration", "org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy.getConf()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest$2.apply(org.apache.hadoop.hbase.regionserver.StoreFile)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest$2.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactor", "org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactor(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.Store)"], ["org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory$Window", "org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory$Window(org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory, long, long, long)"], ["int", "org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory$Window.compareToTimestamp(long)"], ["org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory$Window", "org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory$Window.nextEarlierWindow()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory$Window.startMillis()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory$Window.endMillis()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionWindow", "org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory$Window.nextEarlierWindow()"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours$1.isOffPeakHour()"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours$1.isOffPeakHour(int)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$BoundaryStripeCompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$BoundaryStripeCompactionRequest(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest, java.util.List<byte[]>)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$BoundaryStripeCompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$BoundaryStripeCompactionRequest(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, java.util.List<byte[]>)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeCompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeCompactionRequest(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeCompactionRequest.setMajorRange(byte[], byte[])"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeCompactionRequest.getRequest()"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeCompactionRequest.setRequest(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionInputFormat.createInputFile(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, java.util.Set<org.apache.hadoop.fs.Path>)"], ["org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner", "org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner(org.apache.hadoop.hbase.regionserver.CompactSplitThread, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.compactions.CompactionContext, java.util.concurrent.ThreadPoolExecutor, org.apache.hadoop.hbase.security.User)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.toString()"], ["void", "org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.run()"], ["int", "org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.compareTo(org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner)"], ["int", "org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.compareTo(java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.regionserver.DateTieredStoreEngine$DateTieredCompactionContext.select(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>, boolean, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.DateTieredStoreEngine$DateTieredCompactionContext.forceSelect(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["boolean", "org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.select(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>, boolean, boolean, boolean)"], ["org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager", "org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager(org.apache.hadoop.hbase.KeyValue$KVComparator, java.util.Comparator<org.apache.hadoop.hbase.regionserver.StoreFile>, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration)"], ["void", "org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.loadFiles(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["void", "org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.insertNewFiles(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["int", "org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.getStorefileCount()"], ["void", "org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.addCompactionResults(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["void", "org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.removeCompactedFiles(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["byte[]", "org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.getSplitPoint()"], ["int", "org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.getStoreCompactionPriority()"], ["double", "org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.getCompactionPressure()"], ["org.apache.hadoop.hbase.regionserver.FlushType[]", "org.apache.hadoop.hbase.regionserver.FlushType.values()"], ["org.apache.hadoop.hbase.regionserver.FlushType", "org.apache.hadoop.hbase.regionserver.FlushType.valueOf(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$1.progress()"], ["org.apache.hadoop.hbase.regionserver.HeapMemoryManager$HeapMemoryTunerChore", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$HeapMemoryTunerChore(org.apache.hadoop.hbase.regionserver.HeapMemoryManager)"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$HeapMemoryTunerChore.flushRequested(org.apache.hadoop.hbase.regionserver.FlushType, org.apache.hadoop.hbase.regionserver.Region)"], ["org.apache.hadoop.hbase.regionserver.HRegion$RowLockImpl", "org.apache.hadoop.hbase.regionserver.HRegion$RowLockImpl(org.apache.hadoop.hbase.regionserver.HRegion$RowLockContext, java.util.concurrent.locks.Lock)"], ["java.util.concurrent.locks.Lock", "org.apache.hadoop.hbase.regionserver.HRegion$RowLockImpl.getLock()"], ["org.apache.hadoop.hbase.regionserver.HRegion$RowLockContext", "org.apache.hadoop.hbase.regionserver.HRegion$RowLockImpl.getContext()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion$RowLockImpl.release()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.HRegion$RowLockImpl.toString()"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.getFileSystem()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.getRegionInfo()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.getRegionInfoForFS()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.getTableDir()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.getRegionDir()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.getStoreDir(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.hasReferences(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.hasReferences(org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.deleteFamily(java.lang.String)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.createTempName()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.createTempName(java.lang.String)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.commitStoreFile(java.lang.String, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.removeStoreFile(java.lang.String, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.removeStoreFiles(java.lang.String, java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.loadRegionInfoFileContent(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.regionserver.HRegionFileSystem", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.createRegionOnFileSystem(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.regionserver.HRegionFileSystem", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.openRegionFromFileSystem(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionFileSystem.deleteRegionFromFileSystem(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.regionserver.StoreFile", "org.apache.hadoop.hbase.regionserver.HStore$1.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.HStore$1.call()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.HStore.getColumnFamilyName()"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.regionserver.HStore.getTableName()"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.regionserver.HStore.getFileSystem()"], ["org.apache.hadoop.hbase.regionserver.HRegionFileSystem", "org.apache.hadoop.hbase.regionserver.HStore.getRegionFileSystem()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getStoreFileTtl()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getMemstoreFlushSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getFlushableSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getSnapshotSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getCompactionCheckMultiplier()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getBlockingFileCount()"], ["int", "org.apache.hadoop.hbase.regionserver.HStore.getBytesPerChecksum(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.util.ChecksumType", "org.apache.hadoop.hbase.regionserver.HStore.getChecksumType(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.regionserver.HStore.getCloseCheckInterval()"], ["org.apache.hadoop.hbase.HColumnDescriptor", "org.apache.hadoop.hbase.regionserver.HStore.getFamily()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getMaxSequenceId()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getMaxMemstoreTS()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HStore.getStoreHomedir(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo, byte[])"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HStore.getStoreHomedir(org.apache.hadoop.fs.Path, java.lang.String, byte[])"], ["org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoder", "org.apache.hadoop.hbase.regionserver.HStore.getDataBlockEncoder()"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.refreshStoreFiles()"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.refreshStoreFiles(java.util.Collection<java.lang.String>)"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.add(org.apache.hadoop.hbase.Cell)"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.add(java.lang.Iterable<org.apache.hadoop.hbase.Cell>)"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.timeOfOldestEdit()"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.rollback(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.assertBulkLoadHFileOk(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path>", "org.apache.hadoop.hbase.regionserver.HStore.preBulkLoadHFile(java.lang.String, long)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HStore.bulkLoadHFile(byte[], java.lang.String, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.bulkLoadHFile(org.apache.hadoop.hbase.regionserver.StoreFileInfo)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Writer", "org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(long, org.apache.hadoop.hbase.io.compress.Compression$Algorithm, boolean, boolean, boolean)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Writer", "org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(long, org.apache.hadoop.hbase.io.compress.Compression$Algorithm, boolean, boolean, boolean, boolean)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Writer", "org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(long, org.apache.hadoop.hbase.io.compress.Compression$Algorithm, boolean, boolean, boolean, boolean, org.apache.hadoop.hbase.regionserver.TimeRangeTracker)"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.addChangedReaderObserver(org.apache.hadoop.hbase.regionserver.ChangedReadersObserver)"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.deleteChangedReaderObserver(org.apache.hadoop.hbase.regionserver.ChangedReadersObserver)"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.replayCompactionMarker(org.apache.hadoop.hbase.protobuf.generated.WALProtos$CompactionDescriptor, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.compactRecentForTestingAssumingDefaultPolicy(int)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HStore.hasReferences()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress", "org.apache.hadoop.hbase.regionserver.HStore.getCompactionProgress()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HStore.isMajorCompaction()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionContext", "org.apache.hadoop.hbase.regionserver.HStore.requestCompaction()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionContext", "org.apache.hadoop.hbase.regionserver.HStore.requestCompaction(int, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionContext", "org.apache.hadoop.hbase.regionserver.HStore.requestCompaction(int, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest, org.apache.hadoop.hbase.security.User)"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.cancelRequestedCompaction(org.apache.hadoop.hbase.regionserver.compactions.CompactionContext)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HStore.isCellTTLExpired(org.apache.hadoop.hbase.Cell, long, long)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(byte[])"], ["boolean", "org.apache.hadoop.hbase.regionserver.HStore.canSplit()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.HStore.getSplitPoint()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getLastCompactSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getSize()"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.triggerMajorCompaction()"], ["org.apache.hadoop.hbase.regionserver.KeyValueScanner", "org.apache.hadoop.hbase.regionserver.HStore.getScanner(org.apache.hadoop.hbase.client.Scan, java.util.NavigableSet<byte[]>, long)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.HStore.toString()"], ["int", "org.apache.hadoop.hbase.regionserver.HStore.getStorefilesCount()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getMaxStoreFileAge()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getMinStoreFileAge()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getAvgStoreFileAge()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getNumReferenceFiles()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getNumHFiles()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getStoreSizeUncompressed()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getStorefilesSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getStorefilesIndexSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getTotalStaticIndexSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getTotalStaticBloomSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getMemStoreSize()"], ["int", "org.apache.hadoop.hbase.regionserver.HStore.getCompactPriority()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HStore.throttleCompaction(long)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HStore.getHRegion()"], ["org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost", "org.apache.hadoop.hbase.regionserver.HStore.getCoprocessorHost()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.HStore.getRegionInfo()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HStore.areWritesEnabled()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getSmallestReadPoint()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.updateColumnValue(byte[], byte[], byte[], long)"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.upsert(java.lang.Iterable<org.apache.hadoop.hbase.Cell>, long, java.util.List<org.apache.hadoop.hbase.Cell>)"], ["org.apache.hadoop.hbase.regionserver.StoreFlushContext", "org.apache.hadoop.hbase.regionserver.HStore.createFlushContext(long)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HStore.needsCompaction()"], ["org.apache.hadoop.hbase.io.hfile.CacheConfig", "org.apache.hadoop.hbase.regionserver.HStore.getCacheConfig()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.heapSize()"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.regionserver.HStore.getComparator()"], ["org.apache.hadoop.hbase.regionserver.ScanInfo", "org.apache.hadoop.hbase.regionserver.HStore.getScanInfo()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HStore.hasTooManyStoreFiles()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getFlushedCellsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getFlushedCellsSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getFlushedOutputFileSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getCompactedCellsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getCompactedCellsSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getMajorCompactedCellsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.HStore.getMajorCompactedCellsSize()"], ["org.apache.hadoop.hbase.regionserver.StoreEngine<?, ?, ?, ?>", "org.apache.hadoop.hbase.regionserver.HStore.getStoreEngine()"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.registerChildren(org.apache.hadoop.hbase.conf.ConfigurationManager)"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.deregisterChildren(org.apache.hadoop.hbase.conf.ConfigurationManager)"], ["double", "org.apache.hadoop.hbase.regionserver.HStore.getCompactionPressure()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HStore.isPrimaryReplicaStore()"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.preSnapshotOperation()"], ["void", "org.apache.hadoop.hbase.regionserver.HStore.postSnapshotOperation()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.HStore.void closeAndArchiveCompactedFiles()"], ["java.util.Collection", "org.apache.hadoop.hbase.regionserver.HStore.close()"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl(org.apache.hadoop.hbase.regionserver.HRegion)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getTableName()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getNamespace()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getRegionName()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getNumStores()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getNumStoreFiles()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getMemstoreSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getStoreFileSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getReadRequestCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getWriteRequestCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getNumFilesCompacted()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getNumBytesCompacted()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getNumCompactionsCompleted()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getLastMajorCompactionAge()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getNumCompactionsFailed()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getNumCompactionsQueued()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getNumFlushesQueued()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getMaxCompactionQueueSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getMaxFlushQueueSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getMaxStoreFileAge()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getMinStoreFileAge()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getAvgStoreFileAge()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getNumReferenceFiles()"], ["int", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getRegionHashCode()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.close()"], ["int", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.getReplicaId()"], ["org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl(org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl.getReadRequestsCount(java.lang.String)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl.getWriteRequestsCount(java.lang.String)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl.getTotalRequestsCount(java.lang.String)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl.getMemstoresSize(java.lang.String)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl.getStoreFilesSize(java.lang.String)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl.getTableSize(java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl.close()"], ["org.apache.hadoop.hbase.regionserver.NoLimitScannerContext", "org.apache.hadoop.hbase.regionserver.NoLimitScannerContext()"], ["org.apache.hadoop.hbase.regionserver.ScannerContext", "org.apache.hadoop.hbase.regionserver.NoLimitScannerContext.getInstance()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.MinorCompactionScanQueryMatcher", "org.apache.hadoop.hbase.regionserver.querymatcher.MinorCompactionScanQueryMatcher(org.apache.hadoop.hbase.regionserver.ScanInfo, org.apache.hadoop.hbase.regionserver.DeleteTracker, long, long, long)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.MinorCompactionScanQueryMatcher.match(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$2.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$27.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$34.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$36.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$43.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$50.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$58.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$65.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$8.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$TableCoprocessorAttribute", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$TableCoprocessorAttribute(org.apache.hadoop.fs.Path, java.lang.String, int, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$TableCoprocessorAttribute.getPath()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$TableCoprocessorAttribute.getClassName()"], ["int", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$TableCoprocessorAttribute.getPriority()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$TableCoprocessorAttribute.getConf()"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$6.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$6.run()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$10.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$5.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["int", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$EnvironmentPriorityComparator.compare(org.apache.hadoop.hbase.CoprocessorEnvironment, org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["int", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$EnvironmentPriorityComparator.compare(java.lang.Object, java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.reseek(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.seek(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.seekToPreviousRow(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.backwardSeek(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.RSRpcServices", "org.apache.hadoop.hbase.regionserver.RSRpcServices(org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["void", "org.apache.hadoop.hbase.regionserver.RSRpcServices.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getHostname(org.apache.hadoop.conf.Configuration, boolean)"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getScanner(long)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getScanDetailsWithId(long)"], ["org.apache.hadoop.hbase.regionserver.Region", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$RegionSpecifier)"], ["org.apache.hadoop.hbase.ipc.PriorityFunction", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getPriority()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getConfiguration()"], ["java.net.InetSocketAddress", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getSocketAddress()"], ["int", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getPriority(org.apache.hadoop.hbase.protobuf.generated.RPCProtos$RequestHeader, com.google.protobuf.Message, org.apache.hadoop.hbase.security.User)"], ["long", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getDeadline(org.apache.hadoop.hbase.protobuf.generated.RPCProtos$RequestHeader, com.google.protobuf.Message)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RSRpcServices.checkOOME(java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RSRpcServices.exitIfOOME(java.lang.Throwable)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$CloseRegionResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.closeRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$CloseRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$CompactRegionResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.compactRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$CompactRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$FlushRegionResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.flushRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$FlushRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$GetOnlineRegionResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getOnlineRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$GetOnlineRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$GetRegionInfoResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegionInfo(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$GetRegionInfoRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$GetServerInfoResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getServerInfo(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$GetServerInfoRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$GetStoreFileResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.getStoreFile(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$GetStoreFileRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$MergeRegionsResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.mergeRegions(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$MergeRegionsRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$OpenRegionResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.openRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$OpenRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$WarmupRegionResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.warmupRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$WarmupRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$ReplicateWALEntryResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.replay(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$ReplicateWALEntryRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$ReplicateWALEntryResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.replicateWALEntry(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$ReplicateWALEntryRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$RollWALWriterResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.rollWALWriter(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$RollWALWriterRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$SplitRegionResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.splitRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$SplitRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$StopServerResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.stopServer(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$StopServerRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$UpdateFavoredNodesResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.updateFavoredNodes(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$UpdateFavoredNodesRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$BulkLoadHFileResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.bulkLoadHFile(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$BulkLoadHFileRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$CoprocessorServiceResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.execService(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$CoprocessorServiceRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.get(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MutateResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MutateRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ScanResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ScanRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$CoprocessorServiceResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.execRegionServerService(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$CoprocessorServiceRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$UpdateConfigurationResponse", "org.apache.hadoop.hbase.regionserver.RSRpcServices.updateConfiguration(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$UpdateConfigurationRequest)"], ["void", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$DaughterOpener.run()"], ["org.apache.hadoop.hbase.regionserver.StoreEngine", "org.apache.hadoop.hbase.regionserver.StoreEngine()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy", "org.apache.hadoop.hbase.regionserver.StoreEngine.getCompactionPolicy()"], ["org.apache.hadoop.hbase.regionserver.compactions.Compactor", "org.apache.hadoop.hbase.regionserver.StoreEngine.getCompactor()"], ["org.apache.hadoop.hbase.regionserver.StoreFileManager", "org.apache.hadoop.hbase.regionserver.StoreEngine.getStoreFileManager()"], ["org.apache.hadoop.hbase.regionserver.StoreFlusher", "org.apache.hadoop.hbase.regionserver.StoreEngine.getStoreFlusher()"], ["org.apache.hadoop.hbase.regionserver.StoreEngine<?, ?, ?, ?>", "org.apache.hadoop.hbase.regionserver.StoreEngine.create(org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["byte[]", "org.apache.hadoop.hbase.regionserver.StoreFile.getFirstKey()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.StoreFile.getLastKey()"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.regionserver.StoreFile.getComparator()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile.getMaxMemstoreTS()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile.setMaxMemstoreTS(long)"], ["org.apache.hadoop.hbase.regionserver.StoreFile", "org.apache.hadoop.hbase.regionserver.StoreFile(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.regionserver.BloomType)"], ["org.apache.hadoop.hbase.regionserver.StoreFile", "org.apache.hadoop.hbase.regionserver.StoreFile(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.regionserver.StoreFileInfo, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.regionserver.BloomType)"], ["org.apache.hadoop.hbase.regionserver.StoreFile", "org.apache.hadoop.hbase.regionserver.StoreFile(org.apache.hadoop.hbase.regionserver.StoreFile)"], ["org.apache.hadoop.hbase.regionserver.StoreFile", "org.apache.hadoop.hbase.regionserver.StoreFile.cloneForReader()"], ["org.apache.hadoop.hbase.regionserver.StoreFileInfo", "org.apache.hadoop.hbase.regionserver.StoreFile.getFileInfo()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.StoreFile.getPath()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.StoreFile.getQualifiedPath()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile.isReference()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile.isHFile()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile.isMajorCompaction()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile.excludeFromMinorCompaction()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile.getMaxSequenceId()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile.getModificationTimeStamp()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.StoreFile.getMetadataValue(byte[])"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile.getMaxMemstoreTSInList(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile.getMaxSequenceIdInList(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile.isBulkLoadResult()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile.isCompactedAway()"], ["int", "org.apache.hadoop.hbase.regionserver.StoreFile.getRefCount()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile.getBulkLoadTimestamp()"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.regionserver.StoreFile.getHDFSBlockDistribution()"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Reader", "org.apache.hadoop.hbase.regionserver.StoreFile.createReader()"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Reader", "org.apache.hadoop.hbase.regionserver.StoreFile.createReader(boolean)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Reader", "org.apache.hadoop.hbase.regionserver.StoreFile.getReader()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.StoreFile.void closeReader(boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile.markCompactedAway()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile.deleteReader()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.StoreFile.toString()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.StoreFile.toStringDetailed()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.StoreFile.getUniqueFile(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["java.lang.Long", "org.apache.hadoop.hbase.regionserver.StoreFile.getMinimumTimestamp()"], ["java.lang.Long", "org.apache.hadoop.hbase.regionserver.StoreFile.getMaximumTimestamp()"], ["org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter$BoundaryMultiWriter", "org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter$BoundaryMultiWriter(org.apache.hadoop.hbase.KeyValue$KVComparator, java.util.List<byte[]>, byte[], byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter$BoundaryMultiWriter.append(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.StripeStoreFileManager$KeyBeforeConcatenatedLists$Iterator", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager$KeyBeforeConcatenatedLists$Iterator(org.apache.hadoop.hbase.regionserver.StripeStoreFileManager$KeyBeforeConcatenatedLists)"], ["void", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager$KeyBeforeConcatenatedLists$Iterator.removeComponents(int)"], ["void", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager$KeyBeforeConcatenatedLists$Iterator.remove()"], ["org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$StripeFlushRequest", "org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$StripeFlushRequest(org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter", "org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$StripeFlushRequest.createWriter()"], ["org.apache.hadoop.hbase.regionserver.throttle.PressureAwareCompactionThroughputController", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareCompactionThroughputController()"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareCompactionThroughputController.setup(org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareCompactionThroughputController.setConf(org.apache.hadoop.conf.Configuration)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareCompactionThroughputController.toString()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$3.run()"], ["org.apache.hadoop.hbase.regionserver.wal.MetricsWALEditsReplay", "org.apache.hadoop.hbase.regionserver.wal.MetricsWALEditsReplay()"], ["org.apache.hadoop.hbase.regionserver.wal.RingBufferTruck", "org.apache.hadoop.hbase.regionserver.wal.RingBufferTruck$1.newInstance()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.wal.RingBufferTruck$1.newInstance()"], ["org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec$EncryptedKvEncoder", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec$EncryptedKvEncoder(java.io.OutputStream)"], ["org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec$EncryptedKvEncoder", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec$EncryptedKvEncoder(java.io.OutputStream, org.apache.hadoop.hbase.io.crypto.Encryptor)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec$EncryptedKvEncoder.write(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$CompressedKvDecoder", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$CompressedKvDecoder(java.io.InputStream, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink", "org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.client.HConnection)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.replayEntries(java.util.List<org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.HRegionLocation, org.apache.hadoop.hbase.wal.WAL$Entry>>)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.getStats()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues$WarnOnlyStoppable.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues$WarnOnlyStoppable.isStopped()"], ["org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint$Replicator", "org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint$Replicator(java.util.List<org.apache.hadoop.hbase.wal.WAL$Entry>, int)"], ["java.lang.Integer", "org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint$Replicator.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint$Replicator.call()"], ["org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RetryingRpcCallable", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RetryingRpcCallable(org.apache.hadoop.hbase.client.RpcRetryingCallerFactory, org.apache.hadoop.hbase.client.RetryingCallable<V>, int)"], ["V", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RetryingRpcCallable.call()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSink", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSink(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Stoppable)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.replicateEntries(java.util.List<org.apache.hadoop.hbase.protobuf.generated.AdminProtos$WALEntry>, org.apache.hadoop.hbase.CellScanner, java.lang.String, java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.stopReplicationSinkServices()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.getStats()"], ["org.apache.hadoop.hbase.replication.regionserver.MetricsSink", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.getSinkMetrics()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$1.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$1.isAborted()"], ["org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext()"], ["org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext.setEntries(java.util.List<org.apache.hadoop.hbase.wal.WAL$Entry>)"], ["org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext.setSize(int)"], ["org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext.setWalGroupId(java.lang.String)"], ["int", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext.getSize()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext.getWalGroupId()"], ["java.lang.Void", "org.apache.hadoop.hbase.security.access.AccessController$9.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$9.run()"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.close()"], ["org.apache.hadoop.hbase.security.access.ZKPermissionWatcher", "org.apache.hadoop.hbase.security.access.TableAuthManager.getZKPermissionWatcher()"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.refreshTableCacheFromWritable(org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.refreshNamespaceCacheFromWritable(java.lang.String, byte[])"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.authorize(org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.authorize(org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.authorize(org.apache.hadoop.hbase.security.User, java.lang.String, org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.authorizeUser(org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.TableName, byte[], org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.authorizeUser(org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.TableName, byte[], byte[], org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.userHasAccess(org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.authorizeGroup(java.lang.String, org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.authorizeGroup(java.lang.String, org.apache.hadoop.hbase.TableName, byte[], byte[], org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.groupHasAccess(java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.authorize(org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.TableName, byte[], byte[], org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.hasAccess(org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.authorize(org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.TableName, byte[], org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.matchPermission(org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.TableName, byte[], org.apache.hadoop.hbase.security.access.Permission$Action)"], ["boolean", "org.apache.hadoop.hbase.security.access.TableAuthManager.matchPermission(org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.TableName, byte[], byte[], org.apache.hadoop.hbase.security.access.Permission$Action)"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.removeNamespace(byte[])"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.removeTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.setTableUserPermissions(java.lang.String, org.apache.hadoop.hbase.TableName, java.util.List<org.apache.hadoop.hbase.security.access.TablePermission>)"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.setTableGroupPermissions(java.lang.String, org.apache.hadoop.hbase.TableName, java.util.List<org.apache.hadoop.hbase.security.access.TablePermission>)"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.setNamespaceUserPermissions(java.lang.String, java.lang.String, java.util.List<org.apache.hadoop.hbase.security.access.TablePermission>)"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.setNamespaceGroupPermissions(java.lang.String, java.lang.String, java.util.List<org.apache.hadoop.hbase.security.access.TablePermission>)"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.writeTableToZooKeeper(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.security.access.TableAuthManager$PermissionCache<org.apache.hadoop.hbase.security.access.TablePermission>)"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager.writeNamespaceToZooKeeper(java.lang.String, org.apache.hadoop.hbase.security.access.TableAuthManager$PermissionCache<org.apache.hadoop.hbase.security.access.TablePermission>)"], ["long", "org.apache.hadoop.hbase.security.access.TableAuthManager.getMTime()"], ["synchronized", "org.apache.hadoop.hbase.security.access.TableAuthManager.org.apache.hadoop.hbase.security.access.TableAuthManager getOrCreate(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.security.access.TableAuthManager.getTotalRefCount()"], ["synchronized", "org.apache.hadoop.hbase.security.access.TableAuthManager.void release(org.apache.hadoop.hbase.security.access.TableAuthManager)"], ["org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager$LeaderElector", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager$LeaderElector(org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager$LeaderElector.isMaster()"], ["boolean", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager$LeaderElector.isStopped()"], ["void", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager$LeaderElector.stop(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager$LeaderElector.run()"], ["org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl()"], ["void", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.getConf()"], ["void", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.init(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)"], ["org.apache.hadoop.hbase.regionserver.OperationStatus[]", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.addLabels(java.util.List<byte[]>)"], ["org.apache.hadoop.hbase.regionserver.OperationStatus[]", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.setAuths(byte[], java.util.List<byte[]>)"], ["org.apache.hadoop.hbase.regionserver.OperationStatus[]", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.clearAuths(byte[], java.util.List<byte[]>)"], ["org.apache.hadoop.hbase.security.visibility.VisibilityExpEvaluator", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.getVisibilityExpEvaluator(org.apache.hadoop.hbase.security.visibility.Authorizations)"], ["boolean", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.havingSystemAuth(byte[])"], ["boolean", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.havingSystemAuth(org.apache.hadoop.hbase.security.User)"], ["boolean", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.matchVisibility(java.util.List<org.apache.hadoop.hbase.Tag>, java.lang.Byte, java.util.List<org.apache.hadoop.hbase.Tag>, java.lang.Byte)"], ["byte[]", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.encodeVisibilityForReplication(java.util.List<org.apache.hadoop.hbase.Tag>, java.lang.Byte)"], ["org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker", "org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker()"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker.add(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.DeleteTracker$DeleteResult", "org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker.isDeleted(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker.reset()"], ["org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotInputSplit", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotInputSplit()"], ["org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotInputSplit", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotInputSplit(java.util.List<org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotFileInfo, java.lang.Long>>)"], ["long", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotInputSplit.getLength()"], ["java.lang.String[]", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotInputSplit.getLocations()"], ["void", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotInputSplit.readFields(java.io.DataInput)"], ["void", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotInputSplit.write(java.io.DataOutput)"], ["org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils$CompletedSnaphotDirectoriesFilter", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils$CompletedSnaphotDirectoriesFilter(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getSnapshotDescription()"], ["boolean", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.isSnapshotCorrupted()"], ["int", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getStoreFilesCount()"], ["int", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getArchivedStoreFilesCount()"], ["int", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getLogsCount()"], ["int", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getMissingStoreFilesCount()"], ["int", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getCorruptedStoreFilesCount()"], ["int", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getMissingLogsCount()"], ["long", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getStoreFilesSize()"], ["long", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getSharedStoreFilesSize()"], ["long", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getArchivedStoreFileSize()"], ["long", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getNonSharedArchivedStoreFilesSize()"], ["float", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getSharedStoreFilePercentage()"], ["long", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats.getLogsSize()"], ["org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$2.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$2.call()"], ["org.apache.hadoop.hbase.SplitLogTask$Owned", "org.apache.hadoop.hbase.SplitLogTask$Owned(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode)"], ["org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmplImpl", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmplImpl(org.jamon.TemplateManager, org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData)"], ["void", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmplImpl.renderNoFlush(java.io.Writer)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl$1.renderTo(java.io.Writer)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$1.renderTo(java.io.Writer)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl$1.renderTo(java.io.Writer)"], ["boolean", "org.apache.hadoop.hbase.tool.Canary$Monitor.isDone()"], ["boolean", "org.apache.hadoop.hbase.tool.Canary$Monitor.hasError()"], ["finalCheckForErrors()", "org.apache.hadoop.hbase.tool.Canary$Monitor."], ["void", "org.apache.hadoop.hbase.tool.Canary$Monitor.close()"], ["java.lang.Void", "org.apache.hadoop.hbase.tool.Canary$RegionTask.call()"], ["java.lang.Void", "org.apache.hadoop.hbase.tool.Canary$RegionTask.read()"], ["java.lang.Object", "org.apache.hadoop.hbase.tool.Canary$RegionTask.call()"], ["org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue$PriorityQueue", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue$PriorityQueue(int, java.util.Comparator<? super E>)"], ["void", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue$PriorityQueue.add(E)"], ["E", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue$PriorityQueue.peek()"], ["E", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue$PriorityQueue.poll()"], ["int", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue$PriorityQueue.size()"], ["java.util.Comparator<? super E>", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue$PriorityQueue.comparator()"], ["boolean", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue$PriorityQueue.contains(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue$PriorityQueue.remainingCapacity()"], ["org.apache.hadoop.hbase.util.CompoundBloomFilterBase", "org.apache.hadoop.hbase.util.CompoundBloomFilterBase()"], ["long", "org.apache.hadoop.hbase.util.CompoundBloomFilterBase.getMaxKeys()"], ["long", "org.apache.hadoop.hbase.util.CompoundBloomFilterBase.getKeyCount()"], ["long", "org.apache.hadoop.hbase.util.CompoundBloomFilterBase.getByteSize()"], ["byte[]", "org.apache.hadoop.hbase.util.CompoundBloomFilterBase.createBloomKey(byte[], int, int, byte[], int, int)"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.util.CompoundBloomFilterBase.getComparator()"], ["org.apache.hadoop.hbase.util.ConfigUtil", "org.apache.hadoop.hbase.util.ConfigUtil()"], ["boolean", "org.apache.hadoop.hbase.util.ConfigUtil.useZKForAssignment(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.util.DirectMemoryUtils", "org.apache.hadoop.hbase.util.DirectMemoryUtils()"], ["long", "org.apache.hadoop.hbase.util.DirectMemoryUtils.getDirectMemorySize()"], ["long", "org.apache.hadoop.hbase.util.DirectMemoryUtils.getDirectMemoryUsage()"], ["void", "org.apache.hadoop.hbase.util.DirectMemoryUtils.destroyDirectByteBuffer(java.nio.ByteBuffer)"], ["int", "org.apache.hadoop.hbase.util.FSTableDescriptors$1.compare(org.apache.hadoop.fs.FileStatus, org.apache.hadoop.fs.FileStatus)"], ["int", "org.apache.hadoop.hbase.util.FSTableDescriptors$1.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.util.FSUtils$DirFilter", "org.apache.hadoop.hbase.util.FSUtils$DirFilter(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.util.FSUtils$UserTableDirFilter", "org.apache.hadoop.hbase.util.FSUtils$UserTableDirFilter(org.apache.hadoop.fs.FileSystem)"], ["java.lang.Void", "org.apache.hadoop.hbase.util.HBaseFsck$2.connect(org.apache.hadoop.hbase.client.HConnection)"], ["java.lang.Object", "org.apache.hadoop.hbase.util.HBaseFsck$2.connect(org.apache.hadoop.hbase.client.HConnection)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.clear()"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.void reportError(org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter$ERROR_CODE, java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.void reportError(org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter$ERROR_CODE, java.lang.String, org.apache.hadoop.hbase.util.HBaseFsck$TableInfo)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.void reportError(org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter$ERROR_CODE, java.lang.String, org.apache.hadoop.hbase.util.HBaseFsck$TableInfo, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.void reportError(org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter$ERROR_CODE, java.lang.String, org.apache.hadoop.hbase.util.HBaseFsck$TableInfo, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.void reportError(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.void report(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.int summarize()"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.void print(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.tableHasErrors(org.apache.hadoop.hbase.util.HBaseFsck$TableInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.resetErrors()"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.void detail(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$PrintingErrorReporter.void progress()"], ["java.lang.Void", "org.apache.hadoop.hbase.util.HBaseFsck$WorkItemOverlapMerge.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.util.HBaseFsck$WorkItemOverlapMerge.call()"], ["org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair", "org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair()"], ["void", "org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.main(java.lang.String[])"], ["org.apache.hadoop.hbase.util.hbck.TableLockChecker", "org.apache.hadoop.hbase.util.hbck.TableLockChecker(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter)"], ["void", "org.apache.hadoop.hbase.util.hbck.TableLockChecker.checkTableLocks()"], ["void", "org.apache.hadoop.hbase.util.hbck.TableLockChecker.fixExpiredTableLocks()"], ["org.apache.hadoop.hbase.util.Merge", "org.apache.hadoop.hbase.util.Merge()"], ["org.apache.hadoop.hbase.util.Merge", "org.apache.hadoop.hbase.util.Merge(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.util.Merge.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.util.Merge.main(java.lang.String[])"], ["int", "org.apache.hadoop.hbase.util.RegionSplitCalculator$1.compare(byte[], byte[])"], ["int", "org.apache.hadoop.hbase.util.RegionSplitCalculator$1.compare(java.lang.Object, java.lang.Object)"], ["byte[]", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.split(byte[], byte[])"], ["byte[][]", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.split(int)"], ["byte[][]", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.split(byte[], byte[], int, boolean)"], ["byte[]", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.firstRow()"], ["byte[]", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.lastRow()"], ["void", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.setFirstRow(java.lang.String)"], ["void", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.setLastRow(java.lang.String)"], ["byte[]", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.strToRow(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.rowToStr(byte[])"], ["java.lang.String", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.separator()"], ["void", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.setFirstRow(byte[])"], ["void", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.setLastRow(byte[])"], ["java.math.BigInteger", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.split2(java.math.BigInteger, java.math.BigInteger)"], ["byte[][]", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.convertToBytes(java.math.BigInteger[])"], ["byte[]", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.convertToByte(java.math.BigInteger, int)"], ["byte[]", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.convertToByte(java.math.BigInteger)"], ["java.math.BigInteger", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.convertToBigInteger(byte[])"], ["java.lang.String", "org.apache.hadoop.hbase.util.RegionSplitter$NumberStringSplit.toString()"], ["void", "org.apache.hadoop.hbase.util.ShutdownHookManager$ShutdownHookManagerV1.addShutdownHook(java.lang.Thread, int)"], ["boolean", "org.apache.hadoop.hbase.util.ShutdownHookManager$ShutdownHookManagerV1.removeShutdownHook(java.lang.Runnable)"], ["org.apache.hadoop.hbase.util.SortedList", "org.apache.hadoop.hbase.util.SortedList(java.util.Comparator<? super E>)"], ["org.apache.hadoop.hbase.util.SortedList", "org.apache.hadoop.hbase.util.SortedList(java.util.Collection<? extends E>, java.util.Comparator<? super E>)"], ["int", "org.apache.hadoop.hbase.util.SortedList.size()"], ["boolean", "org.apache.hadoop.hbase.util.SortedList.isEmpty()"], ["boolean", "org.apache.hadoop.hbase.util.SortedList.contains(java.lang.Object)"], ["java.lang.Object[]", "org.apache.hadoop.hbase.util.SortedList.toArray()"], ["<T> T[]", "org.apache.hadoop.hbase.util.SortedList.toArray(T[])"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.boolean add(E)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.boolean remove(java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.util.SortedList.containsAll(java.util.Collection<?>)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.boolean addAll(java.util.Collection<? extends E>)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.boolean addAll(int, java.util.Collection<? extends E>)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.boolean removeAll(java.util.Collection<?>)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.boolean retainAll(java.util.Collection<?>)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.void clear()"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.E get(int)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.E set(int, E)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.void add(int, E)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedList.E remove(int)"], ["int", "org.apache.hadoop.hbase.util.SortedList.indexOf(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.util.SortedList.lastIndexOf(java.lang.Object)"], ["org.apache.hadoop.hbase.wal.RegionGroupingProvider$Strategies[]", "org.apache.hadoop.hbase.wal.RegionGroupingProvider$Strategies.values()"], ["org.apache.hadoop.hbase.wal.RegionGroupingProvider$Strategies", "org.apache.hadoop.hbase.wal.RegionGroupingProvider$Strategies.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl", "org.apache.hadoop.hbase.wal.WALKey.getMvcc()"], ["org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl$WriteEntry", "org.apache.hadoop.hbase.wal.WALKey.getWriteEntry()"], ["void", "org.apache.hadoop.hbase.wal.WALKey.setWriteEntry(org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl$WriteEntry)"], ["org.apache.hadoop.hbase.wal.WALKey", "org.apache.hadoop.hbase.wal.WALKey()"], ["org.apache.hadoop.hbase.wal.WALKey", "org.apache.hadoop.hbase.wal.WALKey(byte[], org.apache.hadoop.hbase.TableName, long, long, java.util.UUID)"], ["org.apache.hadoop.hbase.wal.WALKey", "org.apache.hadoop.hbase.wal.WALKey(byte[], org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.wal.WALKey", "org.apache.hadoop.hbase.wal.WALKey(byte[], org.apache.hadoop.hbase.TableName, long)"], ["org.apache.hadoop.hbase.wal.WALKey", "org.apache.hadoop.hbase.wal.WALKey(byte[], org.apache.hadoop.hbase.TableName, long, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["org.apache.hadoop.hbase.wal.WALKey", "org.apache.hadoop.hbase.wal.WALKey(byte[], org.apache.hadoop.hbase.TableName, long, long, java.util.List<java.util.UUID>, long, long, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["org.apache.hadoop.hbase.wal.WALKey", "org.apache.hadoop.hbase.wal.WALKey(byte[], org.apache.hadoop.hbase.TableName, long, java.util.List<java.util.UUID>, long, long, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["org.apache.hadoop.hbase.wal.WALKey", "org.apache.hadoop.hbase.wal.WALKey(byte[], org.apache.hadoop.hbase.TableName, long, long, long, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["void", "org.apache.hadoop.hbase.wal.WALKey.setCompressionContext(org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["byte[]", "org.apache.hadoop.hbase.wal.WALKey.getEncodedRegionName()"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.wal.WALKey.getTablename()"], ["long", "org.apache.hadoop.hbase.wal.WALKey.getLogSeqNum()"], ["void", "org.apache.hadoop.hbase.wal.WALKey.setOrigLogSeqNum(long)"], ["long", "org.apache.hadoop.hbase.wal.WALKey.getOrigLogSeqNum()"], ["long", "org.apache.hadoop.hbase.wal.WALKey.getSequenceId()"], ["long", "org.apache.hadoop.hbase.wal.WALKey.getWriteTime()"], ["java.util.NavigableMap<byte[], java.lang.Integer>", "org.apache.hadoop.hbase.wal.WALKey.getScopes()"], ["long", "org.apache.hadoop.hbase.wal.WALKey.getNonceGroup()"], ["long", "org.apache.hadoop.hbase.wal.WALKey.getNonce()"], ["void", "org.apache.hadoop.hbase.wal.WALKey.setScopes(java.util.NavigableMap<byte[], java.lang.Integer>)"], ["void", "org.apache.hadoop.hbase.wal.WALKey.readOlderScopes(java.util.NavigableMap<byte[], java.lang.Integer>)"], ["void", "org.apache.hadoop.hbase.wal.WALKey.addClusterId(java.util.UUID)"], ["java.util.UUID", "org.apache.hadoop.hbase.wal.WALKey.getOriginatingClusterId()"], ["java.lang.String", "org.apache.hadoop.hbase.wal.WALKey.toString()"], ["java.util.Map<java.lang.String, java.lang.Object>", "org.apache.hadoop.hbase.wal.WALKey.toStringMap()"], ["boolean", "org.apache.hadoop.hbase.wal.WALKey.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.wal.WALKey.hashCode()"], ["int", "org.apache.hadoop.hbase.wal.WALKey.compareTo(org.apache.hadoop.hbase.wal.WALKey)"], ["org.apache.hadoop.hbase.protobuf.generated.WALProtos$WALKey$Builder", "org.apache.hadoop.hbase.wal.WALKey.getBuilder(org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$ByteStringCompressor)"], ["void", "org.apache.hadoop.hbase.wal.WALKey.readFieldsFromPb(org.apache.hadoop.hbase.protobuf.generated.WALProtos$WALKey, org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$ByteStringUncompressor)"], ["long", "org.apache.hadoop.hbase.wal.WALKey.estimatedSerializedSizeOf()"], ["int", "org.apache.hadoop.hbase.wal.WALKey.compareTo(java.lang.Object)"], ["java.lang.Void", "org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink$2.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink$2.call()"], ["boolean", "org.apache.hadoop.hbase.wal.WALSplitter.splitLogFile(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FileStatus, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.util.CancelableProgressable, org.apache.hadoop.hbase.regionserver.LastSequenceId, org.apache.hadoop.hbase.CoordinatedStateManager, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode, org.apache.hadoop.hbase.wal.WALFactory)"], ["void", "org.apache.hadoop.hbase.wal.WALSplitter.finishSplitLogFile(java.lang.String, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.wal.WALSplitter.getRegionDirRecoveredEditsDir(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.wal.WALSplitter.moveAsideBadEditsFile(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.wal.WALSplitter.isSequenceIdFile(org.apache.hadoop.fs.Path)"], ["long", "org.apache.hadoop.hbase.wal.WALSplitter.writeRegionSequenceIdFile(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, long, long)"], ["org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServer$HACK_UNTIL_ZOOKEEPER_1897_ZooKeeperMain", "org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServer$HACK_UNTIL_ZOOKEEPER_1897_ZooKeeperMain(java.lang.String[])"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.backup.HFileArchiver$1.apply(org.apache.hadoop.hbase.backup.HFileArchiver$File)"], ["java.lang.Object", "org.apache.hadoop.hbase.backup.HFileArchiver$1.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.backup.HFileArchiver$StoreToFile", "org.apache.hadoop.hbase.backup.HFileArchiver$StoreToFile(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.backup.HFileArchiver$File", "org.apache.hadoop.hbase.backup.HFileArchiver$StoreToFile.apply(org.apache.hadoop.hbase.regionserver.StoreFile)"], ["java.lang.Object", "org.apache.hadoop.hbase.backup.HFileArchiver$StoreToFile.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.client.ClientSideRegionScanner", "org.apache.hadoop.hbase.client.ClientSideRegionScanner(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.client.metrics.ScanMetrics)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.client.ClientSideRegionScanner.next()"], ["void", "org.apache.hadoop.hbase.client.ClientSideRegionScanner.close()"], ["boolean", "org.apache.hadoop.hbase.client.ClientSideRegionScanner.renewLease()"], ["org.apache.hadoop.hbase.CoordinatedStateManagerFactory", "org.apache.hadoop.hbase.CoordinatedStateManagerFactory()"], ["org.apache.hadoop.hbase.CoordinatedStateManager", "org.apache.hadoop.hbase.CoordinatedStateManagerFactory.getCoordinatedStateManager(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination(org.apache.hadoop.hbase.CoordinatedStateManager, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.transitionToOpened(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails)"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.transitionFromOfflineToOpening(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails)"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.tickleOpening(org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.regionserver.RegionServerServices, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.tryTransitionFromOfflineToFailedOpen(org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails)"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.tryTransitionFromOpeningToFailedOpen(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails)"], ["org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.parseFromProtoRequest(org.apache.hadoop.hbase.protobuf.generated.AdminProtos$OpenRegionRequest$RegionOpenInfo)"], ["org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.getDetailsForNonCoordinatedOpening()"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.commitOpenOnMasterSide(org.apache.hadoop.hbase.master.AssignmentManager, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails)"], ["org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination", "org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination(org.apache.hadoop.hbase.CoordinatedStateManager, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination.startSplitTransaction(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination.waitForSplitTransaction(org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.coordination.SplitTransactionCoordination$SplitTransactionDetails)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination.completeSplitTransaction(org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.coordination.SplitTransactionCoordination$SplitTransactionDetails, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination.clean(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.coordination.SplitTransactionCoordination$SplitTransactionDetails", "org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination.getDefaultDetails()"], ["int", "org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination.processTransition(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.coordination.SplitTransactionCoordination$SplitTransactionDetails)"], ["org.apache.hadoop.hbase.errorhandling.TimeoutException", "org.apache.hadoop.hbase.errorhandling.TimeoutException(java.lang.String, long, long, long)"], ["long", "org.apache.hadoop.hbase.errorhandling.TimeoutException.getStart()"], ["long", "org.apache.hadoop.hbase.errorhandling.TimeoutException.getEnd()"], ["long", "org.apache.hadoop.hbase.errorhandling.TimeoutException.getMaxAllowedOperationTime()"], ["java.lang.String", "org.apache.hadoop.hbase.errorhandling.TimeoutException.getSourceName()"], ["org.apache.hadoop.hbase.executor.ExecutorService$TrackingThreadPoolExecutor", "org.apache.hadoop.hbase.executor.ExecutorService$TrackingThreadPoolExecutor(int, int, long, java.util.concurrent.TimeUnit, java.util.concurrent.BlockingQueue<java.lang.Runnable>)"], ["java.util.concurrent.ConcurrentMap<java.lang.Thread, java.lang.Runnable>", "org.apache.hadoop.hbase.executor.ExecutorService$TrackingThreadPoolExecutor.getRunningTasks()"], ["org.apache.hadoop.hbase.fs.HFileSystem", "org.apache.hadoop.hbase.fs.HFileSystem(org.apache.hadoop.conf.Configuration, boolean)"], ["org.apache.hadoop.hbase.fs.HFileSystem", "org.apache.hadoop.hbase.fs.HFileSystem(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.fs.HFileSystem.getNoChecksumFs()"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.fs.HFileSystem.getBackingFs()"], ["boolean", "org.apache.hadoop.hbase.fs.HFileSystem.useHBaseChecksum()"], ["void", "org.apache.hadoop.hbase.fs.HFileSystem.close()"], ["boolean", "org.apache.hadoop.hbase.fs.HFileSystem.addLocationsOrderInterceptor(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.fs.HFileSystem.get(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.fs.HFileSystem.getLocalFs(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.fs.FSDataOutputStream", "org.apache.hadoop.hbase.fs.HFileSystem.createNonRecursive(org.apache.hadoop.fs.Path, boolean, int, short, long, org.apache.hadoop.util.Progressable)"], ["org.apache.hadoop.hbase.generated.master.tablesDetailed_jsp", "org.apache.hadoop.hbase.generated.master.tablesDetailed_jsp()"], ["java.lang.Object", "org.apache.hadoop.hbase.generated.master.tablesDetailed_jsp.getDependants()"], ["void", "org.apache.hadoop.hbase.generated.master.tablesDetailed_jsp._jspService(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.HDFSBlocksDistribution()"], ["synchronized", "org.apache.hadoop.hbase.HDFSBlocksDistribution.java.lang.String toString()"], ["void", "org.apache.hadoop.hbase.HDFSBlocksDistribution.addHostsAndBlockWeight(java.lang.String[], long)"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight>", "org.apache.hadoop.hbase.HDFSBlocksDistribution.getHostAndWeights()"], ["long", "org.apache.hadoop.hbase.HDFSBlocksDistribution.getWeight(java.lang.String)"], ["long", "org.apache.hadoop.hbase.HDFSBlocksDistribution.getUniqueBlocksTotalWeight()"], ["float", "org.apache.hadoop.hbase.HDFSBlocksDistribution.getBlockLocalityIndex(java.lang.String)"], ["void", "org.apache.hadoop.hbase.HDFSBlocksDistribution.add(org.apache.hadoop.hbase.HDFSBlocksDistribution)"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight[]", "org.apache.hadoop.hbase.HDFSBlocksDistribution.getTopHostsWithWeights()"], ["void", "org.apache.hadoop.hbase.HealthChecker.init(java.lang.String, long)"], ["org.apache.hadoop.hbase.HealthReport", "org.apache.hadoop.hbase.HealthChecker.checkHealth()"], ["org.apache.hadoop.hbase.http.HttpConfig$Policy[]", "org.apache.hadoop.hbase.http.HttpConfig$Policy.values()"], ["org.apache.hadoop.hbase.http.HttpConfig$Policy", "org.apache.hadoop.hbase.http.HttpConfig$Policy.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpConfig$Policy", "org.apache.hadoop.hbase.http.HttpConfig$Policy.fromString(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.http.HttpConfig$Policy.isHttpEnabled()"], ["boolean", "org.apache.hadoop.hbase.http.HttpConfig$Policy.isHttpsEnabled()"], ["boolean", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter$RequestQuoter$1.hasMoreElements()"], ["java.lang.String", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter$RequestQuoter$1.nextElement()"], ["java.lang.Object", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter$RequestQuoter$1.nextElement()"], ["org.apache.hadoop.hbase.http.log.LogLevel$Servlet", "org.apache.hadoop.hbase.http.log.LogLevel$Servlet()"], ["void", "org.apache.hadoop.hbase.http.log.LogLevel$Servlet.doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$BlockIndexNotLoadedException", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$BlockIndexNotLoadedException()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.BlockCachesIterator.hasNext()"], ["org.apache.hadoop.hbase.io.hfile.CachedBlock", "org.apache.hadoop.hbase.io.hfile.BlockCachesIterator.next()"], ["void", "org.apache.hadoop.hbase.io.hfile.BlockCachesIterator.remove()"], ["java.lang.Object", "org.apache.hadoop.hbase.io.hfile.BlockCachesIterator.next()"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$BucketSizeInfo", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.roundUpToBucketSizeInfo(int)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.toString()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.getUsedSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.getFreeSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.getTotalSize()"], ["synchronized", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.long allocateBlock(int)"], ["synchronized", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.int freeBlock(long)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.sizeIndexOfAllocation(long)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.sizeOfAllocation(long)"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket[]", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.getBuckets()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.freeBlock(long[])"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.getBucketIndex(long)"], ["org.apache.hadoop.hbase.io.hfile.bucket.UniqueIndexMap", "org.apache.hadoop.hbase.io.hfile.bucket.UniqueIndexMap()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getDataMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getLeafIndexMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getBloomChunkMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getMetaMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getRootIndexMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getIntermediateIndexMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getFileInfoMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getGeneralBloomMetaMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getDeleteFamilyBloomMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getTrailerMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getDataHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getLeafIndexHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getBloomChunkHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getMetaHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getRootIndexHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getIntermediateIndexHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getFileInfoHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getGeneralBloomMetaHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getDeleteFamilyBloomHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getTrailerHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getRequestCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getRequestCachingCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getPrimaryMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getMissCachingCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getPrimaryHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getHitCachingCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getEvictionCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getEvictedCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getPrimaryEvictedCount()"], ["void", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.rollMetricsPeriod()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getFailedInserts()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getSumHitCountsPastNPeriods()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getSumRequestCountsPastNPeriods()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getSumHitCachingCountsPastNPeriods()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache$CombinedCacheStats.getSumRequestCachingCountsPastNPeriods()"], ["org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory", "org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory.withPath(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory", "org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory.withOutputStream(org.apache.hadoop.fs.FSDataOutputStream)"], ["org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory", "org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory.withComparator(org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory", "org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory.withFavoredNodes(java.net.InetSocketAddress[])"], ["org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory", "org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory.withFileContext(org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory", "org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory.withShouldDropCacheBehind(boolean)"], ["org.apache.hadoop.hbase.io.hfile.HFile$Writer", "org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory.create()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock", "org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader$1.nextBlock()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock", "org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader$1.nextBlockWithBlockType(org.apache.hadoop.hbase.io.hfile.BlockType)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexChunk.add(byte[], long, int)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexChunk.clear()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexChunk.getEntryBySubEntry(long)"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexChunk.getMidKeyMetadata()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexChunk.getNumEntries()"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexChunk.getBlockKey(int)"], ["long", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexChunk.getBlockOffset(int)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexChunk.getOnDiskDataSize(int)"], ["long", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexChunk.getCumulativeNumKV(int)"], ["org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2(org.apache.hadoop.hbase.io.hfile.HFileReaderV2, boolean, boolean, boolean)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.getKeyValue()"], ["java.nio.ByteBuffer", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.getKey()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.compareKey(org.apache.hadoop.hbase.KeyValue$KVComparator, byte[], int, int)"], ["java.nio.ByteBuffer", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.getValue()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.next()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.getKeyString()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.getValueString()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.compareKey(org.apache.hadoop.hbase.KeyValue$KVComparator, org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.io.hfile.LruBlockCache$StatisticsThread", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$StatisticsThread(org.apache.hadoop.hbase.io.hfile.LruBlockCache)"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$StatisticsThread.run()"], ["org.apache.hadoop.hbase.io.hfile.PrefetchExecutor", "org.apache.hadoop.hbase.io.hfile.PrefetchExecutor()"], ["void", "org.apache.hadoop.hbase.io.hfile.PrefetchExecutor.request(org.apache.hadoop.fs.Path, java.lang.Runnable)"], ["void", "org.apache.hadoop.hbase.io.hfile.PrefetchExecutor.complete(org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.io.hfile.PrefetchExecutor.cancel(org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.PrefetchExecutor.isCompleted(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor(java.lang.String, int, int, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor(java.lang.String, int, java.lang.String, int, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["boolean", "org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor.dispatch(org.apache.hadoop.hbase.ipc.CallRunner)"], ["org.apache.hadoop.hbase.ipc.RpcExecutor$RandomQueueBalancer", "org.apache.hadoop.hbase.ipc.RpcExecutor$RandomQueueBalancer(int)"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor$RandomQueueBalancer.getNextQueue()"], ["org.apache.hadoop.hbase.ipc.RpcScheduler$Context", "org.apache.hadoop.hbase.ipc.RpcScheduler$Context()"], ["java.lang.Object", "org.apache.hadoop.hbase.ipc.RpcServer$Connection$1.run()"], ["org.apache.hadoop.hbase.ipc.RpcServer", "org.apache.hadoop.hbase.ipc.RpcServer(org.apache.hadoop.hbase.Server, java.lang.String, java.util.List<org.apache.hadoop.hbase.ipc.RpcServer$BlockingServiceAndInterface>, java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.ipc.RpcScheduler)"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer.setSocketSendBufSize(int)"], ["boolean", "org.apache.hadoop.hbase.ipc.RpcServer.isStarted()"], ["synchronized", "org.apache.hadoop.hbase.ipc.RpcServer.void start()"], ["synchronized", "org.apache.hadoop.hbase.ipc.RpcServer.void refreshAuthManager(org.apache.hadoop.security.authorize.PolicyProvider)"], ["org.apache.hadoop.security.token.SecretManager<? extends org.apache.hadoop.security.token.TokenIdentifier>", "org.apache.hadoop.hbase.ipc.RpcServer.getSecretManager()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer.setSecretManager(org.apache.hadoop.security.token.SecretManager<? extends org.apache.hadoop.security.token.TokenIdentifier>)"], ["org.apache.hadoop.hbase.util.Pair<com.google.protobuf.Message, org.apache.hadoop.hbase.CellScanner>", "org.apache.hadoop.hbase.ipc.RpcServer.call(com.google.protobuf.BlockingService, com.google.protobuf.Descriptors$MethodDescriptor, com.google.protobuf.Message, org.apache.hadoop.hbase.CellScanner, long, org.apache.hadoop.hbase.monitoring.MonitoredRPCHandler)"], ["org.apache.hadoop.hbase.util.Pair<com.google.protobuf.Message, org.apache.hadoop.hbase.CellScanner>", "org.apache.hadoop.hbase.ipc.RpcServer.call(com.google.protobuf.BlockingService, com.google.protobuf.Descriptors$MethodDescriptor, com.google.protobuf.Message, org.apache.hadoop.hbase.CellScanner, long, org.apache.hadoop.hbase.monitoring.MonitoredRPCHandler, long, int)"], ["synchronized", "org.apache.hadoop.hbase.ipc.RpcServer.void stop()"], ["synchronized", "org.apache.hadoop.hbase.ipc.RpcServer.void join()"], ["synchronized", "org.apache.hadoop.hbase.ipc.RpcServer.java.net.InetSocketAddress getListenerAddress()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer.setErrorHandler(org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler)"], ["org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler", "org.apache.hadoop.hbase.ipc.RpcServer.getErrorHandler()"], ["org.apache.hadoop.hbase.ipc.MetricsHBaseServer", "org.apache.hadoop.hbase.ipc.RpcServer.getMetrics()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer.addCallSize(long)"], ["synchronized", "org.apache.hadoop.hbase.ipc.RpcServer.void authorize(org.apache.hadoop.security.UserGroupInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos$ConnectionHeader, java.net.InetAddress)"], ["org.apache.hadoop.hbase.ipc.RpcCallContext", "org.apache.hadoop.hbase.ipc.RpcServer.getCurrentCall()"], ["boolean", "org.apache.hadoop.hbase.ipc.RpcServer.isInRpcCallContext()"], ["org.apache.hadoop.hbase.security.User", "org.apache.hadoop.hbase.ipc.RpcServer.getRequestUser()"], ["java.lang.String", "org.apache.hadoop.hbase.ipc.RpcServer.getRequestUserName()"], ["java.net.InetAddress", "org.apache.hadoop.hbase.ipc.RpcServer.getRemoteAddress()"], ["java.net.InetAddress", "org.apache.hadoop.hbase.ipc.RpcServer.getRemoteIp()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer.bind(java.net.ServerSocket, java.net.InetSocketAddress, int)"], ["org.apache.hadoop.hbase.ipc.RpcScheduler", "org.apache.hadoop.hbase.ipc.RpcServer.getScheduler()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer.setRsRpcServices(org.apache.hadoop.hbase.regionserver.RSRpcServices)"], ["void", "org.apache.hadoop.hbase.mapred.RowCounter$RowCounterMapper.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapred.OutputCollector<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>, org.apache.hadoop.mapred.Reporter)"], ["void", "org.apache.hadoop.hbase.mapred.RowCounter$RowCounterMapper.configure(org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.RowCounter$RowCounterMapper.close()"], ["void", "org.apache.hadoop.hbase.mapred.RowCounter$RowCounterMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapred.OutputCollector, org.apache.hadoop.mapred.Reporter)"], ["void", "org.apache.hadoop.hbase.mapreduce.CellCounter$IntSumReducer.reduce(Key, java.lang.Iterable<org.apache.hadoop.io.IntWritable>, org.apache.hadoop.mapreduce.Reducer<Key, org.apache.hadoop.io.IntWritable, Key, org.apache.hadoop.io.IntWritable>.Context)"], ["org.apache.hadoop.hbase.mapreduce.GroupingTableMapper", "org.apache.hadoop.hbase.mapreduce.GroupingTableMapper()"], ["void", "org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.initJob(java.lang.String, org.apache.hadoop.hbase.client.Scan, java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>.Context)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.getConf()"], ["void", "org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.setConf(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["org.apache.hadoop.hbase.mapreduce.Import$KeyValueReducer", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueReducer()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getRowKeyOffset()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getRowKeyLength()"], ["long", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getTimestamp(long)"], ["java.lang.String[]", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getIndividualAttributes()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getAttributeKeyOffset()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getAttributeKeyLength()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getCellVisibilityColumnOffset()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getCellVisibilityColumnLength()"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getCellVisibility()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getCellTTLColumnOffset()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getCellTTLColumnLength()"], ["long", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getCellTTL()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getColumnOffset(int)"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getColumnLength(int)"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getColumnCount()"], ["byte[]", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine.getLineBytes()"], ["org.apache.hadoop.hbase.mapreduce.KeyValueSortReducer", "org.apache.hadoop.hbase.mapreduce.KeyValueSortReducer()"], ["org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.setDepth(int)"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.doBulkLoad(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.client.HTable)"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.doBulkLoad(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.client.Admin, org.apache.hadoop.hbase.client.Table, org.apache.hadoop.hbase.client.RegionLocator)"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.prepareHFileQueue(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.client.Table, java.util.Deque<org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$LoadQueueItem>, boolean)"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.loadHFileQueue(org.apache.hadoop.hbase.client.Table, org.apache.hadoop.hbase.client.Connection, java.util.Deque<org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$LoadQueueItem>, org.apache.hadoop.hbase.util.Pair<byte[][], byte[][]>)"], ["byte[][]", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.inferBoundaries(java.util.TreeMap<byte[], java.lang.Integer>)"], ["int", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.main(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.setBulkToken(java.lang.String)"], ["org.apache.hadoop.hbase.mapreduce.ResultSerialization", "org.apache.hadoop.hbase.mapreduce.ResultSerialization()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.ResultSerialization.accept(java.lang.Class<?>)"], ["org.apache.hadoop.hbase.mapreduce.SyncTable$SyncMapper", "org.apache.hadoop.hbase.mapreduce.SyncTable$SyncMapper()"], ["org.apache.hadoop.hbase.mapreduce.TableOutputCommitter", "org.apache.hadoop.hbase.mapreduce.TableOutputCommitter()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.abortTask(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.cleanupJob(org.apache.hadoop.mapreduce.JobContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.setupJob(org.apache.hadoop.mapreduce.JobContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.setupTask(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.isRecoverySupported()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.recoverTask(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["org.apache.hadoop.hbase.mapreduce.TableReducer", "org.apache.hadoop.hbase.mapreduce.TableReducer()"], ["org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionSplit", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionSplit()"], ["org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionSplit", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionSplit(org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit)"], ["org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionSplit", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionSplit(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, java.util.List<java.lang.String>, org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.fs.Path)"], ["long", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionSplit.getLength()"], ["java.lang.String[]", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionSplit.getLocations()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionSplit.write(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionSplit.readFields(java.io.DataInput)"], ["org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader()"], ["org.apache.hadoop.hbase.client.ClientSideRegionScanner", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader.getScanner()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader.initialize(org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit, org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader.nextKeyValue()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader.getCurrentKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader.getCurrentValue()"], ["long", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader.getPos()"], ["float", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader.getProgress()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader.close()"], ["org.apache.hadoop.hbase.mapreduce.TsvImporterMapper", "org.apache.hadoop.hbase.mapreduce.TsvImporterMapper()"], ["long", "org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.getTs()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.getSkipBadLines()"], ["org.apache.hadoop.mapreduce.Counter", "org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.getBadLineCount()"], ["void", "org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.incrementBadLineCount(int)"], ["void", "org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.map(org.apache.hadoop.io.LongWritable, org.apache.hadoop.io.Text, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.io.LongWritable, org.apache.hadoop.io.Text, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Put>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["org.apache.hadoop.hbase.mapreduce.WALPlayer", "org.apache.hadoop.hbase.mapreduce.WALPlayer(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.mapreduce.Job", "org.apache.hadoop.hbase.mapreduce.WALPlayer.createSubmittableJob(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.WALPlayer.main(java.lang.String[])"], ["int", "org.apache.hadoop.hbase.mapreduce.WALPlayer.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$2.process()"], ["java.lang.String", "org.apache.hadoop.hbase.master.AssignmentManager$5.getRegionName()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$5.run()"], ["int", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$1.compare(java.lang.Integer, java.lang.Integer)"], ["int", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$1.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action(org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action$Type)"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action.undoAction()"], ["java.lang.String", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action.toString()"], ["boolean", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.serverHasTooFewRegions(int)"], ["float[][]", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.getOrComputeRackLocalities()"], ["int[]", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.getOrComputeRegionsToMostLocalEntities(org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$LocalityType)"], ["float", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.getOrComputeLocality(int, int, org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$LocalityType)"], ["double", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.getOrComputeWeightedLocality(int, int, org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$LocalityType)"], ["int", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.getRegionSizeMB(int)"], ["int", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.getRackForRegion(int)"], ["void", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.doAction(org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action)"], ["java.lang.String", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.toString()"], ["org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer$RegionReplicaRackCostFunction", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer$RegionReplicaRackCostFunction(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer()"], ["void", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["synchronized", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.void setConf(org.apache.hadoop.conf.Configuration)"], ["synchronized", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.void setClusterStatus(org.apache.hadoop.hbase.ClusterStatus)"], ["void", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.updateMetricsSize(int)"], ["synchronized", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.void setMasterServices(org.apache.hadoop.hbase.master.MasterServices)"], ["java.lang.String[]", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.getCostFunctionNames()"], ["java.lang.String", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.composeAttributeName(java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.cleaner.CleanerChore.initChorePool(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.master.cleaner.CleanerChore", "org.apache.hadoop.hbase.master.cleaner.CleanerChore(java.lang.String, int, org.apache.hadoop.hbase.Stoppable, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.cleaner.CleanerChore.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.master.cleaner.CleanerChore.runCleaner()"], ["synchronized", "org.apache.hadoop.hbase.master.cleaner.CleanerChore.void cleanup()"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.CleanerChore.setEnabled(boolean)"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.CleanerChore.getEnabled()"], ["T", "org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher$HBaseDatagramChannelFactory.newChannel()"], ["java.lang.String", "org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher$HBaseDatagramChannelFactory.toString()"], ["void", "org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler$1.run()"], ["org.apache.hadoop.hbase.master.handler.TableEventHandler", "org.apache.hadoop.hbase.master.handler.TableEventHandler(org.apache.hadoop.hbase.executor.EventType, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.master.MasterServices)"], ["org.apache.hadoop.hbase.master.handler.TableEventHandler", "org.apache.hadoop.hbase.master.handler.TableEventHandler.prepare()"], ["void", "org.apache.hadoop.hbase.master.handler.TableEventHandler.process()"], ["boolean", "org.apache.hadoop.hbase.master.handler.TableEventHandler.reOpenAllRegions(java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.master.handler.TableEventHandler.getTableDescriptor()"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.master.handler.TableEventHandler.prepare()"], ["org.apache.hadoop.hbase.master.HMaster", "org.apache.hadoop.hbase.master.HMaster(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.CoordinatedStateManager)"], ["org.apache.hadoop.hbase.master.MasterRpcServices", "org.apache.hadoop.hbase.master.HMaster.getMasterRpcServices()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.balanceSwitch(boolean)"], ["org.apache.hadoop.hbase.TableDescriptors", "org.apache.hadoop.hbase.master.HMaster.getTableDescriptors()"], ["org.apache.hadoop.hbase.master.ServerManager", "org.apache.hadoop.hbase.master.HMaster.getServerManager()"], ["org.apache.hadoop.hbase.master.MasterFileSystem", "org.apache.hadoop.hbase.master.HMaster.getMasterFileSystem()"], ["org.apache.hadoop.hbase.master.TableNamespaceManager", "org.apache.hadoop.hbase.master.HMaster.getTableNamespaceManager()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.balance()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.balance(boolean)"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.normalizeRegions()"], ["void", "org.apache.hadoop.hbase.master.HMaster.setCatalogJanitorEnabled(boolean)"], ["void", "org.apache.hadoop.hbase.master.HMaster.dispatchMergingRegions(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, boolean, org.apache.hadoop.hbase.security.User)"], ["void", "org.apache.hadoop.hbase.master.HMaster.move(byte[], byte[])"], ["long", "org.apache.hadoop.hbase.master.HMaster.createTable(org.apache.hadoop.hbase.HTableDescriptor, byte[][], long, long)"], ["long", "org.apache.hadoop.hbase.master.HMaster.createSystemTable(org.apache.hadoop.hbase.HTableDescriptor)"], ["long", "org.apache.hadoop.hbase.master.HMaster.deleteTable(org.apache.hadoop.hbase.TableName, long, long)"], ["void", "org.apache.hadoop.hbase.master.HMaster.truncateTable(org.apache.hadoop.hbase.TableName, boolean, long, long)"], ["void", "org.apache.hadoop.hbase.master.HMaster.addColumn(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor, long, long)"], ["void", "org.apache.hadoop.hbase.master.HMaster.modifyColumn(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor, long, long)"], ["void", "org.apache.hadoop.hbase.master.HMaster.deleteColumn(org.apache.hadoop.hbase.TableName, byte[], long, long)"], ["long", "org.apache.hadoop.hbase.master.HMaster.enableTable(org.apache.hadoop.hbase.TableName, long, long)"], ["long", "org.apache.hadoop.hbase.master.HMaster.disableTable(org.apache.hadoop.hbase.TableName, long, long)"], ["void", "org.apache.hadoop.hbase.master.HMaster.modifyTable(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor, long, long)"], ["void", "org.apache.hadoop.hbase.master.HMaster.checkTableModifiable(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.ClusterStatus", "org.apache.hadoop.hbase.master.HMaster.getClusterStatus()"], ["org.apache.hadoop.hbase.ClusterStatus", "org.apache.hadoop.hbase.master.HMaster.getClusterStatusWithoutCoprocessor()"], ["java.lang.String", "org.apache.hadoop.hbase.master.HMaster.getLoadedCoprocessors()"], ["long", "org.apache.hadoop.hbase.master.HMaster.getMasterStartTime()"], ["long", "org.apache.hadoop.hbase.master.HMaster.getMasterActiveTime()"], ["long", "org.apache.hadoop.hbase.master.HMaster.getMasterFinishedInitializationTime()"], ["int", "org.apache.hadoop.hbase.master.HMaster.getNumWALFiles()"], ["org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore", "org.apache.hadoop.hbase.master.HMaster.getWalProcedureStore()"], ["int", "org.apache.hadoop.hbase.master.HMaster.getRegionServerInfoPort(org.apache.hadoop.hbase.ServerName)"], ["java.lang.String", "org.apache.hadoop.hbase.master.HMaster.getRegionServerVersion(org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.HMaster.checkIfShouldMoveSystemRegionAsync()"], ["java.lang.String[]", "org.apache.hadoop.hbase.master.HMaster.getMasterCoprocessors()"], ["void", "org.apache.hadoop.hbase.master.HMaster.abort(java.lang.String, java.lang.Throwable)"], ["org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher", "org.apache.hadoop.hbase.master.HMaster.getZooKeeper()"], ["org.apache.hadoop.hbase.master.MasterCoprocessorHost", "org.apache.hadoop.hbase.master.HMaster.getMasterCoprocessorHost()"], ["org.apache.hadoop.hbase.quotas.MasterQuotaManager", "org.apache.hadoop.hbase.master.HMaster.getMasterQuotaManager()"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.master.HMaster.getServerName()"], ["org.apache.hadoop.hbase.master.AssignmentManager", "org.apache.hadoop.hbase.master.HMaster.getAssignmentManager()"], ["org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer", "org.apache.hadoop.hbase.master.HMaster.getRegionServerFatalLogBuffer()"], ["void", "org.apache.hadoop.hbase.master.HMaster.shutdown()"], ["void", "org.apache.hadoop.hbase.master.HMaster.stopMaster()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.isActiveMaster()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.isInitialized()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.isInMaintenanceMode()"], ["void", "org.apache.hadoop.hbase.master.HMaster.setInitialized(boolean)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent", "org.apache.hadoop.hbase.master.HMaster.getInitializedEvent()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.isServerCrashProcessingEnabled()"], ["void", "org.apache.hadoop.hbase.master.HMaster.setServerCrashProcessingEnabled(boolean)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent", "org.apache.hadoop.hbase.master.HMaster.getServerCrashProcessingEnabledEvent()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.isInitializationStartsMetaRegionAssignment()"], ["double", "org.apache.hadoop.hbase.master.HMaster.getAverageLoad()"], ["long", "org.apache.hadoop.hbase.master.HMaster.getSplitPlanCount()"], ["long", "org.apache.hadoop.hbase.master.HMaster.getMergePlanCount()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.registerService(com.google.protobuf.Service)"], ["org.apache.hadoop.hbase.master.HMaster", "org.apache.hadoop.hbase.master.HMaster.constructMaster(java.lang.Class<? extends org.apache.hadoop.hbase.master.HMaster>, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.CoordinatedStateManager)"], ["void", "org.apache.hadoop.hbase.master.HMaster.main(java.lang.String[])"], ["org.apache.hadoop.hbase.master.cleaner.HFileCleaner", "org.apache.hadoop.hbase.master.HMaster.getHFileCleaner()"], ["org.apache.hadoop.hbase.master.cleaner.LogCleaner", "org.apache.hadoop.hbase.master.HMaster.getLogCleaner()"], ["org.apache.hadoop.hbase.master.snapshot.SnapshotManager", "org.apache.hadoop.hbase.master.HMaster.getSnapshotManager()"], ["org.apache.hadoop.hbase.procedure.MasterProcedureManagerHost", "org.apache.hadoop.hbase.master.HMaster.getMasterProcedureManagerHost()"], ["void", "org.apache.hadoop.hbase.master.HMaster.createNamespace(org.apache.hadoop.hbase.NamespaceDescriptor, long, long)"], ["void", "org.apache.hadoop.hbase.master.HMaster.createNamespaceSync(org.apache.hadoop.hbase.NamespaceDescriptor, long, long, boolean)"], ["void", "org.apache.hadoop.hbase.master.HMaster.modifyNamespace(org.apache.hadoop.hbase.NamespaceDescriptor, long, long)"], ["void", "org.apache.hadoop.hbase.master.HMaster.deleteNamespace(java.lang.String, long, long)"], ["org.apache.hadoop.hbase.NamespaceDescriptor", "org.apache.hadoop.hbase.master.HMaster.getNamespaceDescriptor(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.abortProcedure(long, boolean)"], ["long", "org.apache.hadoop.hbase.master.HMaster.getLastMajorCompactionTimestamp(org.apache.hadoop.hbase.TableName)"], ["long", "org.apache.hadoop.hbase.master.HMaster.getLastMajorCompactionTimestampForRegion(byte[])"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.isBalancerOn()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.isNormalizerOn()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster.isSplitOrMergeEnabled(org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["java.lang.String", "org.apache.hadoop.hbase.master.HMaster.getLoadBalancerClassName()"], ["org.apache.hadoop.hbase.zookeeper.RegionNormalizerTracker", "org.apache.hadoop.hbase.master.HMaster.getRegionNormalizerTracker()"], ["org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker", "org.apache.hadoop.hbase.master.HMaster.getSplitOrMergeTracker()"], ["org.apache.hadoop.hbase.master.LoadBalancer", "org.apache.hadoop.hbase.master.HMaster.getLoadBalancer()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$29.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$43.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$51.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$58.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$65.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$66.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$73.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$86.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$87.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$99.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.master.MasterFileSystem", "org.apache.hadoop.hbase.master.MasterFileSystem(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.master.MasterServices)"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.master.MasterFileSystem.getFileSystem()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.master.MasterFileSystem.getOldLogDir()"], ["boolean", "org.apache.hadoop.hbase.master.MasterFileSystem.checkFileSystem()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.master.MasterFileSystem.getConfiguration()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.master.MasterFileSystem.getRootDir()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.master.MasterFileSystem.getWALRootDir()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.master.MasterFileSystem.getTempDir()"], ["org.apache.hadoop.hbase.ClusterId", "org.apache.hadoop.hbase.master.MasterFileSystem.getClusterId()"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.splitMetaLog(org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.splitMetaLog(java.util.Set<org.apache.hadoop.hbase.ServerName>)"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.prepareLogReplay(org.apache.hadoop.hbase.ServerName, java.util.Set<org.apache.hadoop.hbase.HRegionInfo>)"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(java.util.Set<org.apache.hadoop.hbase.ServerName>)"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(java.util.Set<org.apache.hadoop.hbase.ServerName>, org.apache.hadoop.fs.PathFilter)"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.setInfoFamilyCachingForMeta(org.apache.hadoop.hbase.HTableDescriptor, boolean)"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.deleteFamilyFromFS(org.apache.hadoop.hbase.HRegionInfo, byte[])"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.stop()"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.setLogRecoveryMode()"], ["org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode", "org.apache.hadoop.hbase.master.MasterFileSystem.getLogRecoveryMode()"], ["void", "org.apache.hadoop.hbase.master.MasterFileSystem.logFileSystemState(org.apache.commons.logging.Log)"], ["org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl(org.apache.hadoop.hbase.master.HMaster)"], ["double", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getAverageLoad()"], ["long", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getSplitPlanCount()"], ["long", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getMergePlanCount()"], ["long", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getMasterInitializationTime()"], ["java.lang.String", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getClusterId()"], ["java.lang.String", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getZookeeperQuorum()"], ["java.lang.String[]", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getCoprocessors()"], ["long", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getStartTime()"], ["long", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getActiveTime()"], ["java.lang.String", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getRegionServers()"], ["int", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getNumRegionServers()"], ["java.lang.String", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getDeadRegionServers()"], ["int", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getNumDeadRegionServers()"], ["java.lang.String", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getServerName()"], ["boolean", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getIsActiveMaster()"], ["long", "org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.getNumWALFiles()"], ["void", "org.apache.hadoop.hbase.master.OfflineCallback$ExistCallback.processResult(int, java.lang.String, java.lang.Object, org.apache.zookeeper.data.Stat)"], ["org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure", "org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure()"], ["org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure", "org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.deserializeStateData(java.io.InputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.abort(java.lang.Object)"], ["org.apache.hadoop.hbase.master.procedure.DisableTableProcedure$MarkRegionOfflineOpResult[]", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure$MarkRegionOfflineOpResult.values()"], ["org.apache.hadoop.hbase.master.procedure.DisableTableProcedure$MarkRegionOfflineOpResult", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure$MarkRegionOfflineOpResult.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv$WALStoreLeaseRecovery", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv$WALStoreLeaseRecovery(org.apache.hadoop.hbase.master.HMaster)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv$WALStoreLeaseRecovery.recoverFileLease(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$QueueImpl", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$QueueImpl(TKey)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$QueueImpl", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$QueueImpl(TKey, int)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$QueueImpl.add(org.apache.hadoop.hbase.procedure2.Procedure, boolean)"], ["org.apache.hadoop.hbase.procedure2.Procedure", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$QueueImpl.peek()"], ["org.apache.hadoop.hbase.procedure2.Procedure", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$QueueImpl.poll()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$QueueImpl.isEmpty()"], ["int", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$QueueImpl.size()"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure$1.run()"], ["java.lang.Boolean", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait$1.evaluate()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait$1.evaluate()"], ["org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure", "org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.ServerName, boolean, boolean)"], ["org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure", "org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure()"], ["void", "org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["void", "org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.deserializeStateData(java.io.InputStream)"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.getServerName()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.hasMetaTableRegion()"], ["org.apache.hadoop.hbase.master.procedure.ServerProcedureInterface$ServerOperationType", "org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.getServerOperationType()"], ["org.apache.hadoop.hbase.master.ServerManager", "org.apache.hadoop.hbase.master.ServerManager(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.master.MasterServices)"], ["void", "org.apache.hadoop.hbase.master.ServerManager.registerListener(org.apache.hadoop.hbase.master.ServerListener)"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.unregisterListener(org.apache.hadoop.hbase.master.ServerListener)"], ["org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos$RegionStoreSequenceIds", "org.apache.hadoop.hbase.master.ServerManager.getLastFlushedSequenceId(byte[])"], ["org.apache.hadoop.hbase.ServerLoad", "org.apache.hadoop.hbase.master.ServerManager.getLoad(org.apache.hadoop.hbase.ServerName)"], ["double", "org.apache.hadoop.hbase.master.ServerManager.getAverageLoad()"], ["int", "org.apache.hadoop.hbase.master.ServerManager.countOfRegionServers()"], ["java.util.Map<org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerLoad>", "org.apache.hadoop.hbase.master.ServerManager.getOnlineServers()"], ["org.apache.hadoop.hbase.master.DeadServer", "org.apache.hadoop.hbase.master.ServerManager.getDeadServers()"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.areDeadServersInProgress()"], ["synchronized", "org.apache.hadoop.hbase.master.ServerManager.void expireServer(org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.ServerManager.moveFromOnlineToDeadServers(org.apache.hadoop.hbase.ServerName)"], ["synchronized", "org.apache.hadoop.hbase.master.ServerManager.void processDeadServer(org.apache.hadoop.hbase.ServerName, boolean)"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.removeServerFromDrainList(org.apache.hadoop.hbase.ServerName)"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.addServerToDrainList(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.regionserver.RegionOpeningState", "org.apache.hadoop.hbase.master.ServerManager.sendRegionOpen(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, int, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, int, org.apache.hadoop.hbase.ServerName, boolean)"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, int)"], ["void", "org.apache.hadoop.hbase.master.ServerManager.sendRegionWarmup(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.ServerManager.closeRegionSilentlyAndWait(org.apache.hadoop.hbase.client.ClusterConnection, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, long)"], ["void", "org.apache.hadoop.hbase.master.ServerManager.sendRegionsMerge(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, boolean, org.apache.hadoop.hbase.security.User)"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.isServerReachable(org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.ServerManager.waitForRegionServers(org.apache.hadoop.hbase.monitoring.MonitoredTask)"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.isServerOnline(org.apache.hadoop.hbase.ServerName)"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.isServerWithSameHostnamePortOnline(org.apache.hadoop.hbase.ServerName)"], ["synchronized", "org.apache.hadoop.hbase.master.ServerManager.boolean isServerDead(org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.ServerManager.shutdownCluster()"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.isClusterShutdown()"], ["void", "org.apache.hadoop.hbase.master.ServerManager.stop()"], ["void", "org.apache.hadoop.hbase.master.ServerManager.removeRegion(org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.master.ServerManager.isRegionInServerManagerStates(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.ServerManager.removeRegions(java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["org.apache.hadoop.hbase.master.SplitLogManager", "org.apache.hadoop.hbase.master.SplitLogManager(org.apache.hadoop.hbase.Server, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Stoppable, org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.fs.FileStatus[]", "org.apache.hadoop.hbase.master.SplitLogManager.getFileList(org.apache.hadoop.conf.Configuration, java.util.List<org.apache.hadoop.fs.Path>, org.apache.hadoop.fs.PathFilter)"], ["long", "org.apache.hadoop.hbase.master.SplitLogManager.splitLogDistributed(org.apache.hadoop.fs.Path)"], ["long", "org.apache.hadoop.hbase.master.SplitLogManager.splitLogDistributed(java.util.List<org.apache.hadoop.fs.Path>)"], ["long", "org.apache.hadoop.hbase.master.SplitLogManager.splitLogDistributed(java.util.Set<org.apache.hadoop.hbase.ServerName>, java.util.List<org.apache.hadoop.fs.Path>, org.apache.hadoop.fs.PathFilter)"], ["void", "org.apache.hadoop.hbase.master.SplitLogManager.stop()"], ["void", "org.apache.hadoop.hbase.master.SplitLogManager.setRecoveryMode(boolean)"], ["void", "org.apache.hadoop.hbase.master.SplitLogManager.markRegionsRecovering(org.apache.hadoop.hbase.ServerName, java.util.Set<org.apache.hadoop.hbase.HRegionInfo>)"], ["boolean", "org.apache.hadoop.hbase.master.SplitLogManager.isLogReplaying()"], ["boolean", "org.apache.hadoop.hbase.master.SplitLogManager.isLogSplitting()"], ["org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode", "org.apache.hadoop.hbase.master.SplitLogManager.getRecoveryMode()"], ["int", "org.apache.hadoop.hbase.migration.NamespaceUpgrade$2.compare(org.apache.hadoop.fs.FileStatus, org.apache.hadoop.fs.FileStatus)"], ["int", "org.apache.hadoop.hbase.migration.NamespaceUpgrade$2.compare(java.lang.Object, java.lang.Object)"], ["synchronized", "org.apache.hadoop.hbase.monitoring.TaskMonitor.org.apache.hadoop.hbase.monitoring.TaskMonitor get()"], ["synchronized", "org.apache.hadoop.hbase.monitoring.TaskMonitor.org.apache.hadoop.hbase.monitoring.MonitoredTask createStatus(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.monitoring.TaskMonitor.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandler createRPCStatus(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.TaskMonitor.dumpAsText(java.io.PrintWriter)"], ["synchronized", "org.apache.hadoop.hbase.monitoring.TaskMonitor.void shutdown()"], ["org.apache.hadoop.hbase.procedure.RegionServerProcedureManagerHost", "org.apache.hadoop.hbase.procedure.RegionServerProcedureManagerHost()"], ["void", "org.apache.hadoop.hbase.procedure.RegionServerProcedureManagerHost.initialize(org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["void", "org.apache.hadoop.hbase.procedure.RegionServerProcedureManagerHost.start()"], ["void", "org.apache.hadoop.hbase.procedure.RegionServerProcedureManagerHost.stop(boolean)"], ["void", "org.apache.hadoop.hbase.procedure.RegionServerProcedureManagerHost.loadProcedures(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.procedure.Subprocedure", "org.apache.hadoop.hbase.procedure.Subprocedure(org.apache.hadoop.hbase.procedure.ProcedureMember, java.lang.String, org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher, long, long)"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.Subprocedure.getName()"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.Subprocedure.getMemberName()"], ["java.lang.Void", "org.apache.hadoop.hbase.procedure.Subprocedure.call()"], ["void", "org.apache.hadoop.hbase.procedure.Subprocedure.cancel(java.lang.String, java.lang.Throwable)"], ["void", "org.apache.hadoop.hbase.procedure.Subprocedure.receiveReachedGlobalBarrier()"], ["void", "org.apache.hadoop.hbase.procedure.Subprocedure.waitForLocallyCompleted()"], ["java.lang.Object", "org.apache.hadoop.hbase.procedure.Subprocedure.call()"], ["org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs", "org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String)"], ["org.apache.hadoop.hbase.procedure.ZKProcedureUtil", "org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.getZkController()"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.getMemberName()"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.sendMemberAcquired(org.apache.hadoop.hbase.procedure.Subprocedure)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.sendMemberCompleted(org.apache.hadoop.hbase.procedure.Subprocedure, byte[])"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.sendMemberAborted(org.apache.hadoop.hbase.procedure.Subprocedure, org.apache.hadoop.hbase.errorhandling.ForeignException)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.start(java.lang.String, org.apache.hadoop.hbase.procedure.ProcedureMember)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.close()"], ["org.apache.hadoop.hbase.quotas.OperationQuota", "org.apache.hadoop.hbase.quotas.NoopOperationQuota.get()"], ["void", "org.apache.hadoop.hbase.quotas.NoopOperationQuota.checkQuota(int, int, int)"], ["void", "org.apache.hadoop.hbase.quotas.NoopOperationQuota.close()"], ["void", "org.apache.hadoop.hbase.quotas.NoopOperationQuota.addGetResult(org.apache.hadoop.hbase.client.Result)"], ["void", "org.apache.hadoop.hbase.quotas.NoopOperationQuota.addScanResult(java.util.List<org.apache.hadoop.hbase.client.Result>)"], ["void", "org.apache.hadoop.hbase.quotas.NoopOperationQuota.addMutation(org.apache.hadoop.hbase.client.Mutation)"], ["long", "org.apache.hadoop.hbase.quotas.NoopOperationQuota.getReadAvailable()"], ["long", "org.apache.hadoop.hbase.quotas.NoopOperationQuota.getWriteAvailable()"], ["org.apache.hadoop.hbase.client.Get", "org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore$3.makeGet(java.util.Map$Entry<java.lang.String, org.apache.hadoop.hbase.quotas.UserQuotaState>)"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.quotas.UserQuotaState>", "org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore$3.fetchEntries(java.util.List<org.apache.hadoop.hbase.client.Get>)"], ["java.lang.String", "org.apache.hadoop.hbase.quotas.QuotaUtil$3.getKeyFromRow(byte[])"], ["java.lang.Object", "org.apache.hadoop.hbase.quotas.QuotaUtil$3.getKeyFromRow(byte[])"], ["org.apache.hadoop.hbase.quotas.UserQuotaState", "org.apache.hadoop.hbase.quotas.UserQuotaState()"], ["org.apache.hadoop.hbase.quotas.UserQuotaState", "org.apache.hadoop.hbase.quotas.UserQuotaState(long)"], ["synchronized", "org.apache.hadoop.hbase.quotas.UserQuotaState.java.lang.String toString()"], ["synchronized", "org.apache.hadoop.hbase.quotas.UserQuotaState.boolean isBypass()"], ["synchronized", "org.apache.hadoop.hbase.quotas.UserQuotaState.boolean hasBypassGlobals()"], ["synchronized", "org.apache.hadoop.hbase.quotas.UserQuotaState.void setQuotas(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["synchronized", "org.apache.hadoop.hbase.quotas.UserQuotaState.void setQuotas(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["synchronized", "org.apache.hadoop.hbase.quotas.UserQuotaState.void setQuotas(java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["synchronized", "org.apache.hadoop.hbase.quotas.UserQuotaState.void update(org.apache.hadoop.hbase.quotas.QuotaState)"], ["synchronized", "org.apache.hadoop.hbase.quotas.UserQuotaState.org.apache.hadoop.hbase.quotas.QuotaLimiter getTableLimiter(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.ceiling(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.floor(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.higher(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.lower(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.pollFirst()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.pollLast()"], ["java.util.Comparator<? super org.apache.hadoop.hbase.Cell>", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.comparator()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.first()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.last()"], ["boolean", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.add(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.addAll(java.util.Collection<? extends org.apache.hadoop.hbase.Cell>)"], ["void", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.clear()"], ["boolean", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.contains(java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.containsAll(java.util.Collection<?>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.isEmpty()"], ["boolean", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.remove(java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.removeAll(java.util.Collection<?>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.retainAll(java.util.Collection<?>)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.get(org.apache.hadoop.hbase.Cell)"], ["int", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.size()"], ["java.lang.Object[]", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.toArray()"], ["<T> T[]", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.toArray(T[])"], ["java.util.SortedSet", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.tailSet(java.lang.Object)"], ["java.util.SortedSet", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.headSet(java.lang.Object)"], ["java.util.SortedSet", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.subSet(java.lang.Object, java.lang.Object)"], ["java.util.NavigableSet", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.tailSet(java.lang.Object, boolean)"], ["java.util.NavigableSet", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.headSet(java.lang.Object, boolean)"], ["java.util.NavigableSet", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.subSet(java.lang.Object, boolean, java.lang.Object, boolean)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.pollLast()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.pollFirst()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.higher(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.ceiling(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.floor(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.lower(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.last()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.first()"], ["boolean", "org.apache.hadoop.hbase.regionserver.CellSkipListSet.add(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress", "org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress(long)"], ["float", "org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.getProgressPct()"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.cancel()"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.complete()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.getTotalCompactingKvs()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.getCurrentCompactedKvs()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.getTotalCompactedSize()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.toString()"], ["org.apache.hadoop.hbase.regionserver.ScanType", "org.apache.hadoop.hbase.regionserver.compactions.Compactor$1.getScanType(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.regionserver.compactions.Compactor$1.createScanner(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFileScanner>, org.apache.hadoop.hbase.regionserver.ScanType, org.apache.hadoop.hbase.regionserver.compactions.Compactor$FileDetails, long)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Writer", "org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor$1.createWriter(org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.compactions.Compactor$FileDetails, boolean)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor$1.createWriter(org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.compactions.Compactor$FileDetails, boolean)"], ["org.apache.hadoop.hbase.regionserver.compactions.FIFOCompactionPolicy", "org.apache.hadoop.hbase.regionserver.compactions.FIFOCompactionPolicy(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.StoreConfigInformation)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.FIFOCompactionPolicy.selectCompaction(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>, boolean, boolean, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.FIFOCompactionPolicy.shouldPerformMajorCompaction(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.FIFOCompactionPolicy.needsCompaction(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor$2.createWriter(org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.compactions.Compactor$FileDetails, boolean)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor$2.createWriter(org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.compactions.Compactor$FileDetails, boolean)"], ["java.lang.Thread", "org.apache.hadoop.hbase.regionserver.CompactSplitThread$3.newThread(java.lang.Runnable)"], ["org.apache.hadoop.hbase.regionserver.DefaultStoreEngine", "org.apache.hadoop.hbase.regionserver.DefaultStoreEngine()"], ["boolean", "org.apache.hadoop.hbase.regionserver.DefaultStoreEngine.needsCompaction(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionContext", "org.apache.hadoop.hbase.regionserver.DefaultStoreEngine.createCompaction()"], ["org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy", "org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy()"], ["org.apache.hadoop.hbase.regionserver.handler.FinishRegionRecoveringHandler", "org.apache.hadoop.hbase.regionserver.handler.FinishRegionRecoveringHandler(org.apache.hadoop.hbase.regionserver.RegionServerServices, java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.handler.FinishRegionRecoveringHandler.process()"], ["org.apache.hadoop.hbase.regionserver.handler.OpenPriorityRegionHandler", "org.apache.hadoop.hbase.regionserver.handler.OpenPriorityRegionHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, long, org.apache.hadoop.hbase.coordination.OpenRegionCoordination, org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails)"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB$Chunk.init()"], ["int", "org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB$Chunk.alloc(int)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB$Chunk.toString()"], ["org.apache.hadoop.hbase.util.Pair<byte[], java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>>", "org.apache.hadoop.hbase.regionserver.HRegion$2.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.HRegion$2.call()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion$FlushResultImpl.isFlushSucceeded()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion$FlushResultImpl.isCompactionNeeded()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.HRegion$FlushResultImpl.toString()"], ["org.apache.hadoop.hbase.regionserver.Region$FlushResult$Result", "org.apache.hadoop.hbase.regionserver.HRegion$FlushResultImpl.getResult()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer$5.run(com.google.protobuf.Message)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer$5.run(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.HRegionServer", "org.apache.hadoop.hbase.regionserver.HRegionServer(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.HRegionServer", "org.apache.hadoop.hbase.regionserver.HRegionServer(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.CoordinatedStateManager)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.registerService(com.google.protobuf.Service)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.HRegionServer.getClusterId()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.run()"], ["org.apache.hadoop.hbase.regionserver.RegionServerAccounting", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionServerAccounting()"], ["org.apache.hadoop.hbase.master.TableLockManager", "org.apache.hadoop.hbase.regionserver.HRegionServer.getTableLockManager()"], ["org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos$RegionLoad", "org.apache.hadoop.hbase.regionserver.HRegionServer.createRegionLoad(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.isOnline()"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionServer", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionServerMetrics()"], ["org.apache.hadoop.hbase.zookeeper.MasterAddressTracker", "org.apache.hadoop.hbase.regionserver.HRegionServer.getMasterAddressTracker()"], ["org.apache.hadoop.hbase.wal.WAL", "org.apache.hadoop.hbase.regionserver.HRegionServer.getWAL(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.client.ClusterConnection", "org.apache.hadoop.hbase.regionserver.HRegionServer.getConnection()"], ["org.apache.hadoop.hbase.zookeeper.MetaTableLocator", "org.apache.hadoop.hbase.regionserver.HRegionServer.getMetaTableLocator()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.stop(java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.stop(java.lang.String, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.waitForServerOnline()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(org.apache.hadoop.hbase.regionserver.RegionServerServices$PostOpenDeployContext)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionStateTransition$TransitionCode, org.apache.hadoop.hbase.HRegionInfo...)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionStateTransition$TransitionCode, long, org.apache.hadoop.hbase.HRegionInfo...)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(org.apache.hadoop.hbase.regionserver.RegionServerServices$RegionStateTransitionContext)"], ["org.apache.hadoop.hbase.ipc.RpcServerInterface", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRpcServer()"], ["org.apache.hadoop.hbase.regionserver.RSRpcServices", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRSRpcServices()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.abort(java.lang.String, java.lang.Throwable)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.abort(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.isAborted()"], ["org.apache.hadoop.hbase.regionserver.ReplicationSourceService", "org.apache.hadoop.hbase.regionserver.HRegionServer.getReplicationSourceService()"], ["org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos$RegionStoreSequenceIds", "org.apache.hadoop.hbase.regionserver.HRegionServer.getLastSequenceId(byte[])"], ["org.apache.hadoop.hbase.http.InfoServer", "org.apache.hadoop.hbase.regionserver.HRegionServer.getInfoServer()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.isStopped()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.isStopping()"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.regionserver.Region>", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRecoveringRegions()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.regionserver.HRegionServer.getConfiguration()"], ["int", "org.apache.hadoop.hbase.regionserver.HRegionServer.getNumberOfOnlineRegions()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.addToOnlineRegions(org.apache.hadoop.hbase.regionserver.Region)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegionServer.getStartcode()"], ["org.apache.hadoop.hbase.regionserver.FlushRequester", "org.apache.hadoop.hbase.regionserver.HRegionServer.getFlushRequester()"], ["org.apache.hadoop.hbase.regionserver.Leases", "org.apache.hadoop.hbase.regionserver.HRegionServer.getLeases()"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.regionserver.HRegionServer.getFileSystem()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.HRegionServer.toString()"], ["int", "org.apache.hadoop.hbase.regionserver.HRegionServer.getThreadWakeFrequency()"], ["org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher", "org.apache.hadoop.hbase.regionserver.HRegionServer.getZooKeeper()"], ["org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager", "org.apache.hadoop.hbase.regionserver.HRegionServer.getCoordinatedStateManager()"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.regionserver.HRegionServer.getServerName()"], ["org.apache.hadoop.hbase.regionserver.CompactionRequestor", "org.apache.hadoop.hbase.regionserver.HRegionServer.getCompactionRequester()"], ["org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionServerCoprocessorHost()"], ["java.util.concurrent.ConcurrentMap<byte[], java.lang.Boolean>", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionsInTransitionInRS()"], ["org.apache.hadoop.hbase.executor.ExecutorService", "org.apache.hadoop.hbase.regionserver.HRegionServer.getExecutorService()"], ["org.apache.hadoop.hbase.ChoreService", "org.apache.hadoop.hbase.regionserver.HRegionServer.getChoreService()"], ["org.apache.hadoop.hbase.quotas.RegionServerQuotaManager", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionServerQuotaManager()"], ["org.apache.hadoop.hbase.regionserver.HRegionServer", "org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(java.lang.Class<? extends org.apache.hadoop.hbase.regionserver.HRegionServer>, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.CoordinatedStateManager)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.main(java.lang.String[])"], ["java.lang.String[]", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionServerCoprocessors()"], ["org.apache.hadoop.hbase.regionserver.Region", "org.apache.hadoop.hbase.regionserver.HRegionServer.getOnlineRegion(byte[])"], ["java.net.InetSocketAddress[]", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionBlockLocations(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.Region", "org.apache.hadoop.hbase.regionserver.HRegionServer.getFromOnlineRegions(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.removeFromOnlineRegions(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.regionserver.Region", "org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.checkFileSystem()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.updateRegionFavoredNodesMapping(java.lang.String, java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$ServerName>)"], ["java.net.InetSocketAddress[]", "org.apache.hadoop.hbase.regionserver.HRegionServer.getFavoredNodesForRegion(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.ServerNonceManager", "org.apache.hadoop.hbase.regionserver.HRegionServer.getNonceManager()"], ["org.apache.hadoop.hbase.regionserver.CompactSplitThread", "org.apache.hadoop.hbase.regionserver.HRegionServer.getCompactSplitThread()"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$CoprocessorServiceResponse", "org.apache.hadoop.hbase.regionserver.HRegionServer.execRegionServerService(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$CoprocessorServiceRequest)"], ["org.apache.hadoop.hbase.io.hfile.CacheConfig", "org.apache.hadoop.hbase.regionserver.HRegionServer.getCacheConfig()"], ["org.apache.hadoop.hbase.TableDescriptors", "org.apache.hadoop.hbase.regionserver.HRegionServer.getTableDescriptors()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.updateConfiguration()"], ["org.apache.hadoop.hbase.regionserver.HeapMemoryManager", "org.apache.hadoop.hbase.regionserver.HRegionServer.getHeapMemoryManager()"], ["double", "org.apache.hadoop.hbase.regionserver.HRegionServer.getCompactionPressure()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer.walRollRequestFinished()"], ["org.apache.hadoop.hbase.regionserver.throttle.ThroughputController", "org.apache.hadoop.hbase.regionserver.HRegionServer.getFlushThroughputController()"], ["double", "org.apache.hadoop.hbase.regionserver.HRegionServer.getFlushPressure()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionServer", "org.apache.hadoop.hbase.regionserver.HRegionServer.getMetrics()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer.unassign(byte[])"], ["org.apache.hadoop.hbase.CoordinatedStateManager", "org.apache.hadoop.hbase.regionserver.HRegionServer.getCoordinatedStateManager()"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl$RegionServerMetricsWrapperRunnable", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl$RegionServerMetricsWrapperRunnable(org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl$RegionServerMetricsWrapperRunnable.void run()"], ["org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress", "org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress(T[], org.apache.hadoop.hbase.regionserver.OperationStatus[], org.apache.hadoop.hbase.regionserver.wal.WALEdit[], int, int)"], ["int", "org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.size()"], ["T", "org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.getOperation(int)"], ["void", "org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.setOperationStatus(int, org.apache.hadoop.hbase.regionserver.OperationStatus)"], ["org.apache.hadoop.hbase.regionserver.OperationStatus", "org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.getOperationStatus(int)"], ["void", "org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.setWalEdit(int, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.getWalEdit(int)"], ["void", "org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.addOperationsFromCP(int, org.apache.hadoop.hbase.client.Mutation[])"], ["org.apache.hadoop.hbase.client.Mutation[]", "org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.getOperationsFromCoprocessors(int)"], ["org.apache.hadoop.hbase.regionserver.NonReversedNonLazyKeyValueScanner", "org.apache.hadoop.hbase.regionserver.NonReversedNonLazyKeyValueScanner()"], ["boolean", "org.apache.hadoop.hbase.regionserver.NonReversedNonLazyKeyValueScanner.backwardSeek(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.NonReversedNonLazyKeyValueScanner.seekToPreviousRow(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.NonReversedNonLazyKeyValueScanner.seekToLastRow()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker(int, int, long)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker.checkColumn(byte[], int, int, byte)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker.checkVersions(byte[], int, int, long, byte, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker.reset()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker.getColumnHint()"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker.done()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker.getNextRowOrNextColumn(byte[], int, int)"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker.isDone(long)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$12.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$14.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$21.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$29.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$41.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$54.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$61.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$63.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$70.call(org.apache.hadoop.hbase.coprocessor.EndpointObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionOperation.hasCall(org.apache.hadoop.hbase.Coprocessor)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionOperation.call(org.apache.hadoop.hbase.Coprocessor, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$1.run()"], ["org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$JournalEntryImpl", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$JournalEntryImpl(org.apache.hadoop.hbase.regionserver.RegionMergeTransaction$RegionMergeTransactionPhase)"], ["org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$JournalEntryImpl", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$JournalEntryImpl(org.apache.hadoop.hbase.regionserver.RegionMergeTransaction$RegionMergeTransactionPhase, long)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$JournalEntryImpl.toString()"], ["org.apache.hadoop.hbase.regionserver.RegionMergeTransaction$RegionMergeTransactionPhase", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$JournalEntryImpl.getPhase()"], ["long", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$JournalEntryImpl.getTimeStamp()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$12.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$8.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.regionserver.RegionServerServices$PostOpenDeployContext", "org.apache.hadoop.hbase.regionserver.RegionServerServices$PostOpenDeployContext(org.apache.hadoop.hbase.regionserver.Region, long)"], ["org.apache.hadoop.hbase.regionserver.Region", "org.apache.hadoop.hbase.regionserver.RegionServerServices$PostOpenDeployContext.getRegion()"], ["long", "org.apache.hadoop.hbase.regionserver.RegionServerServices$PostOpenDeployContext.getMasterSystemTime()"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$Builder", "org.apache.hadoop.hbase.regionserver.ScannerContext$Builder.setKeepProgress(boolean)"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$Builder", "org.apache.hadoop.hbase.regionserver.ScannerContext$Builder.setTrackMetrics(boolean)"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$Builder", "org.apache.hadoop.hbase.regionserver.ScannerContext$Builder.setSizeLimit(org.apache.hadoop.hbase.regionserver.ScannerContext$LimitScope, long)"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$Builder", "org.apache.hadoop.hbase.regionserver.ScannerContext$Builder.setTimeLimit(org.apache.hadoop.hbase.regionserver.ScannerContext$LimitScope, long)"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$Builder", "org.apache.hadoop.hbase.regionserver.ScannerContext$Builder.setBatchLimit(int)"], ["org.apache.hadoop.hbase.regionserver.ScannerContext", "org.apache.hadoop.hbase.regionserver.ScannerContext$Builder.build()"], ["org.apache.hadoop.hbase.regionserver.ShutdownHook", "org.apache.hadoop.hbase.regionserver.ShutdownHook()"], ["void", "org.apache.hadoop.hbase.regionserver.ShutdownHook.install(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.Stoppable, java.lang.Thread)"], ["void", "org.apache.hadoop.hbase.regionserver.ShutdownHook.main(java.lang.String[])"], ["org.apache.hadoop.hbase.regionserver.SplitLogWorker$TaskExecutor$Status", "org.apache.hadoop.hbase.regionserver.SplitLogWorker$1.exec(java.lang.String, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["org.apache.hadoop.hbase.regionserver.SplitTransaction$SplitTransactionPhase[]", "org.apache.hadoop.hbase.regionserver.SplitTransaction$SplitTransactionPhase.values()"], ["org.apache.hadoop.hbase.regionserver.SplitTransaction$SplitTransactionPhase", "org.apache.hadoop.hbase.regionserver.SplitTransaction$SplitTransactionPhase.valueOf(java.lang.String)"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$4.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$4.run()"], ["org.apache.hadoop.hbase.regionserver.SplitTransactionImpl", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl(org.apache.hadoop.hbase.regionserver.Region, byte[])"], ["boolean", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.prepare()"], ["org.apache.hadoop.hbase.client.Put", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.addLocation(org.apache.hadoop.hbase.client.Put, org.apache.hadoop.hbase.ServerName, long)"], ["boolean", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.rollback(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["boolean", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.rollback(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.security.User)"], ["org.apache.hadoop.hbase.regionserver.SplitTransaction", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.registerTransactionListener(org.apache.hadoop.hbase.regionserver.SplitTransaction$TransactionListener)"], ["org.apache.hadoop.hbase.Server", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.getServer()"], ["org.apache.hadoop.hbase.regionserver.RegionServerServices", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.getRegionServerServices()"], ["org.apache.hadoop.hbase.regionserver.StoreFileScanner", "org.apache.hadoop.hbase.regionserver.StoreFileScanner(org.apache.hadoop.hbase.regionserver.StoreFile$Reader, org.apache.hadoop.hbase.io.hfile.HFileScanner, boolean, boolean, long, long, boolean)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.toString()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.peek()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.next()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.close()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(org.apache.hadoop.hbase.io.hfile.HFileScanner, org.apache.hadoop.hbase.Cell)"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.getScannerOrder()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.requestSeek(org.apache.hadoop.hbase.Cell, boolean, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.realSeekDone()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.enforceSeek()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.isFileScanner()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.shouldUseScanner(org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.Store, long)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToPreviousRow(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToLastRow()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.backwardSeek(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.StoreFileScanner.getNextIndexedKey()"], ["org.apache.hadoop.hbase.regionserver.StripeStoreEngine", "org.apache.hadoop.hbase.regionserver.StripeStoreEngine()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StripeStoreEngine.needsCompaction(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionContext", "org.apache.hadoop.hbase.regionserver.StripeStoreEngine.createCompaction()"], ["org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$BoundaryStripeFlushRequest", "org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$BoundaryStripeFlushRequest(org.apache.hadoop.hbase.KeyValue$KVComparator, java.util.List<byte[]>)"], ["org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter", "org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$BoundaryStripeFlushRequest.createWriter()"], ["org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController", "org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController()"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController.setup(org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController.start(java.lang.String)"], ["long", "org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController.control(java.lang.String, long)"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController.finish(java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController.isStopped()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController.toString()"], ["org.apache.hadoop.hbase.regionserver.throttle.PressureAwareFlushThroughputController", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareFlushThroughputController()"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareFlushThroughputController.setup(org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareFlushThroughputController.setConf(org.apache.hadoop.conf.Configuration)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareFlushThroughputController.toString()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.throttle.ThroughputControlUtil.getNameForThrottling(org.apache.hadoop.hbase.regionserver.Store, java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.wal.CompressionContext", "org.apache.hadoop.hbase.regionserver.wal.CompressionContext(java.lang.Class<? extends org.apache.hadoop.hbase.io.util.Dictionary>, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferExceptionHandler.handleEventException(java.lang.Throwable, long, java.lang.Object)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferExceptionHandler.handleOnStartException(java.lang.Throwable)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferExceptionHandler.handleOnShutdownException(java.lang.Throwable)"], ["org.apache.hadoop.hbase.KeyValue", "org.apache.hadoop.hbase.regionserver.wal.KeyValueCompression.readKV(java.io.DataInput, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.KeyValueCompression.writeKV(java.io.DataOutput, org.apache.hadoop.hbase.KeyValue, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$ReplicateWALEntryResponse", "org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink$ReplayServerCallable.call(int)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink$ReplayServerCallable.prepare(boolean)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink$ReplayServerCallable.call(int)"], ["org.apache.hadoop.hbase.replication.ChainWALEntryFilter", "org.apache.hadoop.hbase.replication.ChainWALEntryFilter(org.apache.hadoop.hbase.replication.WALEntryFilter...)"], ["org.apache.hadoop.hbase.replication.ChainWALEntryFilter", "org.apache.hadoop.hbase.replication.ChainWALEntryFilter(java.util.List<org.apache.hadoop.hbase.replication.WALEntryFilter>)"], ["void", "org.apache.hadoop.hbase.replication.ChainWALEntryFilter.initCellFilters()"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.replication.ChainWALEntryFilter.filter(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["boolean", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner$1.apply(org.apache.hadoop.fs.FileStatus)"], ["boolean", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner$1.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.replication.regionserver.HFileReplicator$Copier", "org.apache.hadoop.hbase.replication.regionserver.HFileReplicator$Copier(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, java.util.List<java.lang.String>)"], ["java.lang.Void", "org.apache.hadoop.hbase.replication.regionserver.HFileReplicator$Copier.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.replication.regionserver.HFileReplicator$Copier.call()"], ["org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaOutputSink", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaOutputSink(org.apache.hadoop.hbase.wal.WALSplitter$PipelineController, org.apache.hadoop.hbase.TableDescriptors, org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers, org.apache.hadoop.hbase.client.ClusterConnection, java.util.concurrent.ExecutorService, int, int)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaOutputSink.append(org.apache.hadoop.hbase.wal.WALSplitter$RegionEntryBuffer)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaOutputSink.flush()"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaOutputSink.keepRegionEvent(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["java.util.Map<byte[], java.lang.Long>", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaOutputSink.getOutputCounts()"], ["int", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaOutputSink.getNumberOfRecoveredRegions()"], ["org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint()"], ["org.apache.hadoop.hbase.replication.WALEntryFilter", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.getWALEntryfilter()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.init(org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.replicate(org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.canReplicateToSameCluster()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$LogsComparator", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$LogsComparator()"], ["int", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$LogsComparator.compare(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["int", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$LogsComparator.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread(org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager, org.apache.hadoop.hbase.replication.ReplicationQueueInfo, java.util.concurrent.PriorityBlockingQueue<org.apache.hadoop.fs.Path>, long, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.replication.WALEntryFilter, org.apache.hadoop.hbase.replication.regionserver.MetricsSource)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread.run()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread.getCurrentPath()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread$WALEntryBatch", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread.take()"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread.isReaderRunning()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread.setReaderRunning(boolean)"], ["org.apache.hadoop.hbase.replication.ScopeWALEntryFilter", "org.apache.hadoop.hbase.replication.ScopeWALEntryFilter()"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.replication.ScopeWALEntryFilter.filter(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.replication.ScopeWALEntryFilter.filterCell(org.apache.hadoop.hbase.wal.WAL$Entry, org.apache.hadoop.hbase.Cell)"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$11.run()"], ["java.lang.Void", "org.apache.hadoop.hbase.security.access.AccessController$7.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$7.run()"], ["org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$SecureBulkLoadListener", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$SecureBulkLoadListener(org.apache.hadoop.fs.FileSystem, java.lang.String, org.apache.hadoop.conf.Configuration)"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$SecureBulkLoadListener.prepareBulkLoad(byte[], java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$SecureBulkLoadListener.doneBulkLoad(byte[], java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$SecureBulkLoadListener.failedBulkLoad(byte[], java.lang.String)"], ["java.lang.Void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher$1.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher$1.call()"], ["org.apache.hadoop.hbase.security.access.ZKPermissionWatcher", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.security.access.TableAuthManager, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.start()"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.close()"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.nodeDeleted(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.nodeDataChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.nodeChildrenChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.writeToZookeeper(byte[], byte[])"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.deleteTableACLNode(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.deleteNamespaceACLNode(java.lang.String)"], ["org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String, long, long)"], ["void", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.start()"], ["void", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.stop()"], ["boolean", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.isMaster()"], ["java.lang.String", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.getName()"], ["byte[]", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.retrievePassword(org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier)"], ["org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.createIdentifier()"], ["synchronized", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.void addKey(org.apache.hadoop.hbase.security.token.AuthenticationKey)"], ["javax.crypto.SecretKey", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.createSecretKey(byte[])"], ["org.apache.hadoop.security.token.TokenIdentifier", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.createIdentifier()"], ["byte[]", "org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.retrievePassword(org.apache.hadoop.security.token.TokenIdentifier)"], ["org.apache.hadoop.hbase.security.visibility.EnforcingScanLabelGenerator", "org.apache.hadoop.hbase.security.visibility.EnforcingScanLabelGenerator()"], ["void", "org.apache.hadoop.hbase.security.visibility.EnforcingScanLabelGenerator.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.security.visibility.EnforcingScanLabelGenerator.getConf()"], ["org.apache.hadoop.hbase.security.visibility.ExpressionParser", "org.apache.hadoop.hbase.security.visibility.ExpressionParser()"], ["org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode", "org.apache.hadoop.hbase.security.visibility.ExpressionParser.parse(java.lang.String)"], ["org.apache.hadoop.hbase.snapshot.CreateSnapshot", "org.apache.hadoop.hbase.snapshot.CreateSnapshot()"], ["void", "org.apache.hadoop.hbase.snapshot.CreateSnapshot.main(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportMapper.setup(org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.io.BytesWritable, org.apache.hadoop.io.NullWritable, org.apache.hadoop.io.NullWritable, org.apache.hadoop.io.NullWritable>.Context)"], ["void", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportMapper.map(org.apache.hadoop.io.BytesWritable, org.apache.hadoop.io.NullWritable, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.io.BytesWritable, org.apache.hadoop.io.NullWritable, org.apache.hadoop.io.NullWritable, org.apache.hadoop.io.NullWritable>.Context)"], ["void", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$1.storeFile(org.apache.hadoop.hbase.HRegionInfo, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile)"], ["boolean", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$1.accept(org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil$1.storeFile(org.apache.hadoop.hbase.HRegionInfo, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.visitReferencedFiles(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil$SnapshotVisitor)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.visitReferencedFiles(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil$SnapshotVisitor)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.verifySnapshot(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.verifySnapshot(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.snapshot.SnapshotManifest)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.concurrentVisitReferencedFiles(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.snapshot.SnapshotManifest, java.lang.String, org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil$StoreFileVisitor)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.concurrentVisitReferencedFiles(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.snapshot.SnapshotManifest, java.util.concurrent.ExecutorService, org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil$StoreFileVisitor)"], ["java.net.Socket", "org.apache.hadoop.hbase.SslRMIServerSocketFactorySecure$1.accept()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$1.renderTo(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl$ImplData()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl$ImplData.setCacheConfig(org.apache.hadoop.hbase.io.hfile.CacheConfig)"], ["org.apache.hadoop.hbase.io.hfile.CacheConfig", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl$ImplData.getCacheConfig()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl$ImplData.setConfig(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl$ImplData.getConfig()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$1.renderTo(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmplImpl", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmplImpl(org.jamon.TemplateManager, org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl$ImplData)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmplImpl.renderNoFlush(java.io.Writer)"], ["java.lang.Void", "org.apache.hadoop.hbase.tool.Canary$RegionServerTask.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.tool.Canary$RegionServerTask.call()"], ["org.apache.hadoop.hbase.tool.WriteSinkCoprocessor", "org.apache.hadoop.hbase.tool.WriteSinkCoprocessor()"], ["void", "org.apache.hadoop.hbase.tool.WriteSinkCoprocessor.preOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.tool.WriteSinkCoprocessor.preBatchMutate(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress<org.apache.hadoop.hbase.client.Mutation>)"], ["org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue(int, java.util.Comparator<? super E>)"], ["boolean", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.offer(E)"], ["void", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.put(E)"], ["boolean", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.offer(E, long, java.util.concurrent.TimeUnit)"], ["E", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take()"], ["E", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.poll()"], ["E", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.poll(long, java.util.concurrent.TimeUnit)"], ["E", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.peek()"], ["int", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.size()"], ["java.util.Comparator<? super E>", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.comparator()"], ["int", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.remainingCapacity()"], ["boolean", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.remove(java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.contains(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.drainTo(java.util.Collection<? super E>)"], ["int", "org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.drainTo(java.util.Collection<? super E>, int)"], ["void", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter$MetaWriter.readFields(java.io.DataInput)"], ["void", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter$MetaWriter.write(java.io.DataOutput)"], ["org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir", "org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir()"], ["void", "org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir.migrateFSTableDescriptorsIfNecessary(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils$2.accept(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.util.FSUtils$HFileLinkFilter", "org.apache.hadoop.hbase.util.FSUtils$HFileLinkFilter()"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils$HFileLinkFilter.accept(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.util.GetJavaProperty", "org.apache.hadoop.hbase.util.GetJavaProperty()"], ["void", "org.apache.hadoop.hbase.util.GetJavaProperty.main(java.lang.String[])"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck$4.processRow(org.apache.hadoop.hbase.client.Result)"], ["org.apache.hadoop.hbase.util.HBaseFsck$MetaEntry", "org.apache.hadoop.hbase.util.HBaseFsck$MetaEntry(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, long)"], ["org.apache.hadoop.hbase.util.HBaseFsck$MetaEntry", "org.apache.hadoop.hbase.util.HBaseFsck$MetaEntry(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, long, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck$MetaEntry.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck$MetaEntry.hashCode()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$IntegrityFixSuggester.handleRegionStartKeyNotEmpty(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$IntegrityFixSuggester.handleRegionEndKeyNotEmpty(byte[])"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$IntegrityFixSuggester.handleDegenerateRegion(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$IntegrityFixSuggester.handleDuplicateStartKeys(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$IntegrityFixSuggester.handleSplit(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$IntegrityFixSuggester.handleOverlapInRegionChain(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$IntegrityFixSuggester.handleHoleInRegionChain(byte[], byte[])"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$WorkItemRegion.java.lang.Void call()"], ["java.lang.Object", "org.apache.hadoop.hbase.util.HBaseFsck$WorkItemRegion.call()"], ["org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl", "org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl()"], ["org.apache.hadoop.hbase.util.HBaseFsck$TableInfo", "org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.getTableInfo()"], ["void", "org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.setTableInfo(org.apache.hadoop.hbase.util.HBaseFsck$TableInfo)"], ["void", "org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.handleRegionStartKeyNotEmpty(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.handleRegionEndKeyNotEmpty(byte[])"], ["void", "org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.handleDegenerateRegion(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.handleDuplicateStartKeys(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.handleOverlapInRegionChain(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.handleHoleInRegionChain(byte[], byte[])"], ["void", "org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.handleOverlapGroup(java.util.Collection<org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo>)"], ["org.apache.hadoop.hbase.util.HFileV1Detector", "org.apache.hadoop.hbase.util.HFileV1Detector()"], ["int", "org.apache.hadoop.hbase.util.HFileV1Detector.run(java.lang.String[])"], ["org.apache.hadoop.hbase.io.FileLink", "org.apache.hadoop.hbase.util.HFileV1Detector.getFileLinkWithPreNSPath(org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.util.HFileV1Detector.main(java.lang.String[])"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread", "org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread(org.apache.hadoop.hbase.master.HMaster, int)"], ["org.apache.hadoop.hbase.master.HMaster", "org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread.getMaster()"], ["org.apache.hadoop.hbase.util.JVMClusterUtil", "org.apache.hadoop.hbase.util.JVMClusterUtil()"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread", "org.apache.hadoop.hbase.util.JVMClusterUtil.createRegionServerThread(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.CoordinatedStateManager, java.lang.Class<? extends org.apache.hadoop.hbase.regionserver.HRegionServer>, int)"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread", "org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.CoordinatedStateManager, java.lang.Class<? extends org.apache.hadoop.hbase.master.HMaster>, int)"], ["java.lang.String", "org.apache.hadoop.hbase.util.JVMClusterUtil.startup(java.util.List<org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread>, java.util.List<org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread>)"], ["void", "org.apache.hadoop.hbase.util.JVMClusterUtil.shutdown(java.util.List<org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread>, java.util.List<org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread>)"], ["org.apache.hadoop.hbase.util.MetaUtils", "org.apache.hadoop.hbase.util.MetaUtils()"], ["org.apache.hadoop.hbase.util.MetaUtils", "org.apache.hadoop.hbase.util.MetaUtils(org.apache.hadoop.conf.Configuration)"], ["synchronized", "org.apache.hadoop.hbase.util.MetaUtils.org.apache.hadoop.hbase.wal.WAL getLog(org.apache.hadoop.hbase.HRegionInfo)"], ["synchronized", "org.apache.hadoop.hbase.util.MetaUtils.org.apache.hadoop.hbase.regionserver.HRegion getMetaRegion()"], ["synchronized", "org.apache.hadoop.hbase.util.MetaUtils.void shutdown()"], ["org.apache.hadoop.hbase.util.RegionSizeCalculator", "org.apache.hadoop.hbase.util.RegionSizeCalculator(org.apache.hadoop.hbase.client.HTable)"], ["org.apache.hadoop.hbase.util.RegionSizeCalculator", "org.apache.hadoop.hbase.util.RegionSizeCalculator(org.apache.hadoop.hbase.client.RegionLocator, org.apache.hadoop.hbase.client.Admin)"], ["long", "org.apache.hadoop.hbase.util.RegionSizeCalculator.getRegionSize(byte[])"], ["java.util.Map<byte[], java.lang.Long>", "org.apache.hadoop.hbase.util.RegionSizeCalculator.getRegionSizeMap()"], ["org.apache.hadoop.hbase.util.RollingStatCalculator", "org.apache.hadoop.hbase.util.RollingStatCalculator(int)"], ["void", "org.apache.hadoop.hbase.util.RollingStatCalculator.insertDataValue(long)"], ["double", "org.apache.hadoop.hbase.util.RollingStatCalculator.getMean()"], ["double", "org.apache.hadoop.hbase.util.RollingStatCalculator.getDeviation()"], ["void", "org.apache.hadoop.hbase.util.ShutdownHookManager$ShutdownHookManagerV2.addShutdownHook(java.lang.Thread, int)"], ["boolean", "org.apache.hadoop.hbase.util.ShutdownHookManager$ShutdownHookManagerV2.removeShutdownHook(java.lang.Runnable)"], ["org.apache.hadoop.hbase.util.StealJobQueue", "org.apache.hadoop.hbase.util.StealJobQueue()"], ["boolean", "org.apache.hadoop.hbase.util.StealJobQueue.offer(T)"], ["T", "org.apache.hadoop.hbase.util.StealJobQueue.take()"], ["T", "org.apache.hadoop.hbase.util.StealJobQueue.poll(long, java.util.concurrent.TimeUnit)"], ["org.apache.hadoop.hbase.wal.DefaultWALProvider", "org.apache.hadoop.hbase.wal.DefaultWALProvider()"], ["void", "org.apache.hadoop.hbase.wal.DefaultWALProvider.init(org.apache.hadoop.hbase.wal.WALFactory, org.apache.hadoop.conf.Configuration, java.util.List<org.apache.hadoop.hbase.regionserver.wal.WALActionsListener>, java.lang.String)"], ["org.apache.hadoop.hbase.wal.WAL", "org.apache.hadoop.hbase.wal.DefaultWALProvider.getWAL(byte[], byte[])"], ["void", "org.apache.hadoop.hbase.wal.DefaultWALProvider.close()"], ["void", "org.apache.hadoop.hbase.wal.DefaultWALProvider.shutdown()"], ["long", "org.apache.hadoop.hbase.wal.DefaultWALProvider.getNumLogFiles()"], ["long", "org.apache.hadoop.hbase.wal.DefaultWALProvider.getLogFileSize()"], ["int", "org.apache.hadoop.hbase.wal.DefaultWALProvider.getNumRolledLogFiles(org.apache.hadoop.hbase.wal.WAL)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.wal.DefaultWALProvider.getCurrentFileName(org.apache.hadoop.hbase.wal.WAL)"], ["long", "org.apache.hadoop.hbase.wal.DefaultWALProvider.extractFileNumFromWAL(org.apache.hadoop.hbase.wal.WAL)"], ["boolean", "org.apache.hadoop.hbase.wal.DefaultWALProvider.validateWALFilename(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.wal.DefaultWALProvider.getWALDirectoryName(java.lang.String)"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.wal.DefaultWALProvider.getServerNameFromWALDirectoryName(org.apache.hadoop.conf.Configuration, java.lang.String)"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.wal.DefaultWALProvider.getServerNameFromWALDirectoryName(org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.wal.DefaultWALProvider.isMetaFile(org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.wal.DefaultWALProvider.isMetaFile(java.lang.String)"], ["org.apache.hadoop.hbase.wal.DefaultWALProvider$Writer", "org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, boolean)"], ["java.lang.String", "org.apache.hadoop.hbase.wal.DefaultWALProvider.getWALPrefixFromWALName(java.lang.String)"], ["org.apache.hadoop.hbase.wal.WALKey$Version[]", "org.apache.hadoop.hbase.wal.WALKey$Version.values()"], ["org.apache.hadoop.hbase.wal.WALKey$Version", "org.apache.hadoop.hbase.wal.WALKey$Version.valueOf(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.wal.WALKey$Version.atLeast(org.apache.hadoop.hbase.wal.WALKey$Version)"], ["org.apache.hadoop.hbase.wal.WALKey$Version", "org.apache.hadoop.hbase.wal.WALKey$Version.fromCode(int)"], ["java.lang.Void", "org.apache.hadoop.hbase.wal.WALSplitter$BoundedLogWriterCreationOutputSink$1.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.wal.WALSplitter$BoundedLogWriterCreationOutputSink$1.call()"], ["org.apache.hadoop.hbase.wal.WALSplitter$MutationReplay", "org.apache.hadoop.hbase.wal.WALSplitter$MutationReplay(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MutationProto$MutationType, org.apache.hadoop.hbase.client.Mutation, long, long)"], ["int", "org.apache.hadoop.hbase.wal.WALSplitter$MutationReplay.compareTo(org.apache.hadoop.hbase.wal.WALSplitter$MutationReplay)"], ["boolean", "org.apache.hadoop.hbase.wal.WALSplitter$MutationReplay.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.wal.WALSplitter$MutationReplay.hashCode()"], ["int", "org.apache.hadoop.hbase.wal.WALSplitter$MutationReplay.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.zookeeper.DeletionListener", "org.apache.hadoop.hbase.zookeeper.DeletionListener(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String, java.util.concurrent.CountDownLatch)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.DeletionListener.hasException()"], ["java.lang.Throwable", "org.apache.hadoop.hbase.zookeeper.DeletionListener.getException()"], ["void", "org.apache.hadoop.hbase.zookeeper.DeletionListener.nodeDataChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.zookeeper.DeletionListener.nodeDeleted(java.lang.String)"], ["org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadLock", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadLock(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String, byte[], org.apache.hadoop.hbase.InterProcessLock$MetadataHandler)"], ["org.apache.hadoop.hbase.zookeeper.RegionServerTracker", "org.apache.hadoop.hbase.zookeeper.RegionServerTracker(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.master.ServerManager)"], ["void", "org.apache.hadoop.hbase.zookeeper.RegionServerTracker.start()"], ["void", "org.apache.hadoop.hbase.zookeeper.RegionServerTracker.nodeDeleted(java.lang.String)"], ["void", "org.apache.hadoop.hbase.zookeeper.RegionServerTracker.nodeChildrenChanged(java.lang.String)"], ["org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$RegionServerInfo", "org.apache.hadoop.hbase.zookeeper.RegionServerTracker.getRegionServerInfo(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServer", "org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServer()"], ["java.lang.String", "org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServer.parse(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServer.main(java.lang.String[])"], ["org.apache.hadoop.hbase.backup.example.HFileArchiveManager", "org.apache.hadoop.hbase.backup.example.HFileArchiveManager(org.apache.hadoop.hbase.client.HConnection, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.backup.example.HFileArchiveManager", "org.apache.hadoop.hbase.backup.example.HFileArchiveManager.enableHFileBackup(byte[])"], ["org.apache.hadoop.hbase.backup.example.HFileArchiveManager", "org.apache.hadoop.hbase.backup.example.HFileArchiveManager.disableHFileBackup(byte[])"], ["org.apache.hadoop.hbase.backup.example.HFileArchiveManager", "org.apache.hadoop.hbase.backup.example.HFileArchiveManager.disableHFileBackup()"], ["void", "org.apache.hadoop.hbase.backup.example.HFileArchiveManager.stop()"], ["boolean", "org.apache.hadoop.hbase.backup.example.HFileArchiveManager.isArchivingEnabled(byte[])"], ["org.apache.hadoop.hbase.backup.HFileArchiver$FileStatusConverter", "org.apache.hadoop.hbase.backup.HFileArchiver$FileStatusConverter(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.backup.HFileArchiver$File", "org.apache.hadoop.hbase.backup.HFileArchiver$FileStatusConverter.apply(org.apache.hadoop.fs.FileStatus)"], ["java.lang.Object", "org.apache.hadoop.hbase.backup.HFileArchiver$FileStatusConverter.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.conf.ConfigurationManager", "org.apache.hadoop.hbase.conf.ConfigurationManager()"], ["void", "org.apache.hadoop.hbase.conf.ConfigurationManager.registerObserver(org.apache.hadoop.hbase.conf.ConfigurationObserver)"], ["void", "org.apache.hadoop.hbase.conf.ConfigurationManager.deregisterObserver(org.apache.hadoop.hbase.conf.ConfigurationObserver)"], ["void", "org.apache.hadoop.hbase.conf.ConfigurationManager.notifyAllObservers(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.conf.ConfigurationManager.getNumObservers()"], ["org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$CreateAsyncCallback", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$CreateAsyncCallback(org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$CreateAsyncCallback.processResult(int, java.lang.String, java.lang.Object, java.lang.String)"], ["org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination$ZkSplitTransactionDetails", "org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination$ZkSplitTransactionDetails()"], ["int", "org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination$ZkSplitTransactionDetails.getZnodeVersion()"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination$ZkSplitTransactionDetails.setZnodeVersion(int)"], ["org.apache.hadoop.hbase.coprocessor.BaseMasterObserver", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver()"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preCreateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postCreateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preCreateTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postCreateTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preDispatchMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postDispatchMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preGetClusterStatus(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postGetClusterStatus(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.ClusterStatus)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preClearDeadServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postClearDeadServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.ServerName>, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preDeleteTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postDeleteTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preDeleteTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postDeleteTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preTruncateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postTruncateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preTruncateTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postTruncateTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preModifyTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postModifyTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preModifyTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postModifyTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preCreateNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postCreateNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preDeleteNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postDeleteNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preModifyNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postModifyNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preGetNamespaceDescriptor(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postGetNamespaceDescriptor(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preListNamespaceDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.NamespaceDescriptor>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postListNamespaceDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.NamespaceDescriptor>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preAddColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postAddColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preAddColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postAddColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preModifyColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postModifyColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preModifyColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postModifyColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preDeleteColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postDeleteColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preDeleteColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postDeleteColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preEnableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postEnableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preEnableTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postEnableTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preDisableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postDisableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preDisableTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postDisableTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preAbortProcedure(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.procedure2.ProcedureExecutor<org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv>, long)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postAbortProcedure(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preListProcedures(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postListProcedures(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.ProcedureInfo>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preAssign(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postAssign(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preUnassign(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postUnassign(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preRegionOffline(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postRegionOffline(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preSetSplitOrMergeEnabled(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postSetSplitOrMergeEnabled(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preBalance(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postBalance(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.master.RegionPlan>)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preBalanceSwitch(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postBalanceSwitch(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preShutdown(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preStopMaster(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postStartMaster(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preMasterInitialization(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preMove(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postMove(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preListSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postListSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preCloneSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postCloneSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preRestoreSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postRestoreSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preDeleteSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postDeleteSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preGetTableDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postGetTableDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preGetTableDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postGetTableDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preGetTableNames(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postGetTableNames(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preTableFlush(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postTableFlush(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preSetTableQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postSetTableQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preSetNamespaceQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postSetNamespaceQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preMoveServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postMoveServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preMoveTables(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postMoveTables(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preMoveServersAndTables(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postMoveServersAndTables(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preAddRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postAddRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preRemoveRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postRemoveRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preRemoveServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postRemoveServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.preBalanceRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.postBalanceRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, boolean)"], ["org.apache.hadoop.hbase.coprocessor.CoprocessorHost", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost(org.apache.hadoop.hbase.Abortable)"], ["E", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost.load(org.apache.hadoop.fs.Path, java.lang.String, int, org.apache.hadoop.conf.Configuration)"], ["E", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost.load(org.apache.hadoop.fs.Path, java.lang.String, int, org.apache.hadoop.conf.Configuration, java.lang.String[])"], ["void", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost.load(java.lang.Class<?>, int, org.apache.hadoop.conf.Configuration)"], ["E", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost.loadInstance(java.lang.Class<?>, int, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost.shutdown(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["org.apache.hadoop.hbase.Coprocessor", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost.findCoprocessor(java.lang.String)"], ["<T extends org.apache.hadoop.hbase.Coprocessor> java.util.List<T>", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost.findCoprocessors(java.lang.Class<T>)"], ["org.apache.hadoop.hbase.CoprocessorEnvironment", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost.findCoprocessorEnvironment(java.lang.String)"], ["org.apache.hadoop.hbase.DaemonThreadFactory", "org.apache.hadoop.hbase.DaemonThreadFactory(java.lang.String)"], ["java.lang.Thread", "org.apache.hadoop.hbase.DaemonThreadFactory.newThread(java.lang.Runnable)"], ["org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector", "org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector(org.apache.hadoop.hbase.errorhandling.ForeignExceptionListener, long)"], ["long", "org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector.getMaxTime()"], ["void", "org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector.complete()"], ["synchronized", "org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector.void start()"], ["void", "org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector.trigger()"], ["java.lang.String", "org.apache.hadoop.hbase.executor.ExecutorService$Executor.toString()"], ["org.apache.hadoop.hbase.executor.ExecutorService$ExecutorStatus", "org.apache.hadoop.hbase.executor.ExecutorService$Executor.getStatus()"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$2.compare(java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>, java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$2.compare(java.lang.Object, java.lang.Object)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$4.compare(java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>, java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$4.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.generated.regionserver.regionserver_jsp", "org.apache.hadoop.hbase.generated.regionserver.regionserver_jsp()"], ["java.lang.Object", "org.apache.hadoop.hbase.generated.regionserver.regionserver_jsp.getDependants()"], ["void", "org.apache.hadoop.hbase.generated.regionserver.regionserver_jsp._jspService(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.generated.regionserver.storeFile_jsp", "org.apache.hadoop.hbase.generated.regionserver.storeFile_jsp()"], ["java.lang.Object", "org.apache.hadoop.hbase.generated.regionserver.storeFile_jsp.getDependants()"], ["void", "org.apache.hadoop.hbase.generated.regionserver.storeFile_jsp._jspService(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.http.conf.ConfServlet$BadFormatException", "org.apache.hadoop.hbase.http.conf.ConfServlet$BadFormatException(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpRequestLogAppender", "org.apache.hadoop.hbase.http.HttpRequestLogAppender()"], ["void", "org.apache.hadoop.hbase.http.HttpRequestLogAppender.setRetainDays(int)"], ["int", "org.apache.hadoop.hbase.http.HttpRequestLogAppender.getRetainDays()"], ["void", "org.apache.hadoop.hbase.http.HttpRequestLogAppender.setFilename(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.http.HttpRequestLogAppender.getFilename()"], ["void", "org.apache.hadoop.hbase.http.HttpRequestLogAppender.append(org.apache.log4j.spi.LoggingEvent)"], ["void", "org.apache.hadoop.hbase.http.HttpRequestLogAppender.close()"], ["boolean", "org.apache.hadoop.hbase.http.HttpRequestLogAppender.requiresLayout()"], ["org.apache.hadoop.hbase.http.HttpServer$StackServlet", "org.apache.hadoop.hbase.http.HttpServer$StackServlet()"], ["void", "org.apache.hadoop.hbase.http.HttpServer$StackServlet.doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.io.FileLink)"], ["org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.io.FileLink, int)"], ["int", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.read()"], ["int", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.read(byte[])"], ["int", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.read(byte[], int, int)"], ["int", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.read(long, byte[], int, int)"], ["void", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.readFully(long, byte[])"], ["void", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.readFully(long, byte[], int, int)"], ["long", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.skip(long)"], ["int", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.available()"], ["void", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.seek(long)"], ["long", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.getPos()"], ["boolean", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.seekToNewSource(long)"], ["void", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.close()"], ["synchronized", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.void mark(int)"], ["synchronized", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.void reset()"], ["boolean", "org.apache.hadoop.hbase.io.FileLink$FileLinkInputStream.markSupported()"], ["double", "org.apache.hadoop.hbase.io.hfile.AgeSnapshot.get75thPercentile()"], ["double", "org.apache.hadoop.hbase.io.hfile.AgeSnapshot.get95thPercentile()"], ["double", "org.apache.hadoop.hbase.io.hfile.AgeSnapshot.get98thPercentile()"], ["double", "org.apache.hadoop.hbase.io.hfile.AgeSnapshot.get99thPercentile()"], ["double", "org.apache.hadoop.hbase.io.hfile.AgeSnapshot.get999thPercentile()"], ["double", "org.apache.hadoop.hbase.io.hfile.AgeSnapshot.getMean()"], ["double", "org.apache.hadoop.hbase.io.hfile.AgeSnapshot.getMax()"], ["double", "org.apache.hadoop.hbase.io.hfile.AgeSnapshot.getMin()"], ["org.apache.hadoop.hbase.io.hfile.BlockCacheUtil", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.toString(org.apache.hadoop.hbase.io.hfile.CachedBlock, long)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.toJSON(java.lang.String, java.util.NavigableSet<org.apache.hadoop.hbase.io.hfile.CachedBlock>)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.toJSON(org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.toJSON(org.apache.hadoop.hbase.io.hfile.BlockCache)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.toStringMinusFileName(org.apache.hadoop.hbase.io.hfile.CachedBlock, long)"], ["org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.getLoadedCachedBlocksByFile(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.hfile.BlockCache)"], ["int", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.validateBlockAddition(org.apache.hadoop.hbase.io.hfile.Cacheable, org.apache.hadoop.hbase.io.hfile.Cacheable, org.apache.hadoop.hbase.io.hfile.BlockCacheKey)"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket(long)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.isUninstantiated()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.sizeIndex()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.getItemAllocationSize()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.hasFreeSpace()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.isCompletelyFree()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.freeCount()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.usedCount()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.getFreeBytes()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.getUsedBytes()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.getBaseOffset()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.allocate()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket.addAllocation(long)"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketCache", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache(java.lang.String, long, int, int[], int, int, java.lang.String)"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketCache", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache(java.lang.String, long, int, int[], int, int, java.lang.String, int, org.apache.hadoop.conf.Configuration)"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getMaxSize()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getIoEngine()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.cacheBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable)"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.cacheBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.cacheBlockWithWait(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable, boolean, boolean, boolean)"], ["org.apache.hadoop.hbase.io.hfile.Cacheable", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, boolean, boolean, boolean)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.evictBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey)"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.logStats()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getRealCacheSize()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.shutdown()"], ["org.apache.hadoop.hbase.io.hfile.CacheStats", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getStats()"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getAllocator()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.heapSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.size()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getCurrentDataSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getFreeSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getBlockCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getDataBlockCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getCurrentSize()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.evictBlocksByHfileName(java.lang.String)"], ["org.apache.hadoop.hbase.io.hfile.BlockCache[]", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getBlockCaches()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader(org.apache.hadoop.hbase.KeyValue$KVComparator, int, org.apache.hadoop.hbase.io.hfile.HFile$CachingBlockReader)"], ["org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader(org.apache.hadoop.hbase.KeyValue$KVComparator, int)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.isEmpty()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.ensureNonEmpty()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.seekToDataBlock(org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.io.hfile.HFileBlock, boolean, boolean, boolean, org.apache.hadoop.hbase.io.encoding.DataBlockEncoding)"], ["org.apache.hadoop.hbase.io.hfile.BlockWithScanInfo", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.loadDataBlockWithScanInfo(org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.io.hfile.HFileBlock, boolean, boolean, boolean, org.apache.hadoop.hbase.io.encoding.DataBlockEncoding)"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.midkey()"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.getRootBlockKey(int)"], ["long", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.getRootBlockOffset(int)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.getRootBlockDataSize(int)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.getRootBlockCount()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.rootBlockContainingKey(byte[], int, int)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.rootBlockContainingKey(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.readRootIndex(java.io.DataInput, int)"], ["java.io.DataInputStream", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.readRootIndex(org.apache.hadoop.hbase.io.hfile.HFileBlock, int)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.readMultiLevelIndexRoot(org.apache.hadoop.hbase.io.hfile.HFileBlock, int)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.toString()"], ["long", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.heapSize()"], ["org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter$SimpleReporter", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter$SimpleReporter(com.yammer.metrics.core.MetricsRegistry, java.io.PrintStream)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter$SimpleReporter.run()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter$SimpleReporter.processHistogram(com.yammer.metrics.core.MetricName, com.yammer.metrics.core.Histogram, java.io.PrintStream)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter$SimpleReporter.processHistogram(com.yammer.metrics.core.MetricName, com.yammer.metrics.core.Histogram, java.lang.Object)"], ["org.apache.hadoop.hbase.io.hfile.HFileReaderV3$ScannerV3", "org.apache.hadoop.hbase.io.hfile.HFileReaderV3$ScannerV3(org.apache.hadoop.hbase.io.hfile.HFileReaderV3, boolean, boolean, boolean)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.io.hfile.HFileReaderV3$ScannerV3.getKeyValue()"], ["org.apache.hadoop.hbase.io.hfile.InclusiveCombinedBlockCache", "org.apache.hadoop.hbase.io.hfile.InclusiveCombinedBlockCache(org.apache.hadoop.hbase.io.hfile.LruBlockCache, org.apache.hadoop.hbase.io.hfile.BlockCache)"], ["org.apache.hadoop.hbase.io.hfile.Cacheable", "org.apache.hadoop.hbase.io.hfile.InclusiveCombinedBlockCache.getBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, boolean, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.io.hfile.InclusiveCombinedBlockCache.cacheBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable, boolean, boolean)"], ["org.apache.hadoop.hbase.io.MetricsIOWrapperImpl", "org.apache.hadoop.hbase.io.MetricsIOWrapperImpl()"], ["long", "org.apache.hadoop.hbase.io.MetricsIOWrapperImpl.getChecksumFailures()"], ["org.apache.hadoop.hbase.io.Reference$Range[]", "org.apache.hadoop.hbase.io.Reference$Range.values()"], ["org.apache.hadoop.hbase.io.Reference$Range", "org.apache.hadoop.hbase.io.Reference$Range.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.ipc.RpcServer$Call", "org.apache.hadoop.hbase.ipc.CallRunner.getCall()"], ["void", "org.apache.hadoop.hbase.ipc.CallRunner.setStatus(org.apache.hadoop.hbase.monitoring.MonitoredRPCHandler)"], ["void", "org.apache.hadoop.hbase.ipc.CallRunner.run()"], ["void", "org.apache.hadoop.hbase.ipc.CallRunner.drop()"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor$1.getNextQueue()"], ["org.apache.hadoop.hbase.ipc.RpcScheduler", "org.apache.hadoop.hbase.ipc.RpcScheduler()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.startAdd()"], ["synchronized", "org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.java.nio.channels.SelectionKey registerChannel(java.nio.channels.SocketChannel)"], ["synchronized", "org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.void finishAdd()"], ["org.apache.hadoop.hbase.ipc.SimpleRpcScheduler", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler(org.apache.hadoop.conf.Configuration, int, int, int, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.hbase.Abortable, int)"], ["org.apache.hadoop.hbase.ipc.SimpleRpcScheduler", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler(org.apache.hadoop.conf.Configuration, int, int, int, org.apache.hadoop.hbase.ipc.PriorityFunction, int)"], ["void", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.init(org.apache.hadoop.hbase.ipc.RpcScheduler$Context)"], ["void", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.start()"], ["void", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.stop()"], ["boolean", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.dispatch(org.apache.hadoop.hbase.ipc.CallRunner)"], ["void", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getGeneralQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getPriorityQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getReplicationQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getActiveRpcHandlerCount()"], ["long", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getNumGeneralCallsDropped()"], ["long", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getNumLifoModeSwitches()"], ["int", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getWriteQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getReadQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getScanQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getActiveWriteRpcHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getActiveReadRpcHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.getActiveScanRpcHandlerCount()"], ["org.apache.hadoop.hbase.LocalHBaseCluster", "org.apache.hadoop.hbase.LocalHBaseCluster(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.LocalHBaseCluster", "org.apache.hadoop.hbase.LocalHBaseCluster(org.apache.hadoop.conf.Configuration, int)"], ["org.apache.hadoop.hbase.LocalHBaseCluster", "org.apache.hadoop.hbase.LocalHBaseCluster(org.apache.hadoop.conf.Configuration, int, int)"], ["org.apache.hadoop.hbase.LocalHBaseCluster", "org.apache.hadoop.hbase.LocalHBaseCluster(org.apache.hadoop.conf.Configuration, int, int, java.lang.Class<? extends org.apache.hadoop.hbase.master.HMaster>, java.lang.Class<? extends org.apache.hadoop.hbase.regionserver.HRegionServer>)"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread", "org.apache.hadoop.hbase.LocalHBaseCluster.addRegionServer()"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread", "org.apache.hadoop.hbase.LocalHBaseCluster.addRegionServer(org.apache.hadoop.conf.Configuration, int)"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread", "org.apache.hadoop.hbase.LocalHBaseCluster.addRegionServer(org.apache.hadoop.conf.Configuration, int, org.apache.hadoop.hbase.security.User)"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread", "org.apache.hadoop.hbase.LocalHBaseCluster.addMaster()"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread", "org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(org.apache.hadoop.conf.Configuration, int)"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread", "org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(org.apache.hadoop.conf.Configuration, int, org.apache.hadoop.hbase.security.User)"], ["org.apache.hadoop.hbase.regionserver.HRegionServer", "org.apache.hadoop.hbase.LocalHBaseCluster.getRegionServer(int)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.LocalHBaseCluster.getConfiguration()"], ["java.lang.String", "org.apache.hadoop.hbase.LocalHBaseCluster.waitOnRegionServer(int)"], ["java.lang.String", "org.apache.hadoop.hbase.LocalHBaseCluster.waitOnRegionServer(org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread)"], ["org.apache.hadoop.hbase.master.HMaster", "org.apache.hadoop.hbase.LocalHBaseCluster.getMaster(int)"], ["org.apache.hadoop.hbase.master.HMaster", "org.apache.hadoop.hbase.LocalHBaseCluster.getActiveMaster()"], ["java.lang.String", "org.apache.hadoop.hbase.LocalHBaseCluster.waitOnMaster(int)"], ["java.lang.String", "org.apache.hadoop.hbase.LocalHBaseCluster.waitOnMaster(org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread)"], ["void", "org.apache.hadoop.hbase.LocalHBaseCluster.join()"], ["void", "org.apache.hadoop.hbase.LocalHBaseCluster.startup()"], ["void", "org.apache.hadoop.hbase.LocalHBaseCluster.shutdown()"], ["boolean", "org.apache.hadoop.hbase.LocalHBaseCluster.isLocal(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.LocalHBaseCluster.main(java.lang.String[])"], ["org.apache.hadoop.hbase.mapred.MultiTableSnapshotInputFormat", "org.apache.hadoop.hbase.mapred.MultiTableSnapshotInputFormat()"], ["org.apache.hadoop.mapred.InputSplit[]", "org.apache.hadoop.hbase.mapred.MultiTableSnapshotInputFormat.getSplits(org.apache.hadoop.mapred.JobConf, int)"], ["org.apache.hadoop.mapred.RecordReader<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>", "org.apache.hadoop.hbase.mapred.MultiTableSnapshotInputFormat.getRecordReader(org.apache.hadoop.mapred.InputSplit, org.apache.hadoop.mapred.JobConf, org.apache.hadoop.mapred.Reporter)"], ["void", "org.apache.hadoop.hbase.mapred.MultiTableSnapshotInputFormat.setInput(org.apache.hadoop.conf.Configuration, java.util.Map<java.lang.String, java.util.Collection<org.apache.hadoop.hbase.client.Scan>>, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.mapred.TableOutputFormat", "org.apache.hadoop.hbase.mapred.TableOutputFormat()"], ["org.apache.hadoop.mapred.RecordWriter", "org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.mapred.JobConf, java.lang.String, org.apache.hadoop.util.Progressable)"], ["void", "org.apache.hadoop.hbase.mapred.TableOutputFormat.checkOutputSpecs(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.mapred.JobConf)"], ["org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat()"], ["org.apache.hadoop.mapred.InputSplit[]", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat.getSplits(org.apache.hadoop.mapred.JobConf, int)"], ["org.apache.hadoop.mapred.RecordReader<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat.getRecordReader(org.apache.hadoop.mapred.InputSplit, org.apache.hadoop.mapred.JobConf, org.apache.hadoop.mapred.Reporter)"], ["void", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat.setInput(org.apache.hadoop.mapred.JobConf, java.lang.String, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat.setInput(org.apache.hadoop.mapred.JobConf, java.lang.String, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.RegionSplitter$SplitAlgorithm, int)"], ["int", "org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver$1.getLabelOrdinal(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver$1.getLabel(int)"], ["org.apache.hadoop.hbase.mapreduce.Export", "org.apache.hadoop.hbase.mapreduce.Export()"], ["org.apache.hadoop.mapreduce.Job", "org.apache.hadoop.hbase.mapreduce.Export.createSubmittableJob(org.apache.hadoop.conf.Configuration, java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.Export.main(java.lang.String[])"], ["org.apache.hadoop.hbase.mapreduce.HLogInputFormat", "org.apache.hadoop.hbase.mapreduce.HLogInputFormat()"], ["org.apache.hadoop.mapreduce.RecordReader<org.apache.hadoop.hbase.regionserver.wal.HLogKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit>", "org.apache.hadoop.hbase.mapreduce.HLogInputFormat.createRecordReader(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["org.apache.hadoop.hbase.mapreduce.IdentityTableReducer", "org.apache.hadoop.hbase.mapreduce.IdentityTableReducer()"], ["void", "org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.reduce(org.apache.hadoop.io.Writable, java.lang.Iterable<org.apache.hadoop.hbase.client.Mutation>, org.apache.hadoop.mapreduce.Reducer<org.apache.hadoop.io.Writable, org.apache.hadoop.hbase.client.Mutation, org.apache.hadoop.io.Writable, org.apache.hadoop.hbase.client.Mutation>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.reduce(java.lang.Object, java.lang.Iterable, org.apache.hadoop.mapreduce.Reducer$Context)"], ["org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$BadTsvLineException", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$BadTsvLineException(java.lang.String)"], ["org.apache.hadoop.hbase.mapreduce.KeyValueSerialization", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization.accept(java.lang.Class<?>)"], ["org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueDeserializer", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization.getDeserializer(java.lang.Class<org.apache.hadoop.hbase.KeyValue>)"], ["org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueSerializer", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization.getSerializer(java.lang.Class<org.apache.hadoop.hbase.KeyValue>)"], ["org.apache.hadoop.io.serializer.Deserializer", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization.getDeserializer(java.lang.Class)"], ["org.apache.hadoop.io.serializer.Serializer", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization.getSerializer(java.lang.Class)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$MapRunner.run()"], ["void", "org.apache.hadoop.hbase.mapreduce.MutationSerialization$MutationSerializer.close()"], ["void", "org.apache.hadoop.hbase.mapreduce.MutationSerialization$MutationSerializer.open(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.mapreduce.MutationSerialization$MutationSerializer.serialize(org.apache.hadoop.hbase.client.Mutation)"], ["void", "org.apache.hadoop.hbase.mapreduce.MutationSerialization$MutationSerializer.serialize(java.lang.Object)"], ["void", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$Result94Deserializer.close()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$Result94Deserializer.deserialize(org.apache.hadoop.hbase.client.Result)"], ["void", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$Result94Deserializer.open(java.io.InputStream)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$Result94Deserializer.deserialize(java.lang.Object)"], ["void", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$ResultDeserializer.close()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$ResultDeserializer.deserialize(org.apache.hadoop.hbase.client.Result)"], ["void", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$ResultDeserializer.open(java.io.InputStream)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$ResultDeserializer.deserialize(java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.RowCounter$RowCounterMapper$Counters[]", "org.apache.hadoop.hbase.mapreduce.RowCounter$RowCounterMapper$Counters.values()"], ["org.apache.hadoop.hbase.mapreduce.RowCounter$RowCounterMapper$Counters", "org.apache.hadoop.hbase.mapreduce.RowCounter$RowCounterMapper$Counters.valueOf(java.lang.String)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase$1.close()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase$1.getCurrentKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase$1.getCurrentValue()"], ["float", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase$1.getProgress()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase$1.initialize(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase$1.nextKeyValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase$1.getCurrentValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase$1.getCurrentKey()"], ["org.apache.hadoop.hbase.mapreduce.TableOutputFormat$TableRecordWriter", "org.apache.hadoop.hbase.mapreduce.TableOutputFormat$TableRecordWriter(org.apache.hadoop.hbase.mapreduce.TableOutputFormat)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputFormat$TableRecordWriter.close(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputFormat$TableRecordWriter.write(KEY, org.apache.hadoop.hbase.client.Mutation)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputFormat$TableRecordWriter.write(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl", "org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.restart(byte[])"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.setHTable(org.apache.hadoop.hbase.client.Table)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.setScan(org.apache.hadoop.hbase.client.Scan)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.initialize(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.close()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.getCurrentKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.getCurrentValue()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.nextKeyValue()"], ["float", "org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.getProgress()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$11.process()"], ["int", "org.apache.hadoop.hbase.master.AssignmentManager$8.compare(org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.ServerName, java.lang.String>, org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.ServerName, java.lang.String>)"], ["int", "org.apache.hadoop.hbase.master.AssignmentManager$8.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$MoveRegionAction", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$MoveRegionAction(int, int, int)"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$MoveRegionAction.undoAction()"], ["java.lang.String", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$MoveRegionAction.toString()"], ["org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan$Position[]", "org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan$Position.values()"], ["org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan$Position", "org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan$Position.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.master.balancer.MetricsBalancer", "org.apache.hadoop.hbase.master.balancer.MetricsBalancer()"], ["void", "org.apache.hadoop.hbase.master.balancer.MetricsBalancer.balanceCluster(long)"], ["void", "org.apache.hadoop.hbase.master.balancer.MetricsBalancer.incrMiscInvocations()"], ["int", "org.apache.hadoop.hbase.master.balancer.RegionInfoComparator.compare(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["int", "org.apache.hadoop.hbase.master.balancer.RegionInfoComparator.compare(java.lang.Object, java.lang.Object)"], ["int", "org.apache.hadoop.hbase.master.balancer.ServerAndLoad.compareTo(org.apache.hadoop.hbase.master.balancer.ServerAndLoad)"], ["int", "org.apache.hadoop.hbase.master.balancer.ServerAndLoad.hashCode()"], ["boolean", "org.apache.hadoop.hbase.master.balancer.ServerAndLoad.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.master.balancer.ServerAndLoad.compareTo(java.lang.Object)"], ["void", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer$LocalityBasedCostFunction.setServices(org.apache.hadoop.hbase.master.MasterServices)"], ["void", "org.apache.hadoop.hbase.master.BulkReOpen$1.run()"], ["org.apache.hadoop.hbase.master.cleaner.BaseFileCleanerDelegate", "org.apache.hadoop.hbase.master.cleaner.BaseFileCleanerDelegate()"], ["org.apache.hadoop.hbase.master.cleaner.LogCleaner", "org.apache.hadoop.hbase.master.cleaner.LogCleaner(int, org.apache.hadoop.hbase.Stoppable, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.master.cleaner.LogCleaner.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["synchronized", "org.apache.hadoop.hbase.master.cleaner.LogCleaner.void cleanup()"], ["synchronized", "org.apache.hadoop.hbase.master.cleaner.LogCleaner.void cancel(boolean)"], ["org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner", "org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.Abortable)"], ["java.util.Map<java.lang.String, java.util.List<java.lang.String>>", "org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner.getUnDeletedQueues()"], ["void", "org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner.removeQueues(java.util.Map<java.lang.String, java.util.List<java.lang.String>>)"], ["void", "org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner.removeHFileRefsQueues(java.util.Set<java.lang.String>)"], ["org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher", "org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher()"], ["void", "org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher.connect(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher.publish(org.apache.hadoop.hbase.ClusterStatus)"], ["void", "org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher.close()"], ["org.apache.hadoop.hbase.master.handler.ClosedRegionHandler", "org.apache.hadoop.hbase.master.handler.ClosedRegionHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.master.AssignmentManager, org.apache.hadoop.hbase.HRegionInfo)"], ["int", "org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.getPriority()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.getHRegionInfo()"], ["java.lang.String", "org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.toString()"], ["void", "org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.process()"], ["org.apache.hadoop.hbase.master.handler.OpenedRegionHandler$OpenedPriority[]", "org.apache.hadoop.hbase.master.handler.OpenedRegionHandler$OpenedPriority.values()"], ["org.apache.hadoop.hbase.master.handler.OpenedRegionHandler$OpenedPriority", "org.apache.hadoop.hbase.master.handler.OpenedRegionHandler$OpenedPriority.valueOf(java.lang.String)"], ["int", "org.apache.hadoop.hbase.master.handler.OpenedRegionHandler$OpenedPriority.getValue()"], ["org.apache.hadoop.hbase.master.MasterAnnotationReadingPriorityFunction", "org.apache.hadoop.hbase.master.MasterAnnotationReadingPriorityFunction(org.apache.hadoop.hbase.regionserver.RSRpcServices)"], ["org.apache.hadoop.hbase.master.MasterAnnotationReadingPriorityFunction", "org.apache.hadoop.hbase.master.MasterAnnotationReadingPriorityFunction(org.apache.hadoop.hbase.regionserver.RSRpcServices, java.lang.Class<? extends org.apache.hadoop.hbase.regionserver.RSRpcServices>)"], ["int", "org.apache.hadoop.hbase.master.MasterAnnotationReadingPriorityFunction.getPriority(org.apache.hadoop.hbase.protobuf.generated.RPCProtos$RequestHeader, com.google.protobuf.Message, org.apache.hadoop.hbase.security.User)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$100.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$111.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$13.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$2.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$31.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$39.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$40.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$59.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$61.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$69.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$70.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$88.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$95.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer", "org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer()"], ["void", "org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.setMasterServices(org.apache.hadoop.hbase.master.MasterServices)"], ["void", "org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.setMasterRpcServices(org.apache.hadoop.hbase.master.MasterRpcServices)"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure$2.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure$2.run()"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure$1.run()"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure$1.run()"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv$MasterProcedureStoreListener", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv$MasterProcedureStoreListener(org.apache.hadoop.hbase.master.HMaster)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv$MasterProcedureStoreListener.postSync()"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv$MasterProcedureStoreListener.abortProcess()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv$WALStoreLeaseRecovery$1.progress()"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent.boolean isReady()"], ["java.lang.String", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent.toString()"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure$1.run()"], ["org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure", "org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure()"], ["org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure", "org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.deserializeStateData(java.io.InputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.abort(java.lang.Object)"], ["org.apache.hadoop.hbase.master.RegionPlacementMaintainer$RandomizedMatrix", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer$RandomizedMatrix(int, int)"], ["float[][]", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer$RandomizedMatrix.transform(float[][])"], ["float[][]", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer$RandomizedMatrix.invert(float[][])"], ["int[]", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer$RandomizedMatrix.invertIndices(int[])"], ["void", "org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler$1.editRegion(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$SnapshotDirectoryInfo", "org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$SnapshotDirectoryInfo(long, java.util.Collection<java.lang.String>)"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$SnapshotDirectoryInfo.hasBeenModified(long)"], ["org.apache.hadoop.hbase.master.snapshot.SnapshotManager", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager()"], ["org.apache.hadoop.hbase.master.snapshot.SnapshotManager", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.master.MetricsMaster, org.apache.hadoop.hbase.procedure.ProcedureCoordinator, org.apache.hadoop.hbase.executor.ExecutorService)"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.deleteSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.isSnapshotDone(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.takeSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["synchronized", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.void setSnapshotHandlerForTesting(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.master.SnapshotSentinel)"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.restoreSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.restoreSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, boolean)"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.isRestoreDone(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.isStopped()"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.checkSnapshotSupport()"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.initialize(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.master.MetricsMaster)"], ["java.lang.String", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.getProcedureSignature()"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.execProcedure(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$ProcedureDescription)"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.SnapshotManager.isProcedureDone(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$ProcedureDescription)"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$NullTableLockManager$NullTableLock.acquire()"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$NullTableLockManager$NullTableLock.release()"], ["org.apache.hadoop.hbase.master.TableNamespaceManager", "org.apache.hadoop.hbase.master.TableNamespaceManager(org.apache.hadoop.hbase.master.MasterServices)"], ["void", "org.apache.hadoop.hbase.master.TableNamespaceManager.start()"], ["boolean", "org.apache.hadoop.hbase.master.TableNamespaceManager.doesNamespaceExist(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.master.TableNamespaceManager.org.apache.hadoop.hbase.NamespaceDescriptor get(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.TableNamespaceManager.insertIntoNSTable(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.master.TableNamespaceManager.updateZKNamespaceManager(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.master.TableNamespaceManager.removeFromNSTable(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.TableNamespaceManager.removeFromZKNamespaceManager(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.master.TableNamespaceManager.boolean isTableAvailableAndInitialized(boolean)"], ["void", "org.apache.hadoop.hbase.master.TableNamespaceManager.validateTableAndRegionCount(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["long", "org.apache.hadoop.hbase.master.TableNamespaceManager.getMaxTables(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["long", "org.apache.hadoop.hbase.master.TableNamespaceManager.getMaxRegions(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["org.apache.hadoop.hbase.monitoring.MonitoredTask$State[]", "org.apache.hadoop.hbase.monitoring.MonitoredTask$State.values()"], ["org.apache.hadoop.hbase.monitoring.MonitoredTask$State", "org.apache.hadoop.hbase.monitoring.MonitoredTask$State.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.monitoring.StateDumpServlet", "org.apache.hadoop.hbase.monitoring.StateDumpServlet()"], ["org.apache.hadoop.hbase.monitoring.ThreadMonitoring", "org.apache.hadoop.hbase.monitoring.ThreadMonitoring()"], ["java.lang.management.ThreadInfo", "org.apache.hadoop.hbase.monitoring.ThreadMonitoring.getThreadInfo(java.lang.Thread)"], ["java.lang.String", "org.apache.hadoop.hbase.monitoring.ThreadMonitoring.formatThreadInfo(java.lang.management.ThreadInfo, java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.ThreadMonitoring.appendThreadInfo(java.lang.StringBuilder, java.lang.management.ThreadInfo, java.lang.String)"], ["org.apache.hadoop.hbase.namespace.NamespaceTableAndRegionInfo", "org.apache.hadoop.hbase.namespace.NamespaceTableAndRegionInfo(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.namespace.NamespaceTableAndRegionInfo.toString()"], ["org.apache.hadoop.hbase.procedure.Procedure", "org.apache.hadoop.hbase.procedure.Procedure(org.apache.hadoop.hbase.procedure.ProcedureCoordinator, org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher, long, long, java.lang.String, byte[], java.util.List<java.lang.String>)"], ["org.apache.hadoop.hbase.procedure.Procedure", "org.apache.hadoop.hbase.procedure.Procedure(org.apache.hadoop.hbase.procedure.ProcedureCoordinator, long, long, java.lang.String, byte[], java.util.List<java.lang.String>)"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.Procedure.getName()"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.Procedure.getStatus()"], ["org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher", "org.apache.hadoop.hbase.procedure.Procedure.getErrorMonitor()"], ["java.lang.Void", "org.apache.hadoop.hbase.procedure.Procedure.call()"], ["void", "org.apache.hadoop.hbase.procedure.Procedure.sendGlobalBarrierStart()"], ["void", "org.apache.hadoop.hbase.procedure.Procedure.sendGlobalBarrierReached()"], ["void", "org.apache.hadoop.hbase.procedure.Procedure.sendGlobalBarrierComplete()"], ["void", "org.apache.hadoop.hbase.procedure.Procedure.barrierAcquiredByMember(java.lang.String)"], ["void", "org.apache.hadoop.hbase.procedure.Procedure.barrierReleasedByMember(java.lang.String, byte[])"], ["void", "org.apache.hadoop.hbase.procedure.Procedure.waitForCompleted()"], ["java.util.HashMap<java.lang.String, byte[]>", "org.apache.hadoop.hbase.procedure.Procedure.waitForCompletedWithRet()"], ["boolean", "org.apache.hadoop.hbase.procedure.Procedure.isCompleted()"], ["void", "org.apache.hadoop.hbase.procedure.Procedure.receive(org.apache.hadoop.hbase.errorhandling.ForeignException)"], ["void", "org.apache.hadoop.hbase.procedure.Procedure.waitForLatch(java.util.concurrent.CountDownLatch, org.apache.hadoop.hbase.errorhandling.ForeignExceptionSnare, long, java.lang.String)"], ["java.lang.Object", "org.apache.hadoop.hbase.procedure.Procedure.call()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil$1.current()"], ["boolean", "org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil$1.advance()"], ["long", "org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil$1.heapSize()"], ["org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$2.fetch()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$2.update(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$2.delete()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$2.preApply(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$2.postApply(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$5.fetch()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$5.update(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$5.delete()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$5.preApply(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$5.postApply(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["org.apache.hadoop.hbase.quotas.QuotaUtil", "org.apache.hadoop.hbase.quotas.QuotaUtil()"], ["boolean", "org.apache.hadoop.hbase.quotas.QuotaUtil.isQuotaEnabled(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil.addTableQuota(org.apache.hadoop.hbase.client.Connection, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil.deleteTableQuota(org.apache.hadoop.hbase.client.Connection, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil.addNamespaceQuota(org.apache.hadoop.hbase.client.Connection, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil.deleteNamespaceQuota(org.apache.hadoop.hbase.client.Connection, java.lang.String)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil.addUserQuota(org.apache.hadoop.hbase.client.Connection, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil.addUserQuota(org.apache.hadoop.hbase.client.Connection, java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil.addUserQuota(org.apache.hadoop.hbase.client.Connection, java.lang.String, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil.deleteUserQuota(org.apache.hadoop.hbase.client.Connection, java.lang.String)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil.deleteUserQuota(org.apache.hadoop.hbase.client.Connection, java.lang.String, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil.deleteUserQuota(org.apache.hadoop.hbase.client.Connection, java.lang.String, java.lang.String)"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.quotas.UserQuotaState>", "org.apache.hadoop.hbase.quotas.QuotaUtil.fetchUserQuotas(org.apache.hadoop.hbase.client.Connection, java.util.List<org.apache.hadoop.hbase.client.Get>)"], ["java.util.Map<org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.quotas.QuotaState>", "org.apache.hadoop.hbase.quotas.QuotaUtil.fetchTableQuotas(org.apache.hadoop.hbase.client.Connection, java.util.List<org.apache.hadoop.hbase.client.Get>)"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.quotas.QuotaState>", "org.apache.hadoop.hbase.quotas.QuotaUtil.fetchNamespaceQuotas(org.apache.hadoop.hbase.client.Connection, java.util.List<org.apache.hadoop.hbase.client.Get>)"], ["<K> java.util.Map<K, org.apache.hadoop.hbase.quotas.QuotaState>", "org.apache.hadoop.hbase.quotas.QuotaUtil.fetchGlobalQuotas(java.lang.String, org.apache.hadoop.hbase.client.Connection, java.util.List<org.apache.hadoop.hbase.client.Get>, org.apache.hadoop.hbase.quotas.QuotaUtil$KeyFromRow<K>)"], ["long", "org.apache.hadoop.hbase.quotas.QuotaUtil.calculateMutationSize(org.apache.hadoop.hbase.client.Mutation)"], ["long", "org.apache.hadoop.hbase.quotas.QuotaUtil.calculateResultSize(org.apache.hadoop.hbase.client.Result)"], ["long", "org.apache.hadoop.hbase.quotas.QuotaUtil.calculateResultSize(java.util.List<org.apache.hadoop.hbase.client.Result>)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.toString()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getMinCompactSize()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getMaxCompactSize()"], ["int", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getMinFilesToCompact()"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.setMinFilesToCompact(int)"], ["int", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getMaxFilesToCompact()"], ["double", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getCompactionRatio()"], ["double", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getCompactionRatioOffPeak()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getThrottlePoint()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getMajorCompactionPeriod()"], ["float", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getMajorCompactionJitter()"], ["float", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getMinLocalityToForceCompact()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getOffPeakMaxCompactSize()"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getMaxCompactSize(boolean)"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getDateTieredMaxStoreFileAgeMillis()"], ["int", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getDateTieredIncomingWindowMin()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getCompactionPolicyForDateTieredWindow()"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.useDateTieredSingleOutputForMinorCompaction()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.getDateTieredCompactionWindowFactory()"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.regionserver.compactions.Compactor$3.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.compactions.Compactor$3.run()"], ["org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor", "org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.Store)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy$1.apply(org.apache.hadoop.hbase.regionserver.StoreFile)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy$1.apply(java.lang.Object)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionMapper.setup(org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.io.LongWritable, org.apache.hadoop.io.Text, org.apache.hadoop.io.NullWritable, org.apache.hadoop.io.NullWritable>.Context)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionMapper.map(org.apache.hadoop.io.LongWritable, org.apache.hadoop.io.Text, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.io.LongWritable, org.apache.hadoop.io.Text, org.apache.hadoop.io.NullWritable, org.apache.hadoop.io.NullWritable>.Context)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["java.lang.Thread", "org.apache.hadoop.hbase.regionserver.CompactSplitThread$2.newThread(java.lang.Runnable)"], ["java.lang.Thread", "org.apache.hadoop.hbase.regionserver.CompactSplitThread$4.newThread(java.lang.Runnable)"], ["org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerResult", "org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.tune(org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.getConf()"], ["void", "org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.DeleteTracker$DeleteCompare[]", "org.apache.hadoop.hbase.regionserver.DeleteTracker$DeleteCompare.values()"], ["org.apache.hadoop.hbase.regionserver.DeleteTracker$DeleteCompare", "org.apache.hadoop.hbase.regionserver.DeleteTracker$DeleteCompare.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.FlushLargeStoresPolicy", "org.apache.hadoop.hbase.regionserver.FlushLargeStoresPolicy()"], ["org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler", "org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.HRegionInfo, boolean, org.apache.hadoop.hbase.coordination.CloseRegionCoordination, org.apache.hadoop.hbase.coordination.CloseRegionCoordination$CloseRegionDetails)"], ["org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler", "org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, long, org.apache.hadoop.hbase.coordination.OpenRegionCoordination, org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails)"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.getRegionInfo()"], ["void", "org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process()"], ["org.apache.hadoop.hbase.regionserver.HStore", "org.apache.hadoop.hbase.regionserver.HRegion$1.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.HRegion$1.call()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.getRegionInfo()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.getMaxResultSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.getMvccReadPoint()"], ["int", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.getBatch()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(java.util.List<org.apache.hadoop.hbase.Cell>)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.boolean next(java.util.List<org.apache.hadoop.hbase.Cell>, org.apache.hadoop.hbase.regionserver.ScannerContext)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(java.util.List<org.apache.hadoop.hbase.Cell>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(java.util.List<org.apache.hadoop.hbase.Cell>, org.apache.hadoop.hbase.regionserver.ScannerContext)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.boolean isFilterDone()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.void close()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.boolean reseek(byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer$MovedRegionsCleaner.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer$MovedRegionsCleaner.isStopped()"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.HStore$3.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.HStore$3.run()"], ["org.apache.hadoop.hbase.regionserver.InternalScan", "org.apache.hadoop.hbase.regionserver.InternalScan(org.apache.hadoop.hbase.client.Get)"], ["org.apache.hadoop.hbase.regionserver.InternalScan", "org.apache.hadoop.hbase.regionserver.InternalScan(org.apache.hadoop.hbase.client.Scan)"], ["void", "org.apache.hadoop.hbase.regionserver.InternalScan.checkOnlyMemStore()"], ["void", "org.apache.hadoop.hbase.regionserver.InternalScan.checkOnlyStoreFiles()"], ["boolean", "org.apache.hadoop.hbase.regionserver.InternalScan.isCheckOnlyMemStore()"], ["boolean", "org.apache.hadoop.hbase.regionserver.InternalScan.isCheckOnlyStoreFiles()"], ["org.apache.hadoop.hbase.regionserver.Leases$LeaseStillHeldException", "org.apache.hadoop.hbase.regionserver.Leases$LeaseStillHeldException(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.Leases$LeaseStillHeldException.getName()"], ["org.apache.hadoop.hbase.regionserver.LruHashMap", "org.apache.hadoop.hbase.regionserver.LruHashMap(int, float, long)"], ["org.apache.hadoop.hbase.regionserver.LruHashMap", "org.apache.hadoop.hbase.regionserver.LruHashMap(int, float)"], ["org.apache.hadoop.hbase.regionserver.LruHashMap", "org.apache.hadoop.hbase.regionserver.LruHashMap(int)"], ["org.apache.hadoop.hbase.regionserver.LruHashMap", "org.apache.hadoop.hbase.regionserver.LruHashMap(long)"], ["org.apache.hadoop.hbase.regionserver.LruHashMap", "org.apache.hadoop.hbase.regionserver.LruHashMap()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.LruHashMap.long getMemFree()"], ["long", "org.apache.hadoop.hbase.regionserver.LruHashMap.getMemMax()"], ["long", "org.apache.hadoop.hbase.regionserver.LruHashMap.getMemUsed()"], ["long", "org.apache.hadoop.hbase.regionserver.LruHashMap.getHitCount()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.LruHashMap.long getMissCount()"], ["double", "org.apache.hadoop.hbase.regionserver.LruHashMap.getHitRatio()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.LruHashMap.long freeMemory(long)"], ["long", "org.apache.hadoop.hbase.regionserver.LruHashMap.heapSize()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.LruHashMap.V get(java.lang.Object)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.LruHashMap.V put(K, V)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.LruHashMap.V remove(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.regionserver.LruHashMap.size()"], ["boolean", "org.apache.hadoop.hbase.regionserver.LruHashMap.isEmpty()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.LruHashMap.void clear()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.LruHashMap.boolean containsKey(java.lang.Object)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.LruHashMap.boolean containsValue(java.lang.Object)"], ["java.util.List<org.apache.hadoop.hbase.regionserver.LruHashMap$Entry<K, V>>", "org.apache.hadoop.hbase.regionserver.LruHashMap.entryLruList()"], ["java.util.Set<org.apache.hadoop.hbase.regionserver.LruHashMap$Entry<K, V>>", "org.apache.hadoop.hbase.regionserver.LruHashMap.entryTableSet()"], ["org.apache.hadoop.hbase.regionserver.LruHashMap$Entry", "org.apache.hadoop.hbase.regionserver.LruHashMap.getHeadPtr()"], ["org.apache.hadoop.hbase.regionserver.LruHashMap$Entry", "org.apache.hadoop.hbase.regionserver.LruHashMap.getTailPtr()"], ["java.util.Set<java.util.Map$Entry<K, V>>", "org.apache.hadoop.hbase.regionserver.LruHashMap.entrySet()"], ["boolean", "org.apache.hadoop.hbase.regionserver.LruHashMap.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.regionserver.LruHashMap.hashCode()"], ["void", "org.apache.hadoop.hbase.regionserver.LruHashMap.putAll(java.util.Map<? extends K, ? extends V>)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.LruHashMap.remove(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.LruHashMap.put(java.lang.Object, java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.LruHashMap.get(java.lang.Object)"], ["long", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$WakeupFlushThread.getDelay(java.util.concurrent.TimeUnit)"], ["int", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$WakeupFlushThread.compareTo(java.util.concurrent.Delayed)"], ["int", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$WakeupFlushThread.hashCode()"], ["boolean", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$WakeupFlushThread.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$WakeupFlushThread.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.MetricsRegion", "org.apache.hadoop.hbase.regionserver.MetricsRegion(org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegion.close()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegion.updatePut()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegion.updateDelete()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegion.updateGet(long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegion.updateScanTime(long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegion.updateAppend()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegion.updateIncrement()"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper", "org.apache.hadoop.hbase.regionserver.MetricsRegion.getRegionWrapper()"], ["org.apache.hadoop.hbase.regionserver.MetricsTable", "org.apache.hadoop.hbase.regionserver.MetricsTable(org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregate)"], ["org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregate", "org.apache.hadoop.hbase.regionserver.MetricsTable.getTableWrapperAgg()"], ["org.apache.hadoop.hbase.regionserver.MetricsTableAggregateSource", "org.apache.hadoop.hbase.regionserver.MetricsTable.getTableSourceAgg()"], ["org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$TableMetricsWrapperRunnable", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$TableMetricsWrapperRunnable(org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$TableMetricsWrapperRunnable.run()"], ["org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner", "org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner()"], ["boolean", "org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.requestSeek(org.apache.hadoop.hbase.Cell, boolean, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.realSeekDone()"], ["void", "org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.enforceSeek()"], ["boolean", "org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(org.apache.hadoop.hbase.regionserver.KeyValueScanner, org.apache.hadoop.hbase.Cell, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.shouldUseScanner(org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.Store, long)"], ["boolean", "org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.isFileScanner()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.getNextIndexedKey()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$1.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$20.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$28.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$35.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$42.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$5.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$5.postEnvCall(org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$57.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$64.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$71.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionOperationWithResult.setResult(T)"], ["T", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionOperationWithResult.getResult()"], ["org.apache.hadoop.hbase.regionserver.RegionMergeTransactionFactory", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionFactory(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionFactory.getConf()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionFactory.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionFactory.create(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$2.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost(org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$RegionServerEnvironment", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.createEnvironment(java.lang.Class<?>, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.preStop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.preMerge(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.postMerge(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.preMergeCommit(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion, java.util.List<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.postMergeCommit(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.preRollBackMerge(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.postRollBackMerge(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.preRollWALWriterRequest()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.postRollWALWriterRequest()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.preReplicateLogEntries(java.util.List<org.apache.hadoop.hbase.protobuf.generated.AdminProtos$WALEntry>, org.apache.hadoop.hbase.CellScanner)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.postReplicateLogEntries(java.util.List<org.apache.hadoop.hbase.protobuf.generated.AdminProtos$WALEntry>, org.apache.hadoop.hbase.CellScanner)"], ["org.apache.hadoop.hbase.replication.ReplicationEndpoint", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.postCreateReplicationEndPoint(org.apache.hadoop.hbase.replication.ReplicationEndpoint)"], ["org.apache.hadoop.hbase.CoprocessorEnvironment", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.createEnvironment(java.lang.Class, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap$ReversedKVScannerComparator", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap$ReversedKVScannerComparator(org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["int", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap$ReversedKVScannerComparator.compare(org.apache.hadoop.hbase.regionserver.KeyValueScanner, org.apache.hadoop.hbase.regionserver.KeyValueScanner)"], ["int", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap$ReversedKVScannerComparator.compareRows(org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.Cell)"], ["int", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap$ReversedKVScannerComparator.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.RSDumpServlet", "org.apache.hadoop.hbase.regionserver.RSDumpServlet()"], ["void", "org.apache.hadoop.hbase.regionserver.RSDumpServlet.doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["void", "org.apache.hadoop.hbase.regionserver.RSDumpServlet.dumpRowLock(org.apache.hadoop.hbase.regionserver.HRegionServer, java.io.PrintWriter)"], ["void", "org.apache.hadoop.hbase.regionserver.RSDumpServlet.dumpQueue(org.apache.hadoop.hbase.regionserver.HRegionServer, java.io.PrintWriter)"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$LimitScope[]", "org.apache.hadoop.hbase.regionserver.ScannerContext$LimitScope.values()"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$LimitScope", "org.apache.hadoop.hbase.regionserver.ScannerContext$LimitScope.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory", "org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory()"], ["org.apache.hadoop.hbase.ipc.RpcScheduler", "org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.ipc.PriorityFunction)"], ["org.apache.hadoop.hbase.ipc.RpcScheduler", "org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager", "org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager()"], ["void", "org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.start()"], ["void", "org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.stop(boolean)"], ["org.apache.hadoop.hbase.procedure.Subprocedure", "org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.buildSubprocedure(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.initialize(org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.getProcedureSignature()"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$6.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$6.run()"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Comparators", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators()"], ["org.apache.hadoop.hbase.regionserver.StorefileRefresherChore", "org.apache.hadoop.hbase.regionserver.StorefileRefresherChore(int, boolean, org.apache.hadoop.hbase.regionserver.HRegionServer, org.apache.hadoop.hbase.Stoppable)"], ["org.apache.hadoop.hbase.regionserver.StoreUtils", "org.apache.hadoop.hbase.regionserver.StoreUtils()"], ["java.lang.Integer", "org.apache.hadoop.hbase.regionserver.StoreUtils.getDeterministicRandomSeed(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreUtils.hasReferences(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["long", "org.apache.hadoop.hbase.regionserver.StoreUtils.getLowestTimestamp(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$SizeStripeFlushRequest", "org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$SizeStripeFlushRequest(org.apache.hadoop.hbase.KeyValue$KVComparator, int, long)"], ["org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter", "org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$SizeStripeFlushRequest.createWriter()"], ["int", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$1.compare(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["int", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$1.compare(java.lang.Object, java.lang.Object)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.toString()"], ["long", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.trailerSize()"], ["org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.close()"], ["long", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.getPosition()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.reset()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.init(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FSDataInputStream)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.getCodecClsName()"], ["org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.crypto.Encryptor)"], ["org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.crypto.Decryptor)"], ["org.apache.hadoop.hbase.codec.Codec$Decoder", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec.getDecoder(java.io.InputStream)"], ["org.apache.hadoop.hbase.codec.Codec$Encoder", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec.getEncoder(java.io.OutputStream)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec.getCodec(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.crypto.Encryptor)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec.getCodec(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.crypto.Decryptor)"], ["byte[]", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$1.uncompress(com.google.protobuf.ByteString, org.apache.hadoop.hbase.io.util.Dictionary)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec()"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.getWALCellCodecClass(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.create(org.apache.hadoop.conf.Configuration, java.lang.String, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["org.apache.hadoop.hbase.codec.Codec$Decoder", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.getDecoder(java.io.InputStream)"], ["org.apache.hadoop.hbase.codec.Codec$Encoder", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.getEncoder(java.io.OutputStream)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$ByteStringCompressor", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.getByteStringCompressor()"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$ByteStringUncompressor", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.getByteStringUncompressor()"], ["org.apache.hadoop.hbase.replication.BaseReplicationEndpoint", "org.apache.hadoop.hbase.replication.BaseReplicationEndpoint()"], ["void", "org.apache.hadoop.hbase.replication.BaseReplicationEndpoint.init(org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context)"], ["void", "org.apache.hadoop.hbase.replication.BaseReplicationEndpoint.peerConfigUpdated(org.apache.hadoop.hbase.replication.ReplicationPeerConfig)"], ["org.apache.hadoop.hbase.replication.WALEntryFilter", "org.apache.hadoop.hbase.replication.BaseReplicationEndpoint.getWALEntryfilter()"], ["boolean", "org.apache.hadoop.hbase.replication.BaseReplicationEndpoint.canReplicateToSameCluster()"], ["org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner", "org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner()"], ["void", "org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner.setConf(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner.setConf(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["void", "org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner.isStopped()"], ["boolean", "org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner.isFileDeletable(org.apache.hadoop.fs.FileStatus)"], ["org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues.main(java.lang.String[])"], ["int", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues.run(java.lang.String[])"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues.dumpReplicationSummary()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues.dumpPeersState(org.apache.hadoop.hbase.client.replication.ReplicationAdmin, java.util.Map<java.lang.String, org.apache.hadoop.hbase.replication.ReplicationPeerConfig>)"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues.dumpQueues(org.apache.hadoop.hbase.client.ClusterConnection, java.util.Set<java.lang.String>, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, boolean)"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$SkipReplayedEditsFilter.filter(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager$SinkPeer", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager$SinkPeer(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingInterface)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingInterface", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager$SinkPeer.getRegionServer()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$WorkerState[]", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$WorkerState.values()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$WorkerState", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$WorkerState.valueOf(java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread$WALEntryBatch.addEntry(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread$WALEntryBatch.getLastWalPath()"], ["long", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread$WALEntryBatch.getLastWalPosition()"], ["int", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread$WALEntryBatch.getNbEntries()"], ["int", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread$WALEntryBatch.getNbRowKeys()"], ["int", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread$WALEntryBatch.getNbHFiles()"], ["int", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread$WALEntryBatch.getNbOperations()"], ["long", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread$WALEntryBatch.getHeapSize()"], ["java.util.Map<java.lang.String, java.lang.Long>", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread$WALEntryBatch.getLastSeqIds()"], ["boolean", "org.apache.hadoop.hbase.replication.ScopeWALEntryFilter$1.apply(byte[])"], ["boolean", "org.apache.hadoop.hbase.replication.ScopeWALEntryFilter$1.apply(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$10.run()"], ["java.lang.Void", "org.apache.hadoop.hbase.security.access.AccessController$5.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$5.run()"], ["org.apache.hadoop.hbase.security.access.AuthResult$Params", "org.apache.hadoop.hbase.security.access.AuthResult$Params()"], ["org.apache.hadoop.hbase.security.access.AuthResult$Params", "org.apache.hadoop.hbase.security.access.AuthResult$Params.setNamespace(java.lang.String)"], ["org.apache.hadoop.hbase.security.access.AuthResult$Params", "org.apache.hadoop.hbase.security.access.AuthResult$Params.setTableName(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.security.access.AuthResult$Params", "org.apache.hadoop.hbase.security.access.AuthResult$Params.setFamilies(java.util.Map<byte[], ? extends java.util.Collection<?>>)"], ["org.apache.hadoop.hbase.security.access.AuthResult$Params", "org.apache.hadoop.hbase.security.access.AuthResult$Params.setFamily(byte[])"], ["org.apache.hadoop.hbase.security.access.AuthResult$Params", "org.apache.hadoop.hbase.security.access.AuthResult$Params.setQualifier(byte[])"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.AuthResult$Params.toString()"], ["java.lang.Boolean", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$1.run()"], ["org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint()"], ["void", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.prepareBulkLoad(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos$PrepareBulkLoadRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos$PrepareBulkLoadResponse>)"], ["void", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.cleanupBulkLoad(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos$CleanupBulkLoadRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos$CleanupBulkLoadResponse>)"], ["void", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.secureBulkLoadHFiles(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos$SecureBulkLoadHFilesRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos$SecureBulkLoadHFilesResponse>)"], ["com.google.protobuf.Service", "org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.getService()"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher$5.run()"], ["org.apache.hadoop.hbase.security.HBasePolicyProvider", "org.apache.hadoop.hbase.security.HBasePolicyProvider()"], ["org.apache.hadoop.security.authorize.Service[]", "org.apache.hadoop.hbase.security.HBasePolicyProvider.getServices()"], ["void", "org.apache.hadoop.hbase.security.HBasePolicyProvider.init(org.apache.hadoop.conf.Configuration, org.apache.hadoop.security.authorize.ServiceAuthorizationManager)"], ["org.apache.hadoop.hbase.security.token.ZKSecretWatcher", "org.apache.hadoop.hbase.security.token.ZKSecretWatcher(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager)"], ["void", "org.apache.hadoop.hbase.security.token.ZKSecretWatcher.start()"], ["void", "org.apache.hadoop.hbase.security.token.ZKSecretWatcher.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.token.ZKSecretWatcher.nodeDeleted(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.token.ZKSecretWatcher.nodeDataChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.token.ZKSecretWatcher.nodeChildrenChanged(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.security.token.ZKSecretWatcher.getRootKeyZNode()"], ["void", "org.apache.hadoop.hbase.security.token.ZKSecretWatcher.removeKeyFromZK(org.apache.hadoop.hbase.security.token.AuthenticationKey)"], ["void", "org.apache.hadoop.hbase.security.token.ZKSecretWatcher.addKeyToZK(org.apache.hadoop.hbase.security.token.AuthenticationKey)"], ["void", "org.apache.hadoop.hbase.security.token.ZKSecretWatcher.updateKeyInZK(org.apache.hadoop.hbase.security.token.AuthenticationKey)"], ["org.apache.hadoop.hbase.security.visibility.ExpressionExpander", "org.apache.hadoop.hbase.security.visibility.ExpressionExpander()"], ["org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode", "org.apache.hadoop.hbase.security.visibility.ExpressionExpander.expand(org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode)"], ["org.apache.hadoop.hbase.security.visibility.VisibilityController", "org.apache.hadoop.hbase.security.visibility.VisibilityController()"], ["boolean", "org.apache.hadoop.hbase.security.visibility.VisibilityController.isAuthorizationSupported(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.security.visibility.VisibilityController.isCellAuthorizationSupported(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.postStartMaster(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preModifyTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preAddColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preModifyColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preDeleteColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preDisableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.postOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.postLogReplay(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["boolean", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preSetSplitOrMergeEnabled(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.postSetSplitOrMergeEnabled(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preBatchMutate(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.prePrepareTimeStampForDeleteVersion(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Mutation, org.apache.hadoop.hbase.Cell, byte[], org.apache.hadoop.hbase.client.Get)"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.RegionScanner)"], ["org.apache.hadoop.hbase.regionserver.DeleteTracker", "org.apache.hadoop.hbase.security.visibility.VisibilityController.postInstantiateDeleteTracker(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.DeleteTracker)"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.security.visibility.VisibilityController.postScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.RegionScanner)"], ["boolean", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preScannerNext(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner, java.util.List<org.apache.hadoop.hbase.client.Result>, int, boolean)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preScannerClose(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.postScannerClose(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preGetOp(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Get, java.util.List<org.apache.hadoop.hbase.Cell>)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preAppend(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Append)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.security.visibility.VisibilityController.preIncrement(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Increment)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.security.visibility.VisibilityController.postMutationBeforeWAL(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.coprocessor.RegionObserver$MutationType, org.apache.hadoop.hbase.client.Mutation, org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.Cell)"], ["com.google.protobuf.Service", "org.apache.hadoop.hbase.security.visibility.VisibilityController.getService()"], ["synchronized", "org.apache.hadoop.hbase.security.visibility.VisibilityController.void addLabels(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$VisibilityLabelsRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$VisibilityLabelsResponse>)"], ["synchronized", "org.apache.hadoop.hbase.security.visibility.VisibilityController.void setAuths(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$SetAuthsRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$VisibilityLabelsResponse>)"], ["synchronized", "org.apache.hadoop.hbase.security.visibility.VisibilityController.void getAuths(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$GetAuthsRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$GetAuthsResponse>)"], ["synchronized", "org.apache.hadoop.hbase.security.visibility.VisibilityController.void clearAuths(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$SetAuthsRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$VisibilityLabelsResponse>)"], ["synchronized", "org.apache.hadoop.hbase.security.visibility.VisibilityController.void listLabels(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$ListLabelsRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$ListLabelsResponse>)"], ["void", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$3.fillRegion(org.apache.hadoop.hbase.regionserver.HRegion)"], ["boolean", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats$FileInfo.inArchive()"], ["boolean", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats$FileInfo.isCorrupted()"], ["boolean", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats$FileInfo.isMissing()"], ["long", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats$FileInfo.getSize()"], ["org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.regionserver.HRegionFileSystem", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder.regionOpen(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder.regionClose(org.apache.hadoop.hbase.regionserver.HRegionFileSystem)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder.familyOpen(org.apache.hadoop.hbase.regionserver.HRegionFileSystem, byte[])"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder.familyClose(org.apache.hadoop.hbase.regionserver.HRegionFileSystem, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder.storeFile(org.apache.hadoop.hbase.regionserver.HRegionFileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.regionserver.StoreFileInfo)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder.storeFile(java.lang.Object, java.lang.Object, org.apache.hadoop.hbase.regionserver.StoreFileInfo)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder.familyClose(java.lang.Object, java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder.familyOpen(java.lang.Object, byte[])"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder.regionClose(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$ManifestBuilder.regionOpen(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil$3.storeFile(org.apache.hadoop.hbase.HRegionInfo, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile)"], ["org.apache.hadoop.hbase.SplitLogTask$Err", "org.apache.hadoop.hbase.SplitLogTask$Err(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode)"], ["org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl(org.jamon.TemplateManager)"], ["org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl()"], ["org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.setFilter(java.lang.String)"], ["org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.setFormat(java.lang.String)"], ["org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.setTaskMonitor(org.apache.hadoop.hbase.monitoring.TaskMonitor)"], ["org.jamon.AbstractTemplateImpl", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.constructImpl(java.lang.Class<? extends org.jamon.AbstractTemplateImpl>)"], ["org.jamon.Renderer", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.makeRenderer()"], ["void", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.render(java.io.Writer)"], ["void", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.renderNoFlush(java.io.Writer)"], ["org.jamon.AbstractTemplateProxy$ImplData", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl(org.jamon.TemplateManager)"], ["org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl()"], ["org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl.getImplData()"], ["org.jamon.AbstractTemplateImpl", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl.constructImpl(java.lang.Class<? extends org.jamon.AbstractTemplateImpl>)"], ["org.jamon.Renderer", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl.makeRenderer(org.apache.hadoop.hbase.master.HMaster)"], ["void", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl.render(java.io.Writer, org.apache.hadoop.hbase.master.HMaster)"], ["void", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl.renderNoFlush(java.io.Writer, org.apache.hadoop.hbase.master.HMaster)"], ["org.jamon.AbstractTemplateProxy$ImplData", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl$ImplData()"], ["void", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl$ImplData.setMaster(org.apache.hadoop.hbase.master.HMaster)"], ["org.apache.hadoop.hbase.master.HMaster", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl$ImplData.getMaster()"], ["void", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl$ImplData.setServers(java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl$ImplData.getServers__IsNotDefault()"], ["org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl(org.jamon.TemplateManager)"], ["org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl()"], ["org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.getImplData()"], ["org.jamon.AbstractTemplateImpl", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.constructImpl(java.lang.Class<? extends org.jamon.AbstractTemplateImpl>)"], ["org.jamon.Renderer", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.makeRenderer(org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.render(java.io.Writer, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.renderNoFlush(java.io.Writer, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.conf.Configuration)"], ["org.jamon.AbstractTemplateProxy$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl$ImplData()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl$ImplData.setRegionServer(org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["org.apache.hadoop.hbase.regionserver.HRegionServer", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl$ImplData.getRegionServer()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl$ImplData.setOnlineRegions(java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink()"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink.publishReadFailure(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, java.lang.Exception)"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink.publishReadFailure(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HColumnDescriptor, java.lang.Exception)"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink.publishReadTiming(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HColumnDescriptor, long)"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink.publishWriteFailure(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, java.lang.Exception)"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink.publishWriteFailure(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HColumnDescriptor, java.lang.Exception)"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink.publishWriteTiming(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HColumnDescriptor, long)"], ["java.util.Map<java.lang.String, java.util.concurrent.atomic.AtomicLong>", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink.getReadLatencyMap()"], ["java.util.concurrent.atomic.AtomicLong", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink.initializeAndGetReadLatencyForTable(java.lang.String)"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink.initializeWriteLatency()"], ["java.util.concurrent.atomic.AtomicLong", "org.apache.hadoop.hbase.tool.Canary$RegionStdOutSink.getWriteLatency()"], ["void", "org.apache.hadoop.hbase.tool.Canary$ZookeeperMonitor.run()"], ["void", "org.apache.hadoop.hbase.util.ConfigurationUtil.setKeyValues(org.apache.hadoop.conf.Configuration, java.lang.String, java.util.Collection<java.util.Map$Entry<java.lang.String, java.lang.String>>)"], ["void", "org.apache.hadoop.hbase.util.ConfigurationUtil.setKeyValues(org.apache.hadoop.conf.Configuration, java.lang.String, java.util.Collection<java.util.Map$Entry<java.lang.String, java.lang.String>>, char)"], ["java.util.List<java.util.Map$Entry<java.lang.String, java.lang.String>>", "org.apache.hadoop.hbase.util.ConfigurationUtil.getKeyValues(org.apache.hadoop.conf.Configuration, java.lang.String)"], ["java.util.List<java.util.Map$Entry<java.lang.String, java.lang.String>>", "org.apache.hadoop.hbase.util.ConfigurationUtil.getKeyValues(org.apache.hadoop.conf.Configuration, java.lang.String, char)"], ["void", "org.apache.hadoop.hbase.util.EncryptionTest.testKeyProvider(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.util.EncryptionTest.testCipherProvider(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.util.EncryptionTest.testEncryption(org.apache.hadoop.conf.Configuration, java.lang.String, byte[])"], ["void", "org.apache.hadoop.hbase.util.FSUtils$1.run()"], ["void", "org.apache.hadoop.hbase.util.FSUtils.setStoragePolicy(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path, java.lang.String, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.isDistributedFileSystem(org.apache.hadoop.fs.FileSystem)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.isStartingWithPath(org.apache.hadoop.fs.Path, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.isMatchingTail(org.apache.hadoop.fs.Path, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.isMatchingTail(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.util.FSUtils", "org.apache.hadoop.hbase.util.FSUtils.getInstance(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.deleteDirectory(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.deleteRegionDir(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HRegionInfo)"], ["long", "org.apache.hadoop.hbase.util.FSUtils.getDefaultBlockSize(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["short", "org.apache.hadoop.hbase.util.FSUtils.getDefaultReplication(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["int", "org.apache.hadoop.hbase.util.FSUtils.getDefaultBufferSize(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.fs.FSDataOutputStream", "org.apache.hadoop.hbase.util.FSUtils.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.net.InetSocketAddress[])"], ["org.apache.hadoop.fs.FSDataOutputStream", "org.apache.hadoop.hbase.util.FSUtils.create(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, boolean)"], ["org.apache.hadoop.fs.permission.FsPermission", "org.apache.hadoop.hbase.util.FSUtils.getFilePermissions(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration, java.lang.String)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.checkFileSystemAvailable(org.apache.hadoop.fs.FileSystem)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.checkDfsSafeMode(org.apache.hadoop.conf.Configuration)"], ["java.lang.String", "org.apache.hadoop.hbase.util.FSUtils.getVersion(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.checkVersion(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, boolean)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.checkVersion(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, boolean, int, int)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.setVersion(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.setVersion(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, int, int)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.setVersion(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, java.lang.String, int, int)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.checkClusterIdExists(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, int)"], ["org.apache.hadoop.hbase.ClusterId", "org.apache.hadoop.hbase.util.FSUtils.getClusterId(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.setClusterId(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.ClusterId, int)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.FSUtils.validateRootPath(org.apache.hadoop.fs.Path)"], ["java.lang.String", "org.apache.hadoop.hbase.util.FSUtils.removeWALRootPath(org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(org.apache.hadoop.conf.Configuration, long)"], ["java.lang.String", "org.apache.hadoop.hbase.util.FSUtils.getPath(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.FSUtils.getRootDir(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.setRootDir(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.setFsDefault(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.util.FSUtils.getRootDirFileSystem(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.FSUtils.getWALRootDir(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.setWALRootDir(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.util.FSUtils.getWALFileSystem(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.metaRegionExists(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.util.FSUtils.computeHDFSBlocksDistribution(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.FileStatus, long, long)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.addToHDFSBlocksDistribution(org.apache.hadoop.hbase.HDFSBlocksDistribution, org.apache.hadoop.fs.BlockLocation[])"], ["int", "org.apache.hadoop.hbase.util.FSUtils.getTotalTableFragmentation(org.apache.hadoop.hbase.master.HMaster)"], ["java.util.Map<java.lang.String, java.lang.Integer>", "org.apache.hadoop.hbase.util.FSUtils.getTableFragmentation(org.apache.hadoop.hbase.master.HMaster)"], ["java.util.Map<java.lang.String, java.lang.Integer>", "org.apache.hadoop.hbase.util.FSUtils.getTableFragmentation(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.FSUtils.getTableDir(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.util.FSUtils.getTableName(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.FSUtils.getNamespaceDir(org.apache.hadoop.fs.Path, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.isAppendSupported(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.isHDFS(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.isRecoveredEdits(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.util.FSUtils.getCurrentFileSystem(org.apache.hadoop.conf.Configuration)"], ["java.util.Map<java.lang.String, org.apache.hadoop.fs.Path>", "org.apache.hadoop.hbase.util.FSUtils.getTableStoreFilePathMap(java.util.Map<java.lang.String, org.apache.hadoop.fs.Path>, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.TableName)"], ["java.util.Map<java.lang.String, org.apache.hadoop.fs.Path>", "org.apache.hadoop.hbase.util.FSUtils.getTableStoreFilePathMap(java.util.Map<java.lang.String, org.apache.hadoop.fs.Path>, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.TableName, org.apache.hadoop.fs.PathFilter, java.util.concurrent.ExecutorService, org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter)"], ["int", "org.apache.hadoop.hbase.util.FSUtils.getRegionReferenceFileCount(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["java.util.Map<java.lang.String, org.apache.hadoop.fs.Path>", "org.apache.hadoop.hbase.util.FSUtils.getTableStoreFilePathMap(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["java.util.Map<java.lang.String, org.apache.hadoop.fs.Path>", "org.apache.hadoop.hbase.util.FSUtils.getTableStoreFilePathMap(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.PathFilter, java.util.concurrent.ExecutorService, org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter)"], ["org.apache.hadoop.fs.FileStatus[]", "org.apache.hadoop.hbase.util.FSUtils.listStatus(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.PathFilter)"], ["org.apache.hadoop.fs.FileStatus[]", "org.apache.hadoop.hbase.util.FSUtils.listStatus(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.delete(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, boolean)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.isExists(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.checkAccess(org.apache.hadoop.security.UserGroupInformation, org.apache.hadoop.fs.FileStatus, org.apache.hadoop.fs.permission.FsAction)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.logFileSystemState(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.commons.logging.Log)"], ["boolean", "org.apache.hadoop.hbase.util.FSUtils.renameAndSetModifyTime(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["java.util.Map<java.lang.String, java.util.Map<java.lang.String, java.lang.Float>>", "org.apache.hadoop.hbase.util.FSUtils.getRegionDegreeLocalityMappingFromFS(org.apache.hadoop.conf.Configuration)"], ["java.util.Map<java.lang.String, java.util.Map<java.lang.String, java.lang.Float>>", "org.apache.hadoop.hbase.util.FSUtils.getRegionDegreeLocalityMappingFromFS(org.apache.hadoop.conf.Configuration, java.lang.String, int)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.setupShortCircuitRead(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.util.FSUtils.checkShortCircuitReadBufferSize(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.util.HBaseFsckRepair", "org.apache.hadoop.hbase.util.HBaseFsckRepair()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsckRepair.fixMultiAssignment(org.apache.hadoop.hbase.client.HConnection, org.apache.hadoop.hbase.HRegionInfo, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsckRepair.fixUnassigned(org.apache.hadoop.hbase.client.Admin, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsckRepair.waitUntilAssigned(org.apache.hadoop.hbase.client.Admin, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsckRepair.closeRegionSilentlyAndWait(org.apache.hadoop.hbase.client.HConnection, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsckRepair.fixMetaHoleOnlineAndAddReplicas(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HRegionInfo, java.util.Collection<org.apache.hadoop.hbase.ServerName>, int)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.util.HBaseFsckRepair.createHDFSRegionDir(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsckRepair.removeParentInMeta(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.HFileArchiveUtil.getStoreArchivePath(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.TableName, java.lang.String, java.lang.String)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.HFileArchiveUtil.getStoreArchivePath(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.fs.Path, byte[])"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.HFileArchiveUtil.getRegionArchiveDir(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.TableName, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.HFileArchiveUtil.getRegionArchiveDir(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.TableName, java.lang.String)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.HFileArchiveUtil.getTableArchivePath(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.HFileArchiveUtil.getTableArchivePath(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.HFileArchiveUtil.getArchivePath(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.util.HttpServerUtil", "org.apache.hadoop.hbase.util.HttpServerUtil()"], ["void", "org.apache.hadoop.hbase.util.HttpServerUtil.constrainHttpMethods(org.mortbay.jetty.servlet.Context, boolean)"], ["java.util.concurrent.locks.ReentrantReadWriteLock", "org.apache.hadoop.hbase.util.IdReadWriteLock$1.createObject(java.lang.Long)"], ["java.lang.Object", "org.apache.hadoop.hbase.util.IdReadWriteLock$1.createObject(java.lang.Object)"], ["org.apache.hadoop.hbase.util.JvmPauseMonitor", "org.apache.hadoop.hbase.util.JvmPauseMonitor(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.util.JvmPauseMonitor", "org.apache.hadoop.hbase.util.JvmPauseMonitor(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.metrics.JvmPauseMonitorSource)"], ["void", "org.apache.hadoop.hbase.util.JvmPauseMonitor.start()"], ["void", "org.apache.hadoop.hbase.util.JvmPauseMonitor.stop()"], ["void", "org.apache.hadoop.hbase.util.JvmPauseMonitor.updateMetrics(long, boolean)"], ["org.apache.hadoop.hbase.metrics.JvmPauseMonitorSource", "org.apache.hadoop.hbase.util.JvmPauseMonitor.getMetricsSource()"], ["void", "org.apache.hadoop.hbase.util.JvmPauseMonitor.setMetricsSource(org.apache.hadoop.hbase.metrics.JvmPauseMonitorSource)"], ["void", "org.apache.hadoop.hbase.util.JvmPauseMonitor.main(java.lang.String[])"], ["org.apache.hadoop.hbase.util.MBeanUtil", "org.apache.hadoop.hbase.util.MBeanUtil()"], ["javax.management.ObjectName", "org.apache.hadoop.hbase.util.MBeanUtil.registerMBean(java.lang.String, java.lang.String, java.lang.Object)"], ["void", "org.apache.hadoop.hbase.util.MBeanUtil.unregisterMBean(javax.management.ObjectName)"], ["org.apache.hadoop.hbase.util.RegionSplitCalculator", "org.apache.hadoop.hbase.util.RegionSplitCalculator(java.util.Comparator<R>)"], ["boolean", "org.apache.hadoop.hbase.util.RegionSplitCalculator.add(R)"], ["com.google.common.collect.Multimap<byte[], R>", "org.apache.hadoop.hbase.util.RegionSplitCalculator.calcCoverage()"], ["com.google.common.collect.Multimap<byte[], R>", "org.apache.hadoop.hbase.util.RegionSplitCalculator.getStarts()"], ["<R extends org.apache.hadoop.hbase.util.KeyRange> java.util.List<R>", "org.apache.hadoop.hbase.util.RegionSplitCalculator.findBigRanges(java.util.Collection<R>, int)"], ["org.apache.hadoop.hbase.util.ServerCommandLine", "org.apache.hadoop.hbase.util.ServerCommandLine()"], ["void", "org.apache.hadoop.hbase.util.ServerCommandLine.logJVMInfo()"], ["void", "org.apache.hadoop.hbase.util.ServerCommandLine.logProcessInfo(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.util.ServerCommandLine.doMain(java.lang.String[])"], ["boolean", "org.apache.hadoop.hbase.util.StealJobQueue$1.offer(T)"], ["org.apache.hadoop.hbase.wal.WALFactory", "org.apache.hadoop.hbase.wal.WALFactory(org.apache.hadoop.conf.Configuration, java.util.List<org.apache.hadoop.hbase.regionserver.wal.WALActionsListener>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.wal.WALFactory.close()"], ["void", "org.apache.hadoop.hbase.wal.WALFactory.shutdown()"], ["org.apache.hadoop.hbase.wal.WAL", "org.apache.hadoop.hbase.wal.WALFactory.getWAL(byte[], byte[])"], ["org.apache.hadoop.hbase.wal.WAL", "org.apache.hadoop.hbase.wal.WALFactory.getMetaWAL(byte[])"], ["org.apache.hadoop.hbase.wal.WAL$Reader", "org.apache.hadoop.hbase.wal.WALFactory.createReader(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.wal.WAL$Reader", "org.apache.hadoop.hbase.wal.WALFactory.createReader(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["org.apache.hadoop.hbase.wal.WAL$Reader", "org.apache.hadoop.hbase.wal.WALFactory.createReader(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.CancelableProgressable, boolean)"], ["org.apache.hadoop.hbase.wal.WALProvider$Writer", "org.apache.hadoop.hbase.wal.WALFactory.createWALWriter(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.wal.WALProvider$Writer", "org.apache.hadoop.hbase.wal.WALFactory.createRecoveredEditsWriter(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.wal.WALFactory", "org.apache.hadoop.hbase.wal.WALFactory.getInstance(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.wal.WAL$Reader", "org.apache.hadoop.hbase.wal.WALFactory.createReader(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.wal.WAL$Reader", "org.apache.hadoop.hbase.wal.WALFactory.createReaderIgnoreCustomClass(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.wal.WALProvider$Writer", "org.apache.hadoop.hbase.wal.WALFactory.createWALWriter(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.wal.WALProvider", "org.apache.hadoop.hbase.wal.WALFactory.getWALProvider()"], ["org.apache.hadoop.hbase.wal.WALProvider", "org.apache.hadoop.hbase.wal.WALFactory.getMetaWALProvider()"], ["org.apache.hadoop.hbase.wal.WALSplitter$OutputSink", "org.apache.hadoop.hbase.wal.WALSplitter$OutputSink(org.apache.hadoop.hbase.wal.WALSplitter$PipelineController, org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers, int)"], ["synchronized", "org.apache.hadoop.hbase.wal.WALSplitter$OutputSink.void startWriterThreads()"], ["boolean", "org.apache.hadoop.hbase.wal.WALSplitter$OutputSink.flush()"], ["org.apache.hadoop.hbase.wal.WALSplitter$SinkWriter", "org.apache.hadoop.hbase.wal.WALSplitter$SinkWriter()"], ["void", "org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.run()"], ["void", "org.apache.hadoop.hbase.zookeeper.DrainingServerTracker$1.serverAdded(org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.zookeeper.DrainingServerTracker$1.waiting()"], ["void", "org.apache.hadoop.hbase.zookeeper.DrainingServerTracker$1.serverRemoved(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.zookeeper.RecoveringRegionWatcher", "org.apache.hadoop.hbase.zookeeper.RecoveringRegionWatcher(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["void", "org.apache.hadoop.hbase.zookeeper.RecoveringRegionWatcher.nodeDeleted(java.lang.String)"], ["void", "org.apache.hadoop.hbase.zookeeper.RecoveringRegionWatcher.nodeDataChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.zookeeper.RecoveringRegionWatcher.nodeChildrenChanged(java.lang.String)"], ["org.apache.hadoop.hbase.zookeeper.ZKServerTool", "org.apache.hadoop.hbase.zookeeper.ZKServerTool()"], ["org.apache.hadoop.hbase.ServerName[]", "org.apache.hadoop.hbase.zookeeper.ZKServerTool.readZKNodes(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.zookeeper.ZKServerTool.main(java.lang.String[])"], ["org.apache.hadoop.hbase.backup.example.HFileArchiveTableMonitor", "org.apache.hadoop.hbase.backup.example.HFileArchiveTableMonitor()"], ["synchronized", "org.apache.hadoop.hbase.backup.example.HFileArchiveTableMonitor.void setArchiveTables(java.util.List<java.lang.String>)"], ["synchronized", "org.apache.hadoop.hbase.backup.example.HFileArchiveTableMonitor.void addTable(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.backup.example.HFileArchiveTableMonitor.void removeTable(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.backup.example.HFileArchiveTableMonitor.void clearArchive()"], ["synchronized", "org.apache.hadoop.hbase.backup.example.HFileArchiveTableMonitor.boolean shouldArchiveTable(java.lang.String)"], ["org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner", "org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner()"], ["boolean", "org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.isFileDeletable(org.apache.hadoop.fs.FileStatus)"], ["void", "org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.setConf(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.stop(java.lang.String)"], ["org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath", "org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath.delete()"], ["java.lang.String", "org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath.getName()"], ["boolean", "org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath.isFile()"], ["void", "org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath.close()"], ["org.apache.hadoop.hbase.backup.HFileArchiver$FileConverter", "org.apache.hadoop.hbase.backup.HFileArchiver$FileConverter(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.client.HTableInterface", "org.apache.hadoop.hbase.client.HTableWrapper.createWrapper(java.util.List<org.apache.hadoop.hbase.client.HTableInterface>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment, java.util.concurrent.ExecutorService)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.internalClose()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.client.HTableWrapper.getConfiguration()"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.close()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.client.HTableWrapper.getRowOrBefore(byte[], byte[])"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.client.HTableWrapper.get(org.apache.hadoop.hbase.client.Get)"], ["boolean", "org.apache.hadoop.hbase.client.HTableWrapper.exists(org.apache.hadoop.hbase.client.Get)"], ["boolean[]", "org.apache.hadoop.hbase.client.HTableWrapper.existsAll(java.util.List<org.apache.hadoop.hbase.client.Get>)"], ["java.lang.Boolean[]", "org.apache.hadoop.hbase.client.HTableWrapper.exists(java.util.List<org.apache.hadoop.hbase.client.Get>)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.put(org.apache.hadoop.hbase.client.Put)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.put(java.util.List<org.apache.hadoop.hbase.client.Put>)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.delete(org.apache.hadoop.hbase.client.Delete)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.delete(java.util.List<org.apache.hadoop.hbase.client.Delete>)"], ["boolean", "org.apache.hadoop.hbase.client.HTableWrapper.checkAndPut(byte[], byte[], byte[], byte[], org.apache.hadoop.hbase.client.Put)"], ["boolean", "org.apache.hadoop.hbase.client.HTableWrapper.checkAndPut(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, byte[], org.apache.hadoop.hbase.client.Put)"], ["boolean", "org.apache.hadoop.hbase.client.HTableWrapper.checkAndDelete(byte[], byte[], byte[], byte[], org.apache.hadoop.hbase.client.Delete)"], ["boolean", "org.apache.hadoop.hbase.client.HTableWrapper.checkAndDelete(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, byte[], org.apache.hadoop.hbase.client.Delete)"], ["long", "org.apache.hadoop.hbase.client.HTableWrapper.incrementColumnValue(byte[], byte[], byte[], long)"], ["long", "org.apache.hadoop.hbase.client.HTableWrapper.incrementColumnValue(byte[], byte[], byte[], long, org.apache.hadoop.hbase.client.Durability)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.client.HTableWrapper.append(org.apache.hadoop.hbase.client.Append)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.client.HTableWrapper.increment(org.apache.hadoop.hbase.client.Increment)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.flushCommits()"], ["boolean", "org.apache.hadoop.hbase.client.HTableWrapper.isAutoFlush()"], ["org.apache.hadoop.hbase.client.ResultScanner", "org.apache.hadoop.hbase.client.HTableWrapper.getScanner(org.apache.hadoop.hbase.client.Scan)"], ["org.apache.hadoop.hbase.client.ResultScanner", "org.apache.hadoop.hbase.client.HTableWrapper.getScanner(byte[])"], ["org.apache.hadoop.hbase.client.ResultScanner", "org.apache.hadoop.hbase.client.HTableWrapper.getScanner(byte[], byte[])"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.client.HTableWrapper.getTableDescriptor()"], ["byte[]", "org.apache.hadoop.hbase.client.HTableWrapper.getTableName()"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.client.HTableWrapper.getName()"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.batch(java.util.List<? extends org.apache.hadoop.hbase.client.Row>, java.lang.Object[])"], ["java.lang.Object[]", "org.apache.hadoop.hbase.client.HTableWrapper.batch(java.util.List<? extends org.apache.hadoop.hbase.client.Row>)"], ["<R> void", "org.apache.hadoop.hbase.client.HTableWrapper.batchCallback(java.util.List<? extends org.apache.hadoop.hbase.client.Row>, java.lang.Object[], org.apache.hadoop.hbase.client.coprocessor.Batch$Callback<R>)"], ["<R> java.lang.Object[]", "org.apache.hadoop.hbase.client.HTableWrapper.batchCallback(java.util.List<? extends org.apache.hadoop.hbase.client.Row>, org.apache.hadoop.hbase.client.coprocessor.Batch$Callback<R>)"], ["org.apache.hadoop.hbase.client.Result[]", "org.apache.hadoop.hbase.client.HTableWrapper.get(java.util.List<org.apache.hadoop.hbase.client.Get>)"], ["org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel", "org.apache.hadoop.hbase.client.HTableWrapper.coprocessorService(byte[])"], ["<T extends com.google.protobuf.Service, R> java.util.Map<byte[], R>", "org.apache.hadoop.hbase.client.HTableWrapper.coprocessorService(java.lang.Class<T>, byte[], byte[], org.apache.hadoop.hbase.client.coprocessor.Batch$Call<T, R>)"], ["<T extends com.google.protobuf.Service, R> void", "org.apache.hadoop.hbase.client.HTableWrapper.coprocessorService(java.lang.Class<T>, byte[], byte[], org.apache.hadoop.hbase.client.coprocessor.Batch$Call<T, R>, org.apache.hadoop.hbase.client.coprocessor.Batch$Callback<R>)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.mutateRow(org.apache.hadoop.hbase.client.RowMutations)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.setAutoFlush(boolean)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.setAutoFlush(boolean, boolean)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.setAutoFlushTo(boolean)"], ["long", "org.apache.hadoop.hbase.client.HTableWrapper.getWriteBufferSize()"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.setWriteBufferSize(long)"], ["long", "org.apache.hadoop.hbase.client.HTableWrapper.incrementColumnValue(byte[], byte[], byte[], long, boolean)"], ["<R extends com.google.protobuf.Message> java.util.Map<byte[], R>", "org.apache.hadoop.hbase.client.HTableWrapper.batchCoprocessorService(com.google.protobuf.Descriptors$MethodDescriptor, com.google.protobuf.Message, byte[], byte[], R)"], ["<R extends com.google.protobuf.Message> void", "org.apache.hadoop.hbase.client.HTableWrapper.batchCoprocessorService(com.google.protobuf.Descriptors$MethodDescriptor, com.google.protobuf.Message, byte[], byte[], R, org.apache.hadoop.hbase.client.coprocessor.Batch$Callback<R>)"], ["boolean", "org.apache.hadoop.hbase.client.HTableWrapper.checkAndMutate(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, byte[], org.apache.hadoop.hbase.client.RowMutations)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.setOperationTimeout(int)"], ["int", "org.apache.hadoop.hbase.client.HTableWrapper.getOperationTimeout()"], ["int", "org.apache.hadoop.hbase.client.HTableWrapper.getRpcTimeout()"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.setRpcTimeout(int)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.setWriteRpcTimeout(int)"], ["void", "org.apache.hadoop.hbase.client.HTableWrapper.setReadRpcTimeout(int)"], ["int", "org.apache.hadoop.hbase.client.HTableWrapper.getWriteRpcTimeout()"], ["int", "org.apache.hadoop.hbase.client.HTableWrapper.getReadRpcTimeout()"], ["org.apache.hadoop.hbase.constraint.ConstraintException", "org.apache.hadoop.hbase.constraint.ConstraintException()"], ["org.apache.hadoop.hbase.constraint.ConstraintException", "org.apache.hadoop.hbase.constraint.ConstraintException(java.lang.String)"], ["org.apache.hadoop.hbase.constraint.ConstraintException", "org.apache.hadoop.hbase.constraint.ConstraintException(java.lang.String, java.lang.Throwable)"], ["int", "org.apache.hadoop.hbase.constraint.Constraints$1.compare(org.apache.hadoop.hbase.constraint.Constraint, org.apache.hadoop.hbase.constraint.Constraint)"], ["int", "org.apache.hadoop.hbase.constraint.Constraints$1.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$TaskFinisher$Status", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$1.finish(org.apache.hadoop.hbase.ServerName, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$GetDataAsyncCallback.processResult(int, java.lang.String, java.lang.Object, byte[], org.apache.zookeeper.data.Stat)"], ["org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver()"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.preStopRegionServer(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.preMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.postMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.preMergeCommit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, java.util.List<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.postMergeCommit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.preRollBackMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.postRollBackMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.preRollWALWriterRequest(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.postRollWALWriterRequest(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.replication.ReplicationEndpoint", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.postCreateReplicationEndPoint(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.replication.ReplicationEndpoint)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.preReplicateLogEntries(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.protobuf.generated.AdminProtos$WALEntry>, org.apache.hadoop.hbase.CellScanner)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.postReplicateLogEntries(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.protobuf.generated.AdminProtos$WALEntry>, org.apache.hadoop.hbase.CellScanner)"], ["int", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$EnvironmentPriorityComparator.compare(org.apache.hadoop.hbase.CoprocessorEnvironment, org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["int", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$EnvironmentPriorityComparator.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.coprocessor.ObserverContext", "org.apache.hadoop.hbase.coprocessor.ObserverContext()"], ["E", "org.apache.hadoop.hbase.coprocessor.ObserverContext.getEnvironment()"], ["void", "org.apache.hadoop.hbase.coprocessor.ObserverContext.prepare(E)"], ["void", "org.apache.hadoop.hbase.coprocessor.ObserverContext.bypass()"], ["void", "org.apache.hadoop.hbase.coprocessor.ObserverContext.complete()"], ["boolean", "org.apache.hadoop.hbase.coprocessor.ObserverContext.shouldBypass()"], ["boolean", "org.apache.hadoop.hbase.coprocessor.ObserverContext.shouldComplete()"], ["<T extends org.apache.hadoop.hbase.CoprocessorEnvironment> org.apache.hadoop.hbase.coprocessor.ObserverContext<T>", "org.apache.hadoop.hbase.coprocessor.ObserverContext.createAndPrepare(T, org.apache.hadoop.hbase.coprocessor.ObserverContext<T>)"], ["org.apache.hadoop.hbase.coprocessor.RegionObserver$MutationType[]", "org.apache.hadoop.hbase.coprocessor.RegionObserver$MutationType.values()"], ["org.apache.hadoop.hbase.coprocessor.RegionObserver$MutationType", "org.apache.hadoop.hbase.coprocessor.RegionObserver$MutationType.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.generated.master.procedures_jsp", "org.apache.hadoop.hbase.generated.master.procedures_jsp()"], ["java.lang.Object", "org.apache.hadoop.hbase.generated.master.procedures_jsp.getDependants()"], ["void", "org.apache.hadoop.hbase.generated.master.procedures_jsp._jspService(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.generated.regionserver.region_jsp", "org.apache.hadoop.hbase.generated.regionserver.region_jsp()"], ["java.lang.Object", "org.apache.hadoop.hbase.generated.regionserver.region_jsp.getDependants()"], ["void", "org.apache.hadoop.hbase.generated.regionserver.region_jsp._jspService(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.HealthCheckChore", "org.apache.hadoop.hbase.HealthCheckChore(int, org.apache.hadoop.hbase.Stoppable, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.http.conf.ConfServlet", "org.apache.hadoop.hbase.http.conf.ConfServlet()"], ["void", "org.apache.hadoop.hbase.http.conf.ConfServlet.doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter$RequestQuoter", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter$RequestQuoter(javax.servlet.http.HttpServletRequest)"], ["java.lang.String", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter$RequestQuoter.getParameter(java.lang.String)"], ["java.lang.String[]", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter$RequestQuoter.getParameterValues(java.lang.String)"], ["java.util.Map<java.lang.String, java.lang.String[]>", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter$RequestQuoter.getParameterMap()"], ["java.lang.StringBuffer", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter$RequestQuoter.getRequestURL()"], ["java.lang.String", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter$RequestQuoter.getServerName()"], ["java.security.Principal", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter$1.getUserPrincipal()"], ["java.lang.String", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter$1.getRemoteUser()"], ["org.apache.hadoop.hbase.http.log.LogLevel", "org.apache.hadoop.hbase.http.log.LogLevel()"], ["void", "org.apache.hadoop.hbase.http.log.LogLevel.main(java.lang.String[])"], ["org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$Scanner", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$Scanner(org.apache.hadoop.hbase.io.hfile.HFile$Reader, boolean, boolean, boolean)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$Scanner.isSeeked()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$Scanner.toString()"], ["int", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$Scanner.seekTo(byte[])"], ["boolean", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$Scanner.seekBefore(byte[])"], ["int", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$Scanner.reseekTo(byte[])"], ["org.apache.hadoop.hbase.io.hfile.HFile$Reader", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$Scanner.getReader()"], ["void", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$Scanner.close()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile.update(org.apache.hadoop.hbase.io.hfile.CachedBlock)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile.isFull()"], ["java.util.NavigableMap<java.lang.String, java.util.NavigableSet<org.apache.hadoop.hbase.io.hfile.CachedBlock>>", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile.getCachedBlockStatsByFile()"], ["int", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile.getCount()"], ["int", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile.getDataCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile.getSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile.getDataSize()"], ["org.apache.hadoop.hbase.io.hfile.AgeSnapshot", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile.getAgeInCacheSnapshot()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlocksByFile.toString()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry$1.compare(org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry, org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry$1.compare(java.lang.Object, java.lang.Object)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.toString()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.ioHit(long)"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.getIOHitsPerSecond()"], ["double", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.getIOTimePerHit()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.reset()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine$FileWriteAccessor.access(java.nio.channels.FileChannel, java.nio.ByteBuffer, long)"], ["org.apache.hadoop.hbase.io.hfile.CacheStats", "org.apache.hadoop.hbase.io.hfile.CacheStats(java.lang.String)"], ["org.apache.hadoop.hbase.io.hfile.CacheStats", "org.apache.hadoop.hbase.io.hfile.CacheStats(java.lang.String, int)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.CacheStats.toString()"], ["void", "org.apache.hadoop.hbase.io.hfile.CacheStats.miss(boolean, boolean, org.apache.hadoop.hbase.io.hfile.BlockType)"], ["void", "org.apache.hadoop.hbase.io.hfile.CacheStats.hit(boolean, boolean, org.apache.hadoop.hbase.io.hfile.BlockType)"], ["void", "org.apache.hadoop.hbase.io.hfile.CacheStats.evict()"], ["void", "org.apache.hadoop.hbase.io.hfile.CacheStats.evicted(long, boolean)"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.failInsert()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getDataMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getLeafIndexMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getBloomChunkMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getMetaMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getRootIndexMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getIntermediateIndexMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getFileInfoMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getGeneralBloomMetaMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getDeleteFamilyBloomMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getTrailerMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getDataHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getLeafIndexHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getBloomChunkHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getMetaHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getRootIndexHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getIntermediateIndexHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getFileInfoHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getGeneralBloomMetaHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getDeleteFamilyBloomHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getTrailerHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getRequestCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getRequestCachingCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getPrimaryMissCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getMissCachingCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getPrimaryHitCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getHitCachingCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getEvictionCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getEvictedCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getPrimaryEvictedCount()"], ["double", "org.apache.hadoop.hbase.io.hfile.CacheStats.getHitRatio()"], ["double", "org.apache.hadoop.hbase.io.hfile.CacheStats.getHitCachingRatio()"], ["double", "org.apache.hadoop.hbase.io.hfile.CacheStats.getMissRatio()"], ["double", "org.apache.hadoop.hbase.io.hfile.CacheStats.getMissCachingRatio()"], ["double", "org.apache.hadoop.hbase.io.hfile.CacheStats.evictedPerEviction()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getFailedInserts()"], ["void", "org.apache.hadoop.hbase.io.hfile.CacheStats.rollMetricsPeriod()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getSumHitCountsPastNPeriods()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getSumRequestCountsPastNPeriods()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getSumHitCachingCountsPastNPeriods()"], ["long", "org.apache.hadoop.hbase.io.hfile.CacheStats.getSumRequestCachingCountsPastNPeriods()"], ["double", "org.apache.hadoop.hbase.io.hfile.CacheStats.getHitRatioPastNPeriods()"], ["double", "org.apache.hadoop.hbase.io.hfile.CacheStats.getHitCachingRatioPastNPeriods()"], ["org.apache.hadoop.hbase.io.hfile.AgeSnapshot", "org.apache.hadoop.hbase.io.hfile.CacheStats.getAgeAtEvictionSnapshot()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter(org.apache.hadoop.hbase.io.hfile.HFileBlock$Writer, org.apache.hadoop.hbase.io.hfile.CacheConfig, java.lang.String)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.setMaxChunkSize(int)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.setMinIndexNumEntries(int)"], ["long", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.writeIndexBlocks(org.apache.hadoop.fs.FSDataOutputStream)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.writeSingleLevelIndex(java.io.DataOutput, java.lang.String)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.getNumRootEntries()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.getNumLevels()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.shouldWriteBlock(boolean)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.writeInlineBlock(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.blockWritten(long, int, int)"], ["org.apache.hadoop.hbase.io.hfile.BlockType", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.getInlineBlockType()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.addEntry(byte[], long, int)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.ensureSingleLevel()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.getCacheOnWrite()"], ["long", "org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexWriter.getTotalUncompressedSize()"], ["org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2(org.apache.hadoop.hbase.io.hfile.HFileReaderV2, boolean, boolean, boolean, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.isSeeked()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.seekTo()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.next()"], ["java.nio.ByteBuffer", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.getKey()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.compareKey(org.apache.hadoop.hbase.KeyValue$KVComparator, byte[], int, int)"], ["java.nio.ByteBuffer", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.getValue()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.getKeyValue()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.getKeyString()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.getValueString()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.compareKey(org.apache.hadoop.hbase.KeyValue$KVComparator, org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.io.hfile.HFileWriterV2", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FSDataOutputStream, org.apache.hadoop.hbase.KeyValue$KVComparator, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2.appendMetaBlock(java.lang.String, org.apache.hadoop.io.Writable)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2.append(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2.close()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2.addInlineBlockWriter(org.apache.hadoop.hbase.io.hfile.InlineBlockWriter)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2.addGeneralBloomFilter(org.apache.hadoop.hbase.util.BloomFilterWriter)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2.addDeleteFamilyBloomFilter(org.apache.hadoop.hbase.util.BloomFilterWriter)"], ["org.apache.hadoop.hbase.io.hfile.HFileContext", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2.getFileContext()"], ["org.apache.hadoop.hbase.io.hfile.LruCachedBlock", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable, long)"], ["org.apache.hadoop.hbase.io.hfile.LruCachedBlock", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable, long, boolean)"], ["void", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock.access(long)"], ["long", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock.getCachedTime()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock.heapSize()"], ["int", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock.compareTo(org.apache.hadoop.hbase.io.hfile.LruCachedBlock)"], ["int", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock.hashCode()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock.equals(java.lang.Object)"], ["org.apache.hadoop.hbase.io.hfile.Cacheable", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock.getBuffer()"], ["org.apache.hadoop.hbase.io.hfile.BlockCacheKey", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock.getCacheKey()"], ["org.apache.hadoop.hbase.io.hfile.BlockPriority", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock.getPriority()"], ["int", "org.apache.hadoop.hbase.io.hfile.LruCachedBlock.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.io.Reference", "org.apache.hadoop.hbase.io.Reference.createTopReference(byte[])"], ["org.apache.hadoop.hbase.io.Reference", "org.apache.hadoop.hbase.io.Reference.createBottomReference(byte[])"], ["org.apache.hadoop.hbase.io.Reference", "org.apache.hadoop.hbase.io.Reference()"], ["org.apache.hadoop.hbase.io.Reference$Range", "org.apache.hadoop.hbase.io.Reference.getFileRegion()"], ["byte[]", "org.apache.hadoop.hbase.io.Reference.getSplitKey()"], ["java.lang.String", "org.apache.hadoop.hbase.io.Reference.toString()"], ["boolean", "org.apache.hadoop.hbase.io.Reference.isTopFileRegion(org.apache.hadoop.hbase.io.Reference$Range)"], ["void", "org.apache.hadoop.hbase.io.Reference.readFields(java.io.DataInput)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.io.Reference.write(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.io.Reference", "org.apache.hadoop.hbase.io.Reference.read(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.protobuf.generated.FSProtos$Reference", "org.apache.hadoop.hbase.io.Reference.convert()"], ["org.apache.hadoop.hbase.io.Reference", "org.apache.hadoop.hbase.io.Reference.convert(org.apache.hadoop.hbase.protobuf.generated.FSProtos$Reference)"], ["int", "org.apache.hadoop.hbase.io.Reference.hashCode()"], ["boolean", "org.apache.hadoop.hbase.io.Reference.equals(java.lang.Object)"], ["void", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run()"], ["java.net.InetSocketAddress", "org.apache.hadoop.hbase.ipc.RpcSchedulerContext.getListenerAddress()"], ["int", "org.apache.hadoop.hbase.ipc.RpcServer$Connection$2.read()"], ["org.apache.hadoop.hbase.jetty.SslSelectChannelConnectorSecure", "org.apache.hadoop.hbase.jetty.SslSelectChannelConnectorSecure()"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread", "org.apache.hadoop.hbase.LocalHBaseCluster$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.LocalHBaseCluster$1.run()"], ["org.apache.hadoop.hbase.mapred.IdentityTableMap", "org.apache.hadoop.hbase.mapred.IdentityTableMap()"], ["void", "org.apache.hadoop.hbase.mapred.IdentityTableMap.initJob(java.lang.String, java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableMap>, org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.IdentityTableMap.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapred.OutputCollector<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>, org.apache.hadoop.mapred.Reporter)"], ["void", "org.apache.hadoop.hbase.mapred.IdentityTableMap.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapred.OutputCollector, org.apache.hadoop.mapred.Reporter)"], ["org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader(org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit, org.apache.hadoop.mapred.JobConf)"], ["boolean", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader.next(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result)"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader.createKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader.createValue()"], ["long", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader.getPos()"], ["void", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader.close()"], ["float", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader.getProgress()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader.createValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader.createKey()"], ["boolean", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRecordReader.next(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.CellCounter", "org.apache.hadoop.hbase.mapreduce.CellCounter()"], ["org.apache.hadoop.mapreduce.Job", "org.apache.hadoop.hbase.mapreduce.CellCounter.createSubmittableJob(org.apache.hadoop.conf.Configuration, java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.CellCounter.main(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2$1.write(org.apache.hadoop.hbase.io.ImmutableBytesWritable, V)"], ["void", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2$1.close(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2$1.write(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable()"], ["org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable(org.apache.hadoop.hbase.KeyValue)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable.write(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable.readFields(java.io.DataInput)"], ["int", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable.compareTo(org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable)"], ["int", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.Import", "org.apache.hadoop.hbase.mapreduce.Import()"], ["org.apache.hadoop.hbase.filter.Filter", "org.apache.hadoop.hbase.mapreduce.Import.instantiateFilter(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.mapreduce.Import.filterKv(org.apache.hadoop.hbase.filter.Filter, org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import.configureCfRenaming(org.apache.hadoop.conf.Configuration, java.util.Map<java.lang.String, java.lang.String>)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import.addFilterAndArguments(org.apache.hadoop.conf.Configuration, java.lang.Class<? extends org.apache.hadoop.hbase.filter.Filter>, java.util.List<java.lang.String>)"], ["org.apache.hadoop.mapreduce.Job", "org.apache.hadoop.hbase.mapreduce.Import.createSubmittableJob(org.apache.hadoop.conf.Configuration, java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.Import.flushRegionsIfNecessary(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import.main(java.lang.String[])"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$2.call()"], ["org.apache.hadoop.hbase.mapreduce.MultiTableInputFormat", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormat()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormat.getConf()"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormat.setConf(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordWriter.close(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordWriter.write(K2, V2)"], ["void", "org.apache.hadoop.hbase.mapreduce.MutationSerialization$MutationDeserializer.close()"], ["org.apache.hadoop.hbase.client.Mutation", "org.apache.hadoop.hbase.mapreduce.MutationSerialization$MutationDeserializer.deserialize(org.apache.hadoop.hbase.client.Mutation)"], ["void", "org.apache.hadoop.hbase.mapreduce.MutationSerialization$MutationDeserializer.open(java.io.InputStream)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.MutationSerialization$MutationDeserializer.deserialize(java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier$Counters[]", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier$Counters.values()"], ["org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier$Counters", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier$Counters.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication()"], ["org.apache.hadoop.mapreduce.Job", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.createSubmittableJob(org.apache.hadoop.conf.Configuration, java.lang.String[])"], ["int", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.main(java.lang.String[])"], ["org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(java.lang.String, org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(byte[], org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(java.lang.String, org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job, boolean, java.lang.Class<? extends org.apache.hadoop.mapreduce.InputFormat>)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(java.lang.String, org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job, boolean, boolean, java.lang.Class<? extends org.apache.hadoop.mapreduce.InputFormat>)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(byte[], org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job, boolean, java.lang.Class<? extends org.apache.hadoop.mapreduce.InputFormat>)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(byte[], org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job, boolean)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(java.lang.String, org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job, boolean)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.resetCacheConfig(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initMultiTableSnapshotMapperJob(java.util.Map<java.lang.String, java.util.Collection<org.apache.hadoop.hbase.client.Scan>>, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job, boolean, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableSnapshotMapperJob(java.lang.String, org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job, boolean, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableSnapshotMapperJob(java.lang.String, org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job, boolean, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.RegionSplitter$SplitAlgorithm, int)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(java.util.List<org.apache.hadoop.hbase.client.Scan>, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(java.util.List<org.apache.hadoop.hbase.client.Scan>, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job, boolean)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(java.util.List<org.apache.hadoop.hbase.client.Scan>, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.Job, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initCredentials(org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initCredentialsForCluster(org.apache.hadoop.mapreduce.Job, java.lang.String)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initCredentialsForCluster(org.apache.hadoop.mapreduce.Job, org.apache.hadoop.conf.Configuration)"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.convertScanToString(org.apache.hadoop.hbase.client.Scan)"], ["org.apache.hadoop.hbase.client.Scan", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.convertStringToScan(java.lang.String)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableReducerJob(java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableReducer>, org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableReducerJob(java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableReducer>, org.apache.hadoop.mapreduce.Job, java.lang.Class)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableReducerJob(java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableReducer>, org.apache.hadoop.mapreduce.Job, java.lang.Class, java.lang.String, java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableReducerJob(java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableReducer>, org.apache.hadoop.mapreduce.Job, java.lang.Class, java.lang.String, java.lang.String, java.lang.String, boolean)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.limitNumReduceTasks(java.lang.String, org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.setNumReduceTasks(java.lang.String, org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.setScannerCaching(org.apache.hadoop.mapreduce.Job, int)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.addHBaseDependencyJars(org.apache.hadoop.conf.Configuration)"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.buildDependencyClasspath(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.addDependencyJars(org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.addDependencyJars(org.apache.hadoop.conf.Configuration, java.lang.Class<?>...)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.addDependencyJarsForClasses(org.apache.hadoop.conf.Configuration, java.lang.Class<?>...)"], ["org.apache.hadoop.hbase.wal.WALKey", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALKeyRecordReader.getCurrentKey()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALKeyRecordReader.getCurrentKey()"], ["void", "org.apache.hadoop.hbase.mapreduce.WALPlayer$WALMapper.map(org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Mutation>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.WALPlayer$WALMapper.setup(org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Mutation>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.WALPlayer$WALMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["java.lang.Object", "org.apache.hadoop.hbase.master.AssignmentManager$13.call()"], ["org.apache.hadoop.hbase.master.AssignmentManager$ServerHostRegion[]", "org.apache.hadoop.hbase.master.AssignmentManager$ServerHostRegion.values()"], ["org.apache.hadoop.hbase.master.AssignmentManager$ServerHostRegion", "org.apache.hadoop.hbase.master.AssignmentManager$ServerHostRegion.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.master.balancer.BalancerChore", "org.apache.hadoop.hbase.master.balancer.BalancerChore(org.apache.hadoop.hbase.master.HMaster)"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$AssignRegionAction", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$AssignRegionAction(int, int)"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$AssignRegionAction.undoAction()"], ["java.lang.String", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$AssignRegionAction.toString()"], ["org.apache.hadoop.hbase.master.balancer.ClusterLoadState", "org.apache.hadoop.hbase.master.balancer.ClusterLoadState(java.util.Map<org.apache.hadoop.hbase.ServerName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>>)"], ["org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan", "org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan()"], ["synchronized", "org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.void updateFavoredNodesMap(org.apache.hadoop.hbase.HRegionInfo, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan$Position", "org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.getFavoredServerPosition(java.util.List<org.apache.hadoop.hbase.ServerName>, org.apache.hadoop.hbase.ServerName)"], ["java.util.Map<org.apache.hadoop.hbase.HRegionInfo, java.util.List<org.apache.hadoop.hbase.ServerName>>", "org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.getAssignmentMap()"], ["synchronized", "org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.void updateAssignmentPlan(org.apache.hadoop.hbase.HRegionInfo, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["boolean", "org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.hashCode()"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder$1.load(org.apache.hadoop.hbase.HRegionInfo)"], ["com.google.common.util.concurrent.ListenableFuture", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder$1.reload(java.lang.Object, java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder$1.load(java.lang.Object)"], ["org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer$BalanceInfo", "org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer$BalanceInfo(int, int)"], ["org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer$RackLocalityCostFunction", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer$RackLocalityCostFunction(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.master.MasterServices)"], ["org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer$RegionReplicaHostCostFunction", "org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer$RegionReplicaHostCostFunction(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.master.BulkAssigner$1.uncaughtException(java.lang.Thread, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.master.CatalogJanitor.setEnabled(boolean)"], ["boolean", "org.apache.hadoop.hbase.master.CatalogJanitor.cleanMergeQualifier(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner", "org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner()"], ["synchronized", "org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner.boolean isFileDeletable(org.apache.hadoop.fs.FileStatus)"], ["synchronized", "org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner.void setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner", "org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner()"], ["void", "org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner.setConf(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner.isFileDeletable(org.apache.hadoop.fs.FileStatus)"], ["org.apache.hadoop.hbase.master.handler.ClosedRegionHandler$ClosedPriority[]", "org.apache.hadoop.hbase.master.handler.ClosedRegionHandler$ClosedPriority.values()"], ["org.apache.hadoop.hbase.master.handler.ClosedRegionHandler$ClosedPriority", "org.apache.hadoop.hbase.master.handler.ClosedRegionHandler$ClosedPriority.valueOf(java.lang.String)"], ["int", "org.apache.hadoop.hbase.master.handler.ClosedRegionHandler$ClosedPriority.getValue()"], ["org.apache.hadoop.hbase.master.handler.DispatchMergingRegionHandler", "org.apache.hadoop.hbase.master.handler.DispatchMergingRegionHandler(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.master.CatalogJanitor, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, boolean, org.apache.hadoop.hbase.security.User)"], ["void", "org.apache.hadoop.hbase.master.handler.DispatchMergingRegionHandler.process()"], ["void", "org.apache.hadoop.hbase.master.HMaster$InitializationMonitor.run()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$1.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$103.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$104.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$110.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$12.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$19.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$25.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$32.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$4.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$47.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$54.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$67.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$67.postEnvCall(org.apache.hadoop.hbase.master.MasterCoprocessorHost$MasterEnvironment)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$68.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$68.postEnvCall(org.apache.hadoop.hbase.master.MasterCoprocessorHost$MasterEnvironment)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$7.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$78.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$90.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$91.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$94.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$97.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["boolean", "org.apache.hadoop.hbase.master.MasterFileSystem$1.accept(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.master.MasterRpcServices", "org.apache.hadoop.hbase.master.MasterRpcServices(org.apache.hadoop.hbase.master.HMaster)"], ["boolean", "org.apache.hadoop.hbase.master.MasterRpcServices.normalizerSwitch(boolean)"], ["org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$GetLastFlushedSequenceIdResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getLastFlushedSequenceId(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$GetLastFlushedSequenceIdRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerReportResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.regionServerReport(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerReportRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStartupResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.regionServerStartup(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStartupRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$ReportRSFatalErrorResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.reportRSFatalError(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$ReportRSFatalErrorRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$AddColumnResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.addColumn(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$AddColumnRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$AssignRegionResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.assignRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$AssignRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$BalanceResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.balance(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$BalanceRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$CreateNamespaceResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.createNamespace(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$CreateNamespaceRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$CreateTableResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.createTable(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$CreateTableRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DeleteColumnResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.deleteColumn(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DeleteColumnRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DeleteNamespaceResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.deleteNamespace(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DeleteNamespaceRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DeleteSnapshotResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.deleteSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DeleteSnapshotRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DeleteTableResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.deleteTable(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DeleteTableRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$TruncateTableResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.truncateTable(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$TruncateTableRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DisableTableResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.disableTable(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DisableTableRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DispatchMergingRegionsResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.dispatchMergingRegions(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$DispatchMergingRegionsRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$EnableCatalogJanitorResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.enableCatalogJanitor(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$EnableCatalogJanitorRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetCleanerChoreRunningResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.setCleanerChoreRunning(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetCleanerChoreRunningRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$EnableTableResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.enableTable(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$EnableTableRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$CoprocessorServiceResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.execMasterService(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$CoprocessorServiceRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ExecProcedureResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.execProcedure(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ExecProcedureRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ExecProcedureResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.execProcedureWithRet(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ExecProcedureRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetClusterStatusResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getClusterStatus(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetClusterStatusRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetCompletedSnapshotsResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getCompletedSnapshots(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetCompletedSnapshotsRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetNamespaceDescriptorResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getNamespaceDescriptor(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetNamespaceDescriptorRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetSchemaAlterStatusResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getSchemaAlterStatus(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetSchemaAlterStatusRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetTableDescriptorsResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getTableDescriptors(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetTableDescriptorsRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetTableNamesResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getTableNames(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetTableNamesRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsCatalogJanitorEnabledResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.isCatalogJanitorEnabled(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsCatalogJanitorEnabledRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsCleanerChoreEnabledResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.isCleanerChoreEnabled(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsCleanerChoreEnabledRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsMasterRunningResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.isMasterRunning(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsMasterRunningRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsProcedureDoneResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.isProcedureDone(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsProcedureDoneRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsRestoreSnapshotDoneResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.isRestoreSnapshotDone(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsRestoreSnapshotDoneRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsSnapshotDoneResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.isSnapshotDone(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsSnapshotDoneRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetProcedureResultResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getProcedureResult(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$GetProcedureResultRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$AbortProcedureResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.abortProcedure(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$AbortProcedureRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ListProceduresResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.listProcedures(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ListProceduresRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ClearDeadServersResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.clearDeadServers(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ClearDeadServersRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ListNamespaceDescriptorsResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.listNamespaceDescriptors(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ListNamespaceDescriptorsRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ListTableDescriptorsByNamespaceResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.listTableDescriptorsByNamespace(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ListTableDescriptorsByNamespaceRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ListTableNamesByNamespaceResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.listTableNamesByNamespace(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ListTableNamesByNamespaceRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ModifyColumnResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.modifyColumn(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ModifyColumnRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ModifyNamespaceResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.modifyNamespace(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ModifyNamespaceRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ModifyTableResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.modifyTable(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ModifyTableRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MoveRegionResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.moveRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MoveRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$OfflineRegionResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.offlineRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$OfflineRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$RestoreSnapshotResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.restoreSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$RestoreSnapshotRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$RunCatalogScanResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.runCatalogScan(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$RunCatalogScanRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$RunCleanerChoreResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.runCleanerChore(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$RunCleanerChoreRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetBalancerRunningResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.setBalancerRunning(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetBalancerRunningRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ShutdownResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.shutdown(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$ShutdownRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SnapshotResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.snapshot(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SnapshotRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$StopMasterResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.stopMaster(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$StopMasterRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsInMaintenanceModeResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.isMasterInMaintenanceMode(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsInMaintenanceModeRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$UnassignRegionResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.unassignRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$UnassignRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$ReportRegionStateTransitionResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.reportRegionStateTransition(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$ReportRegionStateTransitionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MajorCompactionTimestampResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getLastMajorCompactionTimestamp(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MajorCompactionTimestampRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MajorCompactionTimestampResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getLastMajorCompactionTimestampForRegion(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MajorCompactionTimestampForRegionRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsBalancerEnabledResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.isBalancerEnabled(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsBalancerEnabledRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetSplitOrMergeEnabledResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.setSplitOrMergeEnabled(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetSplitOrMergeEnabledRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsSplitOrMergeEnabledResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.isSplitOrMergeEnabled(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsSplitOrMergeEnabledRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$NormalizeResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.normalize(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$NormalizeRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetNormalizerRunningResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.setNormalizerRunning(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetNormalizerRunningRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsNormalizerEnabledResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.isNormalizerEnabled(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$IsNormalizerEnabledRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetQuotaResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.setQuota(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetQuotaRequest)"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SecurityCapabilitiesResponse", "org.apache.hadoop.hbase.master.MasterRpcServices.getSecurityCapabilities(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SecurityCapabilitiesRequest)"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure$1.run()"], ["void", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure$BulkDisabler$1.run()"], ["org.apache.hadoop.hbase.master.procedure.DisableTableProcedure$BulkDisabler", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure$BulkDisabler(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["<T extends java.lang.Comparable<T>> org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$AvlTree.get(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>, T)"], ["<T extends java.lang.Comparable<T>> org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$AvlTree.getFirst(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>)"], ["<T extends java.lang.Comparable<T>> org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$AvlTree.getLast(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>)"], ["<T extends java.lang.Comparable<T>> org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$AvlTree.insert(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>, org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>)"], ["<T extends java.lang.Comparable<T>> org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$AvlTree.remove(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>, T)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$NamespaceQueue, int)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$NamespaceQueue", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.getNamespaceQueue()"], ["synchronized", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.boolean isAvailable()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.requireExclusiveLock(org.apache.hadoop.hbase.procedure2.Procedure)"], ["int", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.size()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.isEmpty()"], ["org.apache.hadoop.hbase.procedure2.Procedure", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.poll()"], ["org.apache.hadoop.hbase.procedure2.Procedure", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.peek()"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.add(org.apache.hadoop.hbase.procedure2.Procedure, boolean)"], ["java.lang.String", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.toString()"], ["int", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.compareTo(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.releaseExclusiveLock()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.tryExclusiveLock(long)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.releaseSharedLock()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.trySharedLock()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.hasExclusiveLock()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.isLocked()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$TableQueue.isSuspended()"], ["org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch", "org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch()"], ["org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch", "org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch.createLatch()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch.hasProcedureSupport()"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure$1.run()"], ["org.apache.hadoop.hbase.master.RegionPlan$RegionPlanComparator", "org.apache.hadoop.hbase.master.RegionPlan$RegionPlanComparator()"], ["int", "org.apache.hadoop.hbase.master.RegionPlan$RegionPlanComparator.compare(org.apache.hadoop.hbase.master.RegionPlan, org.apache.hadoop.hbase.master.RegionPlan)"], ["int", "org.apache.hadoop.hbase.master.RegionPlan$RegionPlanComparator.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.master.snapshot.SnapshotManager)"], ["org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler.prepare()"], ["org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler.prepare()"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler.prepare()"], ["org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.master.MasterServices)"], ["org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.prepare()"], ["void", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.process()"], ["void", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.completeSnapshot(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FileSystem)"], ["void", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.cancel(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.isFinished()"], ["long", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.getCompletionTimestamp()"], ["org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.getSnapshot()"], ["org.apache.hadoop.hbase.errorhandling.ForeignException", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.getExceptionIfFailed()"], ["void", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.rethrowExceptionIfFailed()"], ["void", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.rethrowException()"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.hasException()"], ["org.apache.hadoop.hbase.errorhandling.ForeignException", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.getException()"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.prepare()"], ["org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.ServerName, long, long, long)"], ["org.apache.hadoop.hbase.master.TableLockManager$TableLock", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager.writeLock(org.apache.hadoop.hbase.TableName, java.lang.String)"], ["org.apache.hadoop.hbase.master.TableLockManager$TableLock", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager.readLock(org.apache.hadoop.hbase.TableName, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager.visitAllLocks(org.apache.hadoop.hbase.InterProcessLock$MetadataHandler)"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager.reapWriteLocks()"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager.reapAllExpiredLocks()"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager.tableDeleted(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.MetaMigrationConvertingToPB", "org.apache.hadoop.hbase.MetaMigrationConvertingToPB()"], ["long", "org.apache.hadoop.hbase.MetaMigrationConvertingToPB.updateMetaIfNecessary(org.apache.hadoop.hbase.master.MasterServices)"], ["org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl()"], ["synchronized", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl clone()"], ["java.lang.String", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getStatus()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getRPCQueueTime()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getRPCStartTime()"], ["synchronized", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.java.lang.String getRPC()"], ["synchronized", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.java.lang.String getRPC(boolean)"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getRPCPacketLength()"], ["java.lang.String", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getClient()"], ["boolean", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.isRPCRunning()"], ["synchronized", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.boolean isOperationRunning()"], ["synchronized", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.void setRPC(java.lang.String, java.lang.Object[], long)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.setRPCPacket(com.google.protobuf.Message)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.setConnection(java.lang.String, int)"], ["synchronized", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.void markComplete(java.lang.String)"], ["java.util.Map<java.lang.String, java.lang.Object>", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.toMap()"], ["java.lang.String", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.toString()"], ["java.lang.String", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.toJSON()"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.expireNow()"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.cleanup()"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.setWarnTime(long)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.setDescription(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.setStatus(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.abort(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.resume(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.pause(java.lang.String)"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getCompletionTimestamp()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getWarnTime()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getStateTime()"], ["org.apache.hadoop.hbase.monitoring.MonitoredTask$State", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getState()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getStatusTime()"], ["java.lang.String", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getDescription()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.getStartTime()"], ["org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.clone()"], ["org.apache.hadoop.hbase.monitoring.MonitoredTask", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.clone()"], ["java.lang.Object", "org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.clone()"], ["org.apache.hadoop.hbase.monitoring.TaskMonitor$TaskAndWeakRefPair", "org.apache.hadoop.hbase.monitoring.TaskMonitor$TaskAndWeakRefPair(org.apache.hadoop.hbase.monitoring.MonitoredTask, org.apache.hadoop.hbase.monitoring.MonitoredTask)"], ["org.apache.hadoop.hbase.monitoring.MonitoredTask", "org.apache.hadoop.hbase.monitoring.TaskMonitor$TaskAndWeakRefPair.get()"], ["boolean", "org.apache.hadoop.hbase.monitoring.TaskMonitor$TaskAndWeakRefPair.isDead()"], ["org.apache.hadoop.hbase.procedure.MasterProcedureManagerHost", "org.apache.hadoop.hbase.procedure.MasterProcedureManagerHost()"], ["void", "org.apache.hadoop.hbase.procedure.MasterProcedureManagerHost.loadProcedures(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.procedure.MasterProcedureManagerHost.initialize(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.master.MetricsMaster)"], ["void", "org.apache.hadoop.hbase.procedure.MasterProcedureManagerHost.stop(java.lang.String)"], ["org.apache.hadoop.hbase.procedure.MasterProcedureManager", "org.apache.hadoop.hbase.procedure.MasterProcedureManagerHost.getProcedureManager(java.lang.String)"], ["org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter", "org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter()"], ["long", "org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter.refill(long)"], ["long", "org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter.getWaitInterval(long, long, long)"], ["void", "org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter.setNextRefillTime(long)"], ["long", "org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter.getNextRefillTime()"], ["org.apache.hadoop.hbase.quotas.MasterQuotaManager", "org.apache.hadoop.hbase.quotas.MasterQuotaManager(org.apache.hadoop.hbase.master.MasterServices)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.start()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.stop()"], ["boolean", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.isQuotaInitialized()"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetQuotaResponse", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.setQuota(org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetQuotaRequest)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.setUserQuota(java.lang.String, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetQuotaRequest)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.setUserQuota(java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetQuotaRequest)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.setUserQuota(java.lang.String, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetQuotaRequest)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.setTableQuota(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetQuotaRequest)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.setNamespaceQuota(java.lang.String, org.apache.hadoop.hbase.protobuf.generated.MasterProtos$SetQuotaRequest)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.setNamespaceQuota(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.removeNamespaceQuota(java.lang.String)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.checkNamespaceTableAndRegionQuota(org.apache.hadoop.hbase.TableName, int)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.checkAndUpdateNamespaceRegionQuota(org.apache.hadoop.hbase.TableName, int)"], ["int", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.getRegionCountOfTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.onRegionMerged(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.onRegionSplit(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.removeTableFromNamespaceQuota(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.namespace.NamespaceAuditor", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.getNamespaceQuotaManager()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager.onRegionSplitReverted(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.quotas.QuotaState", "org.apache.hadoop.hbase.quotas.QuotaState()"], ["org.apache.hadoop.hbase.quotas.QuotaState", "org.apache.hadoop.hbase.quotas.QuotaState(long)"], ["synchronized", "org.apache.hadoop.hbase.quotas.QuotaState.long getLastUpdate()"], ["synchronized", "org.apache.hadoop.hbase.quotas.QuotaState.long getLastQuery()"], ["synchronized", "org.apache.hadoop.hbase.quotas.QuotaState.java.lang.String toString()"], ["synchronized", "org.apache.hadoop.hbase.quotas.QuotaState.boolean isBypass()"], ["synchronized", "org.apache.hadoop.hbase.quotas.QuotaState.void setQuotas(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["synchronized", "org.apache.hadoop.hbase.quotas.QuotaState.void update(org.apache.hadoop.hbase.quotas.QuotaState)"], ["synchronized", "org.apache.hadoop.hbase.quotas.QuotaState.org.apache.hadoop.hbase.quotas.QuotaLimiter getGlobalLimiter()"], ["synchronized", "org.apache.hadoop.hbase.quotas.QuotaState.void setLastQuery(long)"], ["void", "org.apache.hadoop.hbase.quotas.TimeBasedLimiter.update(org.apache.hadoop.hbase.quotas.TimeBasedLimiter)"], ["void", "org.apache.hadoop.hbase.quotas.TimeBasedLimiter.checkQuota(long, long, long, long)"], ["void", "org.apache.hadoop.hbase.quotas.TimeBasedLimiter.grabQuota(long, long, long, long)"], ["void", "org.apache.hadoop.hbase.quotas.TimeBasedLimiter.consumeWrite(long)"], ["void", "org.apache.hadoop.hbase.quotas.TimeBasedLimiter.consumeRead(long)"], ["boolean", "org.apache.hadoop.hbase.quotas.TimeBasedLimiter.isBypass()"], ["long", "org.apache.hadoop.hbase.quotas.TimeBasedLimiter.getWriteAvailable()"], ["long", "org.apache.hadoop.hbase.quotas.TimeBasedLimiter.getReadAvailable()"], ["java.lang.String", "org.apache.hadoop.hbase.quotas.TimeBasedLimiter.toString()"], ["org.apache.hadoop.hbase.regionserver.compactions.AbstractMultiOutputCompactor", "org.apache.hadoop.hbase.regionserver.compactions.AbstractMultiOutputCompactor(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.Store)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionWindow", "org.apache.hadoop.hbase.regionserver.compactions.CompactionWindow()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.compactions.CompactionWindow.toString()"], ["org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionRequest(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, java.util.List<java.lang.Long>)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionRequest.toString()"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours$OffPeakHoursImpl.isOffPeakHour()"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours$OffPeakHoursImpl.isOffPeakHour(int)"], ["org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy", "org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.StoreConfigInformation)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.shouldPerformMajorCompaction(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.needsCompaction(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.setMinThreshold(int)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.Store)"], ["org.apache.hadoop.hbase.regionserver.CompactionTool", "org.apache.hadoop.hbase.regionserver.CompactionTool()"], ["int", "org.apache.hadoop.hbase.regionserver.CompactionTool.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.regionserver.CompactionTool.main(java.lang.String[])"], ["org.apache.hadoop.hbase.regionserver.DateTieredStoreEngine", "org.apache.hadoop.hbase.regionserver.DateTieredStoreEngine()"], ["boolean", "org.apache.hadoop.hbase.regionserver.DateTieredStoreEngine.needsCompaction(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionContext", "org.apache.hadoop.hbase.regionserver.DateTieredStoreEngine.createCompaction()"], ["org.apache.hadoop.hbase.regionserver.DefaultMemStore", "org.apache.hadoop.hbase.regionserver.DefaultMemStore()"], ["org.apache.hadoop.hbase.regionserver.DefaultMemStore", "org.apache.hadoop.hbase.regionserver.DefaultMemStore(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["org.apache.hadoop.hbase.regionserver.MemStoreSnapshot", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.snapshot()"], ["void", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.clearSnapshot(long)"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.getFlushableSize()"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.getSnapshotSize()"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.add(org.apache.hadoop.hbase.Cell)"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.add(java.lang.Iterable<org.apache.hadoop.hbase.Cell>)"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.timeOfOldestEdit()"], ["void", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.rollback(org.apache.hadoop.hbase.Cell)"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.delete(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.getRowKeyAtOrBefore(org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker)"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.updateColumnValue(byte[], byte[], byte[], long, long)"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.upsert(java.lang.Iterable<org.apache.hadoop.hbase.Cell>, long, java.util.List<org.apache.hadoop.hbase.Cell>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.shouldSeek(org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.Store, long)"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.heapSize()"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.size()"], ["void", "org.apache.hadoop.hbase.regionserver.DefaultMemStore.main(java.lang.String[])"], ["org.apache.hadoop.hbase.regionserver.FlushAllStoresPolicy", "org.apache.hadoop.hbase.regionserver.FlushAllStoresPolicy()"], ["boolean", "org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.isDeleted(org.apache.hadoop.hbase.Cell, java.util.NavigableSet<org.apache.hadoop.hbase.KeyValue>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.isExpired(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.hasCandidate()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.getCandidate()"], ["org.apache.hadoop.hbase.KeyValue", "org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.getTargetKey()"], ["org.apache.hadoop.hbase.regionserver.handler.RegionReplicaFlushHandler", "org.apache.hadoop.hbase.regionserver.handler.RegionReplicaFlushHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.client.ClusterConnection, org.apache.hadoop.hbase.client.RpcRetryingCallerFactory, org.apache.hadoop.hbase.ipc.RpcControllerFactory, int, org.apache.hadoop.hbase.regionserver.HRegion)"], ["void", "org.apache.hadoop.hbase.regionserver.handler.RegionReplicaFlushHandler.process()"], ["org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB", "org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB()"], ["org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB", "org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.util.ByteRange", "org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB.allocateBytes(int)"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB.close()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB.incScannerCount()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB.decScannerCount()"], ["org.apache.hadoop.hbase.regionserver.HRegion$MutationBatch", "org.apache.hadoop.hbase.regionserver.HRegion$MutationBatch(org.apache.hadoop.hbase.client.Mutation[], long, long)"], ["org.apache.hadoop.hbase.client.Mutation", "org.apache.hadoop.hbase.regionserver.HRegion$MutationBatch.getMutation(int)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion$MutationBatch.getNonceGroup(int)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion$MutationBatch.getNonce(int)"], ["org.apache.hadoop.hbase.client.Mutation[]", "org.apache.hadoop.hbase.regionserver.HRegion$MutationBatch.getMutationsForCoprocs()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion$MutationBatch.isInReplay()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion$MutationBatch.getReplaySequenceId()"], ["org.apache.hadoop.hbase.regionserver.Region$FlushResult", "org.apache.hadoop.hbase.regionserver.HRegion$PrepareFlushResult.getResult()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion$RowLockContext.setThreadName(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.HRegion$RowLockContext.toString()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.HRegionServer$3.run()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer$MovedRegionsCleaner$1.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegionServer$MovedRegionsCleaner$1.isStopped()"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.HStore$5.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.HStore$5.run()"], ["org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy", "org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy()"], ["void", "org.apache.hadoop.hbase.regionserver.LogRoller.addWAL(org.apache.hadoop.hbase.wal.WAL)"], ["void", "org.apache.hadoop.hbase.regionserver.LogRoller.requestRollAll()"], ["org.apache.hadoop.hbase.regionserver.LogRoller", "org.apache.hadoop.hbase.regionserver.LogRoller(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["void", "org.apache.hadoop.hbase.regionserver.LogRoller.interrupt()"], ["void", "org.apache.hadoop.hbase.regionserver.LogRoller.run()"], ["boolean", "org.apache.hadoop.hbase.regionserver.LogRoller.walRollFinished()"], ["org.apache.hadoop.hbase.regionserver.MemStoreFlusher", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["org.apache.hadoop.hbase.util.Counter", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.getUpdatesBlockedMsHighWater()"], ["void", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.requestFlush(org.apache.hadoop.hbase.regionserver.Region, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.requestDelayedFlush(org.apache.hadoop.hbase.regionserver.Region, long, boolean)"], ["int", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.getFlushQueueSize()"], ["void", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.reclaimMemStoreMemory()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.toString()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.dumpQueue()"], ["void", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.registerFlushRequestListener(org.apache.hadoop.hbase.regionserver.FlushRequestListener)"], ["boolean", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.unregisterFlushRequestListener(org.apache.hadoop.hbase.regionserver.FlushRequestListener)"], ["void", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.setGlobalMemstoreLimit(long)"], ["long", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher.getMemoryLimit()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.getTotalRequestsCount()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.setTotalRequestsCount(long)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.getReadRequestsCount()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.setReadRequestsCount(long)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.getWriteRequestsCount()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.setWriteRequestsCount(long)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.getMemstoresSize()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.setMemstoresSize(long)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.getStoreFilesSize()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.setStoreFilesSize(long)"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.getTableSize()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl$MetricsTableValues.setTableSize(long)"], ["long", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl$WriteEntry.getWriteNumber()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl$WriteEntry.toString()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount", "org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount(byte[])"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount", "org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount(byte[], int)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount", "org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount(byte[], int, int, int)"], ["byte[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount.getBuffer()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount.getOffset()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount.getLength()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount.decrement()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount.increment()"], ["void", "org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount.setCount(int)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.MajorCompactionScanQueryMatcher", "org.apache.hadoop.hbase.regionserver.querymatcher.MajorCompactionScanQueryMatcher(org.apache.hadoop.hbase.regionserver.ScanInfo, org.apache.hadoop.hbase.regionserver.DeleteTracker, long, long, long, long)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.MajorCompactionScanQueryMatcher.match(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.NormalUserScanQueryMatcher.match(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.NormalUserScanQueryMatcher", "org.apache.hadoop.hbase.regionserver.querymatcher.NormalUserScanQueryMatcher.create(org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.ScanInfo, org.apache.hadoop.hbase.regionserver.querymatcher.ColumnTracker, boolean, long, long, org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost)"], ["byte[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getRowArray()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getRowOffset()"], ["short", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getRowLength()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getFamilyArray()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getFamilyOffset()"], ["byte", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getFamilyLength()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getQualifierArray()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getQualifierOffset()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getQualifierLength()"], ["long", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getTimestamp()"], ["byte", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getTypeByte()"], ["long", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getMvccVersion()"], ["long", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getSequenceId()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getValueArray()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getValueOffset()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getValueLength()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getTagsArray()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getTagsOffset()"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getTagsLength()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getValue()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getFamily()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getQualifier()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$1.getRow()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.StripeCompactionScanQueryMatcher", "org.apache.hadoop.hbase.regionserver.querymatcher.StripeCompactionScanQueryMatcher(org.apache.hadoop.hbase.regionserver.ScanInfo, org.apache.hadoop.hbase.regionserver.DeleteTracker, long, long, long, long, byte[], byte[])"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.StripeCompactionScanQueryMatcher.match(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.Region$FlushResult$Result[]", "org.apache.hadoop.hbase.regionserver.Region$FlushResult$Result.values()"], ["org.apache.hadoop.hbase.regionserver.Region$FlushResult$Result", "org.apache.hadoop.hbase.regionserver.Region$FlushResult$Result.valueOf(java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$11.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$18.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$30.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$38.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$45.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$52.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$6.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$67.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$CoprocessorOperation.postEnvCall(org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.RegionMergeRequest.toString()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionMergeRequest.run()"], ["java.lang.Boolean", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$3.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$3.run()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$11.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$CoprocessOperationWithResult.setResult(T)"], ["T", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$CoprocessOperationWithResult.getResult()"], ["org.apache.hadoop.hbase.regionserver.RowTooBigException", "org.apache.hadoop.hbase.regionserver.RowTooBigException(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.ScannerContext$LimitFields.toString()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext.toString()"], ["org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext", "org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext()"], ["void", "org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext.setState(int)"], ["int", "org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext.getState()"], ["void", "org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext.setHasWait()"], ["boolean", "org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext.hasWait()"], ["void", "org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext.reportActivity()"], ["boolean", "org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext.isExpired(long)"], ["void", "org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext.setMvcc(long)"], ["long", "org.apache.hadoop.hbase.regionserver.ServerNonceManager$OperationContext.getMvcc()"], ["org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure$RegionSnapshotTask", "org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure$RegionSnapshotTask(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, boolean, org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher)"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure$RegionSnapshotTask.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure$RegionSnapshotTask.call()"], ["org.apache.hadoop.hbase.regionserver.SplitLogWorker", "org.apache.hadoop.hbase.regionserver.SplitLogWorker(org.apache.hadoop.hbase.Server, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.regionserver.SplitLogWorker$TaskExecutor)"], ["org.apache.hadoop.hbase.regionserver.SplitLogWorker", "org.apache.hadoop.hbase.regionserver.SplitLogWorker(org.apache.hadoop.hbase.Server, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.regionserver.LastSequenceId, org.apache.hadoop.hbase.wal.WALFactory)"], ["void", "org.apache.hadoop.hbase.regionserver.SplitLogWorker.run()"], ["void", "org.apache.hadoop.hbase.regionserver.SplitLogWorker.stopTask()"], ["void", "org.apache.hadoop.hbase.regionserver.SplitLogWorker.start()"], ["void", "org.apache.hadoop.hbase.regionserver.SplitLogWorker.stop()"], ["int", "org.apache.hadoop.hbase.regionserver.SplitLogWorker.getTaskReadySeq()"], ["java.lang.Boolean", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$2.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$2.run()"], ["boolean", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$LoggingProgressable.progress()"], ["java.lang.Long", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators$GetBulkTime.apply(org.apache.hadoop.hbase.regionserver.StoreFile)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators$GetBulkTime.apply(java.lang.Object)"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Writer.appendMetadata(long, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Writer.appendTrackedTimestampsToMetadata()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Writer.trackTimestamps(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Writer.append(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.StoreFile$Writer.getPath()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Writer.close()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Writer.appendFileInfo(byte[], byte[])"], ["org.apache.hadoop.hbase.regionserver.StoreScanner", "org.apache.hadoop.hbase.regionserver.StoreScanner(org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.ScanInfo, org.apache.hadoop.hbase.client.Scan, java.util.NavigableSet<byte[]>, long)"], ["org.apache.hadoop.hbase.regionserver.StoreScanner", "org.apache.hadoop.hbase.regionserver.StoreScanner(org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.ScanInfo, org.apache.hadoop.hbase.client.Scan, java.util.List<? extends org.apache.hadoop.hbase.regionserver.KeyValueScanner>, org.apache.hadoop.hbase.regionserver.ScanType, long, long)"], ["org.apache.hadoop.hbase.regionserver.StoreScanner", "org.apache.hadoop.hbase.regionserver.StoreScanner(org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.ScanInfo, org.apache.hadoop.hbase.client.Scan, java.util.List<? extends org.apache.hadoop.hbase.regionserver.KeyValueScanner>, long, long, byte[], byte[])"], ["org.apache.hadoop.hbase.regionserver.StoreScanner", "org.apache.hadoop.hbase.regionserver.StoreScanner(org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.ScanInfo, org.apache.hadoop.hbase.regionserver.ScanType, java.util.NavigableSet<byte[]>, java.util.List<org.apache.hadoop.hbase.regionserver.KeyValueScanner>, long, long)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.StoreScanner.peek()"], ["org.apache.hadoop.hbase.KeyValue", "org.apache.hadoop.hbase.regionserver.StoreScanner.next()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreScanner.close()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreScanner.seek(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreScanner.next(java.util.List<org.apache.hadoop.hbase.Cell>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreScanner.next(java.util.List<org.apache.hadoop.hbase.Cell>, org.apache.hadoop.hbase.regionserver.ScannerContext)"], ["long", "org.apache.hadoop.hbase.regionserver.StoreScanner.getReadPoint()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreScanner.updateReaders(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>, java.util.List<org.apache.hadoop.hbase.regionserver.KeyValueScanner>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(org.apache.hadoop.hbase.Cell)"], ["long", "org.apache.hadoop.hbase.regionserver.StoreScanner.getScannerOrder()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreScanner.getEstimatedNumberOfKvsScanned()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.StoreScanner.getNextIndexedKey()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.StoreScanner.next()"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Writer", "org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$1.createWriter()"], ["org.apache.hadoop.hbase.regionserver.throttle.ThroughputController", "org.apache.hadoop.hbase.regionserver.throttle.FlushThroughputControllerFactory.create(org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.conf.Configuration)"], ["java.lang.Class<? extends org.apache.hadoop.hbase.regionserver.throttle.ThroughputController>", "org.apache.hadoop.hbase.regionserver.throttle.FlushThroughputControllerFactory.getThroughputControllerClass(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.throttle.PressureAwareThroughputController", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareThroughputController()"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareThroughputController.start(java.lang.String)"], ["long", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareThroughputController.control(java.lang.String, long)"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareThroughputController.finish(java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareThroughputController.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareThroughputController.isStopped()"], ["double", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareThroughputController.getMaxThroughput()"], ["void", "org.apache.hadoop.hbase.regionserver.throttle.PressureAwareThroughputController.setMaxThroughput(double)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(org.apache.hadoop.hbase.regionserver.wal.RingBufferTruck, long, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onStart()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onShutdown()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(java.lang.Object, long, boolean)"], ["org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter", "org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter()"], ["org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter", "org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter(boolean, boolean, long, java.lang.String, java.lang.String, boolean, java.io.PrintStream)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter.main(java.lang.String[])"], ["org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader$WALHdrResult[]", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader$WALHdrResult.values()"], ["org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader$WALHdrResult", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader$WALHdrResult.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader", "org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.wal.SyncFuture.java.lang.String toString()"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.SyncFuture.cancel(boolean)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.wal.SyncFuture.long get(long)"], ["java.lang.Long", "org.apache.hadoop.hbase.regionserver.wal.SyncFuture.get(long, java.util.concurrent.TimeUnit)"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.SyncFuture.isCancelled()"], ["com.google.protobuf.ByteString", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$BaosAndCompressor.toByteString()"], ["com.google.protobuf.ByteString", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$BaosAndCompressor.compress(byte[], org.apache.hadoop.hbase.io.util.Dictionary)"], ["org.apache.hadoop.hbase.wal.WAL", "org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost$WALEnvironment.getWAL()"], ["org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost$WALEnvironment", "org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost$WALEnvironment(java.lang.Class<?>, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.wal.WAL)"], ["org.apache.hadoop.hbase.metrics.MetricRegistry", "org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost$WALEnvironment.getMetricRegistryForRegionServer()"], ["org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint$PeerRegionServerListener", "org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint$PeerRegionServerListener(org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint)"], ["synchronized", "org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint$PeerRegionServerListener.void nodeChildrenChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner$WarnOnlyAbortable.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner$WarnOnlyAbortable.isAborted()"], ["org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues$DumpOptions", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues$DumpOptions()"], ["org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues$DumpOptions", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues$DumpOptions(org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues$DumpOptions)"], ["org.apache.hadoop.hbase.replication.regionserver.HFileReplicator", "org.apache.hadoop.hbase.replication.regionserver.HFileReplicator(org.apache.hadoop.conf.Configuration, java.lang.String, java.lang.String, java.util.Map<java.lang.String, java.util.List<org.apache.hadoop.hbase.util.Pair<byte[], java.util.List<java.lang.String>>>>, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.client.Connection)"], ["java.lang.Void", "org.apache.hadoop.hbase.replication.regionserver.HFileReplicator.replicate()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad", "org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad.buildReplicationLoad(java.util.List<org.apache.hadoop.hbase.replication.regionserver.MetricsSource>, org.apache.hadoop.hbase.replication.regionserver.MetricsSink)"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad.sourceToString()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad.sinkToString()"], ["org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos$ReplicationLoadSink", "org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad.getReplicationLoadSink()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad.toString()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$1.uncaughtException(java.lang.Thread, java.lang.Throwable)"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSource", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.init(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager, org.apache.hadoop.hbase.replication.ReplicationQueues, org.apache.hadoop.hbase.replication.ReplicationPeers, org.apache.hadoop.hbase.Stoppable, java.lang.String, java.util.UUID, org.apache.hadoop.hbase.replication.ReplicationEndpoint, org.apache.hadoop.hbase.replication.regionserver.MetricsSource)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.enqueueLog(org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.addHFileRefs(org.apache.hadoop.hbase.TableName, byte[], java.util.List<org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path>>)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.startup()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.terminate(java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.terminate(java.lang.String, java.lang.Exception)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.terminate(java.lang.String, java.lang.Exception, boolean)"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.getPeerClusterZnode()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.getPeerClusterId()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.getCurrentPath()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.getStats()"], ["org.apache.hadoop.hbase.replication.regionserver.MetricsSource", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.getSourceMetrics()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationThrottler", "org.apache.hadoop.hbase.replication.regionserver.ReplicationThrottler(double)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.ReplicationThrottler.isEnabled()"], ["long", "org.apache.hadoop.hbase.replication.regionserver.ReplicationThrottler.getNextSleepInterval(int)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationThrottler.addPushSize(int)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationThrottler.resetStartTick()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationThrottler.setBandwidth(double)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessChecker.isAuthorizationSupported(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.security.access.AccessChecker", "org.apache.hadoop.hbase.security.access.AccessChecker(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["org.apache.hadoop.hbase.security.access.TableAuthManager", "org.apache.hadoop.hbase.security.access.AccessChecker.getAuthManager()"], ["void", "org.apache.hadoop.hbase.security.access.AccessChecker.logResult(org.apache.hadoop.hbase.security.access.AuthResult)"], ["void", "org.apache.hadoop.hbase.security.access.AccessChecker.requirePermission(org.apache.hadoop.hbase.security.User, java.lang.String, org.apache.hadoop.hbase.TableName, byte[], byte[], org.apache.hadoop.hbase.security.access.Permission$Action...)"], ["void", "org.apache.hadoop.hbase.security.access.AccessChecker.requireTablePermission(org.apache.hadoop.hbase.security.User, java.lang.String, org.apache.hadoop.hbase.TableName, byte[], byte[], org.apache.hadoop.hbase.security.access.Permission$Action...)"], ["void", "org.apache.hadoop.hbase.security.access.AccessChecker.requireAccess(org.apache.hadoop.hbase.security.User, java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.security.access.Permission$Action...)"], ["void", "org.apache.hadoop.hbase.security.access.AccessChecker.requirePermission(org.apache.hadoop.hbase.security.User, java.lang.String, org.apache.hadoop.hbase.security.access.Permission$Action)"], ["void", "org.apache.hadoop.hbase.security.access.AccessChecker.requireGlobalPermission(org.apache.hadoop.hbase.security.User, java.lang.String, org.apache.hadoop.hbase.security.access.Permission$Action, org.apache.hadoop.hbase.TableName, java.util.Map<byte[], ? extends java.util.Collection<byte[]>>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessChecker.requireGlobalPermission(org.apache.hadoop.hbase.security.User, java.lang.String, org.apache.hadoop.hbase.security.access.Permission$Action, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessChecker.requireNamespacePermission(org.apache.hadoop.hbase.security.User, java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.access.Permission$Action...)"], ["void", "org.apache.hadoop.hbase.security.access.AccessChecker.requireNamespacePermission(org.apache.hadoop.hbase.security.User, java.lang.String, java.lang.String, org.apache.hadoop.hbase.TableName, java.util.Map<byte[], ? extends java.util.Collection<byte[]>>, org.apache.hadoop.hbase.security.access.Permission$Action...)"], ["java.lang.Void", "org.apache.hadoop.hbase.security.access.AccessController$3.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$3.run()"], ["org.apache.hadoop.hbase.security.access.AccessController", "org.apache.hadoop.hbase.security.access.AccessController()"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessController.isAuthorizationSupported(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessController.isCellAuthorizationSupported(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.Region", "org.apache.hadoop.hbase.security.access.AccessController.getRegion()"], ["org.apache.hadoop.hbase.security.access.TableAuthManager", "org.apache.hadoop.hbase.security.access.AccessController.getAuthManager()"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.requirePermission(java.lang.String, org.apache.hadoop.hbase.TableName, byte[], byte[], org.apache.hadoop.hbase.security.access.Permission$Action...)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.requireTablePermission(java.lang.String, org.apache.hadoop.hbase.TableName, byte[], byte[], org.apache.hadoop.hbase.security.access.Permission$Action...)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.requireAccess(java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.security.access.Permission$Action...)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.requirePermission(java.lang.String, org.apache.hadoop.hbase.security.access.Permission$Action)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.requireGlobalPermission(java.lang.String, org.apache.hadoop.hbase.security.access.Permission$Action, org.apache.hadoop.hbase.TableName, java.util.Map<byte[], ? extends java.util.Collection<byte[]>>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.requireGlobalPermission(java.lang.String, org.apache.hadoop.hbase.security.access.Permission$Action, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.requireNamespacePermission(java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.access.Permission$Action...)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.requireNamespacePermission(java.lang.String, java.lang.String, org.apache.hadoop.hbase.TableName, java.util.Map<byte[], ? extends java.util.Collection<byte[]>>, org.apache.hadoop.hbase.security.access.Permission$Action...)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preCreateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postCreateTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preDeleteTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postDeleteTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preTruncateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postTruncateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preModifyTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postModifyTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preAddColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preModifyColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preDeleteColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postDeleteColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preEnableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preDisableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preAbortProcedure(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.procedure2.ProcedureExecutor<org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv>, long)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postAbortProcedure(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preListProcedures(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postListProcedures(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.ProcedureInfo>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preMove(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preAssign(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preUnassign(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preRegionOffline(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessController.preSetSplitOrMergeEnabled(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postSetSplitOrMergeEnabled(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preBalance(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessController.preBalanceSwitch(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preShutdown(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preStopMaster(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postStartMaster(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preListSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preCloneSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preRestoreSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preDeleteSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preCreateNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preDeleteNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postDeleteNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preModifyNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preGetNamespaceDescriptor(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postListNamespaceDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.NamespaceDescriptor>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preTableFlush(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postLogReplay(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preFlush(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[])"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.security.access.AccessController.preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.ScanType)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preGetClosestRowBefore(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], org.apache.hadoop.hbase.client.Result)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preGetOp(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Get, java.util.List<org.apache.hadoop.hbase.Cell>)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessController.preExists(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Get, boolean)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.prePut(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Put, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postPut(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Put, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preDelete(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Delete, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preBatchMutate(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postDelete(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Delete, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessController.preCheckAndPut(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Put, boolean)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessController.preCheckAndPutAfterRowLock(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Put, boolean)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessController.preCheckAndDelete(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Delete, boolean)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessController.preCheckAndDeleteAfterRowLock(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Delete, boolean)"], ["long", "org.apache.hadoop.hbase.security.access.AccessController.preIncrementColumnValue(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], long, boolean)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.security.access.AccessController.preAppend(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Append)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.security.access.AccessController.preAppendAfterRowLock(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Append)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.security.access.AccessController.preIncrement(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Increment)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.security.access.AccessController.preIncrementAfterRowLock(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Increment)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.security.access.AccessController.postMutationBeforeWAL(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.coprocessor.RegionObserver$MutationType, org.apache.hadoop.hbase.client.Mutation, org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.security.access.AccessController.preScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.RegionScanner)"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.security.access.AccessController.postScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.RegionScanner)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessController.preScannerNext(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner, java.util.List<org.apache.hadoop.hbase.client.Result>, int, boolean)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preScannerClose(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postScannerClose(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preBulkLoadHFile(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.util.Pair<byte[], java.lang.String>>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.prePrepareBulkLoad(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos$PrepareBulkLoadRequest)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preCleanupBulkLoad(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos$CleanupBulkLoadRequest)"], ["com.google.protobuf.Message", "org.apache.hadoop.hbase.security.access.AccessController.preEndpointInvocation(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, com.google.protobuf.Service, java.lang.String, com.google.protobuf.Message)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postEndpointInvocation(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, com.google.protobuf.Service, java.lang.String, com.google.protobuf.Message, com.google.protobuf.Message$Builder)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.grant(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos$GrantRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos$GrantResponse>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.revoke(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos$RevokeRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos$RevokeResponse>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.getUserPermissions(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos$GetUserPermissionsRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos$GetUserPermissionsResponse>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.checkPermissions(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos$CheckPermissionsRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos$CheckPermissionsResponse>)"], ["com.google.protobuf.Service", "org.apache.hadoop.hbase.security.access.AccessController.getService()"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preClose(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, boolean)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preStopRegionServer(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preGetTableDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postGetTableDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postGetTableNames(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preDispatchMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preClearDeadServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postClearDeadServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.ServerName>, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preMergeCommit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, java.util.List<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postMergeCommit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preRollBackMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postRollBackMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preRollWALWriterRequest(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postRollWALWriterRequest(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.replication.ReplicationEndpoint", "org.apache.hadoop.hbase.security.access.AccessController.postCreateReplicationEndPoint(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.replication.ReplicationEndpoint)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preReplicateLogEntries(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.protobuf.generated.AdminProtos$WALEntry>, org.apache.hadoop.hbase.CellScanner)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.postReplicateLogEntries(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.protobuf.generated.AdminProtos$WALEntry>, org.apache.hadoop.hbase.CellScanner)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preSetTableQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preSetNamespaceQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preMoveServersAndTables(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preMoveServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preMoveTables(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preRemoveServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preAddRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preRemoveRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.access.AccessController.preBalanceRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["org.apache.hadoop.hbase.security.visibility.expression.Operator[]", "org.apache.hadoop.hbase.security.visibility.expression.Operator.values()"], ["org.apache.hadoop.hbase.security.visibility.expression.Operator", "org.apache.hadoop.hbase.security.visibility.expression.Operator.valueOf(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.security.visibility.expression.Operator.toString()"], ["org.apache.hadoop.hbase.security.visibility.VisibilityController$VisibilityReplication", "org.apache.hadoop.hbase.security.visibility.VisibilityController$VisibilityReplication()"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController$VisibilityReplication.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityController$VisibilityReplication.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["org.apache.hadoop.hbase.replication.ReplicationEndpoint", "org.apache.hadoop.hbase.security.visibility.VisibilityController$VisibilityReplication.postCreateReplicationEndPoint(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>, org.apache.hadoop.hbase.replication.ReplicationEndpoint)"], ["org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint(org.apache.hadoop.hbase.replication.ReplicationEndpoint, org.apache.hadoop.hbase.security.visibility.VisibilityLabelService)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.init(org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context)"], ["boolean", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.replicate(org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext)"], ["synchronized", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.java.util.UUID getPeerUUID()"], ["boolean", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.canReplicateToSameCluster()"], ["org.apache.hadoop.hbase.replication.WALEntryFilter", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.getWALEntryfilter()"], ["boolean", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.isRunning()"], ["com.google.common.util.concurrent.Service$State", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.startAndWait()"], ["com.google.common.util.concurrent.Service$State", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.state()"], ["com.google.common.util.concurrent.Service$State", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.stopAndWait()"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.peerConfigUpdated(org.apache.hadoop.hbase.replication.ReplicationPeerConfig)"], ["int", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$2.compare(org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotFileInfo, java.lang.Long>, org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotFileInfo, java.lang.Long>)"], ["int", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$2.compare(java.lang.Object, java.lang.Object)"], ["void", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotRecordReader.close()"], ["org.apache.hadoop.io.BytesWritable", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotRecordReader.getCurrentKey()"], ["org.apache.hadoop.io.NullWritable", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotRecordReader.getCurrentValue()"], ["float", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotRecordReader.getProgress()"], ["void", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotRecordReader.initialize(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["boolean", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotRecordReader.nextKeyValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotRecordReader.getCurrentValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat$ExportSnapshotRecordReader.getCurrentKey()"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$RestoreMetaChanges.getTableDescriptor()"], ["boolean", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$RestoreMetaChanges.hasRegionsToAdd()"], ["boolean", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$RestoreMetaChanges.hasRegionsToRestore()"], ["boolean", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$RestoreMetaChanges.hasRegionsToRemove()"], ["void", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$RestoreMetaChanges.updateMetaParentRegions(org.apache.hadoop.hbase.client.Connection, java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["long", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.getMaxMasterTimeout(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription$Type, long)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.getSnapshotRootDir(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.getCompletedSnapshotDir(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.getCompletedSnapshotDir(java.lang.String, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.getWorkingSnapshotDir(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.getWorkingSnapshotDir(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.getWorkingSnapshotDir(java.lang.String, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.getSnapshotsDir(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.validate(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.writeSnapshotInfo(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FileSystem)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.createInProgressTag(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.readSnapshotInfo(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.completeSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FileSystem)"], ["boolean", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.isSnapshotOwner(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.security.User)"], ["boolean", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.isSecurityAvailable(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$1.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV1$1.call()"], ["org.apache.hadoop.hbase.SplitLogTask$Resigned", "org.apache.hadoop.hbase.SplitLogTask$Resigned(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode)"], ["org.apache.hadoop.hbase.TagRewriteCell", "org.apache.hadoop.hbase.TagRewriteCell(org.apache.hadoop.hbase.Cell, byte[])"], ["byte[]", "org.apache.hadoop.hbase.TagRewriteCell.getRowArray()"], ["int", "org.apache.hadoop.hbase.TagRewriteCell.getRowOffset()"], ["short", "org.apache.hadoop.hbase.TagRewriteCell.getRowLength()"], ["byte[]", "org.apache.hadoop.hbase.TagRewriteCell.getFamilyArray()"], ["int", "org.apache.hadoop.hbase.TagRewriteCell.getFamilyOffset()"], ["byte", "org.apache.hadoop.hbase.TagRewriteCell.getFamilyLength()"], ["byte[]", "org.apache.hadoop.hbase.TagRewriteCell.getQualifierArray()"], ["int", "org.apache.hadoop.hbase.TagRewriteCell.getQualifierOffset()"], ["int", "org.apache.hadoop.hbase.TagRewriteCell.getQualifierLength()"], ["long", "org.apache.hadoop.hbase.TagRewriteCell.getTimestamp()"], ["byte", "org.apache.hadoop.hbase.TagRewriteCell.getTypeByte()"], ["long", "org.apache.hadoop.hbase.TagRewriteCell.getMvccVersion()"], ["long", "org.apache.hadoop.hbase.TagRewriteCell.getSequenceId()"], ["byte[]", "org.apache.hadoop.hbase.TagRewriteCell.getValueArray()"], ["int", "org.apache.hadoop.hbase.TagRewriteCell.getValueOffset()"], ["int", "org.apache.hadoop.hbase.TagRewriteCell.getValueLength()"], ["byte[]", "org.apache.hadoop.hbase.TagRewriteCell.getTagsArray()"], ["int", "org.apache.hadoop.hbase.TagRewriteCell.getTagsOffset()"], ["int", "org.apache.hadoop.hbase.TagRewriteCell.getTagsLength()"], ["byte[]", "org.apache.hadoop.hbase.TagRewriteCell.getValue()"], ["byte[]", "org.apache.hadoop.hbase.TagRewriteCell.getFamily()"], ["byte[]", "org.apache.hadoop.hbase.TagRewriteCell.getQualifier()"], ["byte[]", "org.apache.hadoop.hbase.TagRewriteCell.getRow()"], ["long", "org.apache.hadoop.hbase.TagRewriteCell.heapSize()"], ["void", "org.apache.hadoop.hbase.TagRewriteCell.setTimestamp(long)"], ["void", "org.apache.hadoop.hbase.TagRewriteCell.setTimestamp(byte[], int)"], ["void", "org.apache.hadoop.hbase.TagRewriteCell.setSequenceId(long)"], ["void", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl$1.renderTo(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.setMaster(org.apache.hadoop.hbase.master.HMaster)"], ["org.apache.hadoop.hbase.master.HMaster", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getMaster()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.setCatalogJanitorEnabled(boolean)"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getCatalogJanitorEnabled()"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getCatalogJanitorEnabled__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.setServerManager(org.apache.hadoop.hbase.master.ServerManager)"], ["org.apache.hadoop.hbase.master.ServerManager", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getServerManager()"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getServerManager__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.setFormat(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getFormat()"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getFormat__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.setFrags(java.util.Map<java.lang.String, java.lang.Integer>)"], ["java.util.Map<java.lang.String, java.lang.Integer>", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getFrags()"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getFrags__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.setAssignmentManager(org.apache.hadoop.hbase.master.AssignmentManager)"], ["org.apache.hadoop.hbase.master.AssignmentManager", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getAssignmentManager()"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getAssignmentManager__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.setMetaLocation(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getMetaLocation()"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getMetaLocation__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.setDeadServers(java.util.Set<org.apache.hadoop.hbase.ServerName>)"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getDeadServers__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.setServers(java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getServers__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.setFilter(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getFilter()"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData.getFilter__IsNotDefault()"], ["org.apache.hadoop.hbase.tmpl.master.RegionServerListTmplImpl", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmplImpl(org.jamon.TemplateManager, org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl$ImplData)"], ["void", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmplImpl.renderNoFlush(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmplImpl", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmplImpl(org.jamon.TemplateManager, org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmplImpl.renderNoFlush(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmplImpl", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmplImpl(org.jamon.TemplateManager, org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmplImpl.renderNoFlush(java.io.Writer)"], ["org.apache.hadoop.hbase.util.AbstractFileStatusFilter", "org.apache.hadoop.hbase.util.AbstractFileStatusFilter()"], ["boolean", "org.apache.hadoop.hbase.util.AbstractFileStatusFilter.accept(org.apache.hadoop.fs.FileStatus)"], ["boolean", "org.apache.hadoop.hbase.util.AbstractFileStatusFilter.accept(org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.util.ByteBloomFilter$MetaWriter.readFields(java.io.DataInput)"], ["void", "org.apache.hadoop.hbase.util.ByteBloomFilter$MetaWriter.write(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.util.FSRegionScanner.run()"], ["org.apache.hadoop.hbase.util.FSUtils$BlackListDirFilter", "org.apache.hadoop.hbase.util.FSUtils$BlackListDirFilter(org.apache.hadoop.fs.FileSystem, java.util.List<java.lang.String>)"], ["org.apache.hadoop.hbase.util.FSUtils$FamilyDirFilter", "org.apache.hadoop.hbase.util.FSUtils$FamilyDirFilter(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.util.FSUtils$ReferenceFileFilter", "org.apache.hadoop.hbase.util.FSUtils$ReferenceFileFilter(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.util.HBaseConfTool", "org.apache.hadoop.hbase.util.HBaseConfTool()"], ["void", "org.apache.hadoop.hbase.util.HBaseConfTool.main(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$3.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck$3.isAborted()"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$WorkItemHdfsDir.java.lang.Void call()"], ["java.lang.Object", "org.apache.hadoop.hbase.util.HBaseFsck$WorkItemHdfsDir.call()"], ["org.apache.hadoop.hbase.util.hbck.ReplicationChecker", "org.apache.hadoop.hbase.util.hbck.ReplicationChecker(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.client.HConnection, org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter)"], ["boolean", "org.apache.hadoop.hbase.util.hbck.ReplicationChecker.hasUnDeletedQueues()"], ["void", "org.apache.hadoop.hbase.util.hbck.ReplicationChecker.checkUnDeletedQueues()"], ["void", "org.apache.hadoop.hbase.util.hbck.ReplicationChecker.fixUnDeletedQueues()"], ["java.lang.Boolean", "org.apache.hadoop.hbase.util.HMerge$1.connect(org.apache.hadoop.hbase.client.HConnection)"], ["java.lang.Object", "org.apache.hadoop.hbase.util.HMerge$1.connect(org.apache.hadoop.hbase.client.HConnection)"], ["org.apache.hadoop.hbase.util.IdReadWriteLock", "org.apache.hadoop.hbase.util.IdReadWriteLock()"], ["java.util.concurrent.locks.ReentrantReadWriteLock", "org.apache.hadoop.hbase.util.IdReadWriteLock.getLock(long)"], ["void", "org.apache.hadoop.hbase.util.IdReadWriteLock.waitForWaiters(long, int)"], ["void", "org.apache.hadoop.hbase.util.JvmPauseMonitor$Monitor.run()"], ["java.lang.Thread", "org.apache.hadoop.hbase.util.ModifyRegionUtils$3.newThread(java.lang.Runnable)"], ["org.apache.hadoop.hbase.util.ProtoUtil", "org.apache.hadoop.hbase.util.ProtoUtil()"], ["int", "org.apache.hadoop.hbase.util.ProtoUtil.readRawVarint32(java.io.DataInput)"], ["org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit()"], ["byte[]", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.split(byte[], byte[])"], ["byte[][]", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.split(int)"], ["byte[][]", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.split(byte[], byte[], int, boolean)"], ["byte[]", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.firstRow()"], ["byte[]", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.lastRow()"], ["void", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.setFirstRow(java.lang.String)"], ["void", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.setLastRow(java.lang.String)"], ["void", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.setFirstRow(byte[])"], ["void", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.setLastRow(byte[])"], ["byte[]", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.strToRow(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.rowToStr(byte[])"], ["java.lang.String", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.separator()"], ["java.lang.String", "org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.toString()"], ["org.apache.hadoop.hbase.util.SortedCopyOnWriteSet", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet()"], ["org.apache.hadoop.hbase.util.SortedCopyOnWriteSet", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet(java.util.Collection<? extends E>)"], ["org.apache.hadoop.hbase.util.SortedCopyOnWriteSet", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet(java.util.Comparator<? super E>)"], ["int", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.size()"], ["boolean", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.isEmpty()"], ["boolean", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.contains(java.lang.Object)"], ["java.lang.Object[]", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.toArray()"], ["<T> T[]", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.toArray(T[])"], ["synchronized", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.boolean add(E)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.boolean remove(java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.containsAll(java.util.Collection<?>)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.boolean addAll(java.util.Collection<? extends E>)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.boolean retainAll(java.util.Collection<?>)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.boolean removeAll(java.util.Collection<?>)"], ["synchronized", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.void clear()"], ["java.util.Comparator<? super E>", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.comparator()"], ["E", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.first()"], ["E", "org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.last()"], ["org.apache.hadoop.hbase.wal.BoundedGroupingStrategy", "org.apache.hadoop.hbase.wal.BoundedGroupingStrategy()"], ["java.lang.String", "org.apache.hadoop.hbase.wal.BoundedGroupingStrategy.group(byte[], byte[])"], ["void", "org.apache.hadoop.hbase.wal.BoundedGroupingStrategy.init(org.apache.hadoop.conf.Configuration, java.lang.String)"], ["org.apache.hadoop.hbase.wal.NamespaceGroupingStrategy", "org.apache.hadoop.hbase.wal.NamespaceGroupingStrategy()"], ["java.lang.String", "org.apache.hadoop.hbase.wal.NamespaceGroupingStrategy.group(byte[], byte[])"], ["void", "org.apache.hadoop.hbase.wal.NamespaceGroupingStrategy.init(org.apache.hadoop.conf.Configuration, java.lang.String)"], ["org.apache.hadoop.hbase.wal.WALSplitter$BoundedLogWriterCreationOutputSink", "org.apache.hadoop.hbase.wal.WALSplitter$BoundedLogWriterCreationOutputSink(org.apache.hadoop.hbase.wal.WALSplitter, org.apache.hadoop.hbase.wal.WALSplitter$PipelineController, org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers, int)"], ["java.util.Map<byte[], java.lang.Long>", "org.apache.hadoop.hbase.wal.WALSplitter$BoundedLogWriterCreationOutputSink.getOutputCounts()"], ["int", "org.apache.hadoop.hbase.wal.WALSplitter$BoundedLogWriterCreationOutputSink.getNumberOfRecoveredRegions()"], ["void", "org.apache.hadoop.hbase.wal.WALSplitter$BoundedLogWriterCreationOutputSink.append(org.apache.hadoop.hbase.wal.WALSplitter$RegionEntryBuffer)"], ["org.apache.hadoop.hbase.wal.WALSplitter$PipelineController", "org.apache.hadoop.hbase.wal.WALSplitter$PipelineController()"], ["void", "org.apache.hadoop.hbase.ZNodeClearer.writeMyEphemeralNodeOnDisk(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.ZNodeClearer.readMyEphemeralNodeOnDisk()"], ["java.lang.String", "org.apache.hadoop.hbase.ZNodeClearer.getMyEphemeralNodeFileName()"], ["void", "org.apache.hadoop.hbase.ZNodeClearer.deleteMyEphemeralNodeOnDisk()"], ["boolean", "org.apache.hadoop.hbase.ZNodeClearer.clear(org.apache.hadoop.conf.Configuration)"], ["long", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase$ZNodeComparator.getChildSequenceId(java.lang.String)"], ["int", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase$ZNodeComparator.compare(java.lang.String, java.lang.String)"], ["int", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase$ZNodeComparator.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadWriteLock", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadWriteLock(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String, org.apache.hadoop.hbase.InterProcessLock$MetadataHandler)"], ["org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadLock", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadWriteLock.readLock(byte[])"], ["org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessWriteLock", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadWriteLock.writeLock(byte[])"], ["org.apache.hadoop.hbase.InterProcessLock", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadWriteLock.writeLock(byte[])"], ["org.apache.hadoop.hbase.InterProcessLock", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadWriteLock.readLock(byte[])"], ["org.apache.hadoop.hbase.zookeeper.RegionNormalizerTracker", "org.apache.hadoop.hbase.zookeeper.RegionNormalizerTracker(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.Abortable)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.RegionNormalizerTracker.isNormalizerOn()"], ["void", "org.apache.hadoop.hbase.zookeeper.RegionNormalizerTracker.setNormalizerOn(boolean)"], ["org.apache.hadoop.hbase.zookeeper.ZKTableStateManager", "org.apache.hadoop.hbase.zookeeper.ZKTableStateManager(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["void", "org.apache.hadoop.hbase.zookeeper.ZKTableStateManager.setTableState(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$Table$State)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ZKTableStateManager.setTableStateIfInStates(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$Table$State, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$Table$State...)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ZKTableStateManager.setTableStateIfNotInStates(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$Table$State, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$Table$State...)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ZKTableStateManager.isTableState(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$Table$State...)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ZKTableStateManager.isTableState(org.apache.hadoop.hbase.TableName, boolean, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$Table$State...)"], ["void", "org.apache.hadoop.hbase.zookeeper.ZKTableStateManager.setDeletedTable(org.apache.hadoop.hbase.TableName)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ZKTableStateManager.isTablePresent(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.zookeeper.ZKTableStateManager.checkAndRemoveTableState(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$Table$State, boolean)"], ["org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient", "org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.client.ClusterConnection)"], ["void", "org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.enableHFileBackupAsync(byte[])"], ["void", "org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.disableHFileBackup(java.lang.String)"], ["void", "org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.disableHFileBackup(byte[])"], ["void", "org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.disableHFileBackup()"], ["boolean", "org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.getArchivingEnabled(byte[])"], ["boolean", "org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.getArchivingEnabled(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.getArchiveZNode(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile", "org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.regionserver.StoreFile)"], ["void", "org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile.delete()"], ["java.lang.String", "org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile.getName()"], ["boolean", "org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile.isFile()"], ["void", "org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile.close()"], ["org.apache.hadoop.hbase.client.ClusterConnection", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getConnectionForEnvironment(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["org.apache.hadoop.hbase.client.CoprocessorHConnection", "org.apache.hadoop.hbase.client.CoprocessorHConnection(org.apache.hadoop.hbase.client.ClusterConnection, org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["org.apache.hadoop.hbase.client.CoprocessorHConnection", "org.apache.hadoop.hbase.client.CoprocessorHConnection(org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["org.apache.hadoop.hbase.client.CoprocessorHConnection", "org.apache.hadoop.hbase.client.CoprocessorHConnection(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingInterface", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getClient(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.client.NonceGenerator", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getNonceGenerator()"], ["org.apache.hadoop.hbase.ipc.RpcControllerFactory", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getRpcControllerFactory()"], ["org.apache.hadoop.hbase.client.RpcRetryingCallerFactory", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getRpcRetryingCallerFactory()"], ["org.apache.hadoop.hbase.client.ConnectionConfiguration", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getConnectionConfiguration()"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.hasCellBlockSupport()"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isManaged()"], ["org.apache.hadoop.hbase.client.RpcRetryingCallerFactory", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getNewRpcRetryingCallerFactory(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getHTableDescriptor(byte[])"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getHTableDescriptor(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.HTableDescriptor[]", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getHTableDescriptors(java.util.List)"], ["org.apache.hadoop.hbase.HTableDescriptor[]", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getHTableDescriptorsByTableName(java.util.List)"], ["org.apache.hadoop.hbase.TableName[]", "org.apache.hadoop.hbase.client.CoprocessorHConnection.listTableNames()"], ["java.lang.String[]", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getTableNames()"], ["org.apache.hadoop.hbase.HTableDescriptor[]", "org.apache.hadoop.hbase.client.CoprocessorHConnection.listTables()"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.close()"], ["int", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getCurrentNrHRS()"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isAborted()"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isClosed()"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getRegionCachePrefetch(byte[])"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getRegionCachePrefetch(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.setRegionCachePrefetch(byte[], boolean)"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.setRegionCachePrefetch(org.apache.hadoop.hbase.TableName, boolean)"], ["org.apache.hadoop.hbase.client.backoff.ClientBackoffPolicy", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getBackoffPolicy()"], ["org.apache.hadoop.hbase.client.ServerStatisticTracker", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getStatisticsTracker()"], ["org.apache.hadoop.hbase.client.AsyncProcess", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getAsyncProcess()"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.processBatchCallback(java.util.List, byte[], java.util.concurrent.ExecutorService, java.lang.Object[], org.apache.hadoop.hbase.client.coprocessor.Batch$Callback)"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.processBatchCallback(java.util.List, org.apache.hadoop.hbase.TableName, java.util.concurrent.ExecutorService, java.lang.Object[], org.apache.hadoop.hbase.client.coprocessor.Batch$Callback)"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.processBatch(java.util.List, byte[], java.util.concurrent.ExecutorService, java.lang.Object[])"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.processBatch(java.util.List, org.apache.hadoop.hbase.TableName, java.util.concurrent.ExecutorService, java.lang.Object[])"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.updateCachedLocations(byte[], byte[], java.lang.Object, org.apache.hadoop.hbase.HRegionLocation)"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.updateCachedLocations(org.apache.hadoop.hbase.TableName, byte[], byte[], java.lang.Object, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.updateCachedLocations(org.apache.hadoop.hbase.TableName, byte[], java.lang.Object, org.apache.hadoop.hbase.HRegionLocation)"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.deleteCachedRegionLocation(org.apache.hadoop.hbase.HRegionLocation)"], ["org.apache.hadoop.hbase.client.MasterKeepAliveConnection", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getKeepAliveMasterService()"], ["org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$BlockingInterface", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getMaster()"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingInterface", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getAdmin(org.apache.hadoop.hbase.ServerName, boolean)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingInterface", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getAdmin(org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.clearRegionCache(byte[])"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.clearRegionCache(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.clearRegionCache()"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.clearCaches(org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.clearRegionCache(org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.client.CoprocessorHConnection.cacheLocation(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.RegionLocations)"], ["org.apache.hadoop.hbase.RegionLocations", "org.apache.hadoop.hbase.client.CoprocessorHConnection.locateRegion(org.apache.hadoop.hbase.TableName, byte[], boolean, boolean, int)"], ["org.apache.hadoop.hbase.RegionLocations", "org.apache.hadoop.hbase.client.CoprocessorHConnection.locateRegion(org.apache.hadoop.hbase.TableName, byte[], boolean, boolean)"], ["org.apache.hadoop.hbase.HRegionLocation", "org.apache.hadoop.hbase.client.CoprocessorHConnection.relocateRegion(byte[], byte[])"], ["org.apache.hadoop.hbase.RegionLocations", "org.apache.hadoop.hbase.client.CoprocessorHConnection.relocateRegion(org.apache.hadoop.hbase.TableName, byte[], int)"], ["org.apache.hadoop.hbase.HRegionLocation", "org.apache.hadoop.hbase.client.CoprocessorHConnection.relocateRegion(org.apache.hadoop.hbase.TableName, byte[])"], ["org.apache.hadoop.hbase.HRegionLocation", "org.apache.hadoop.hbase.client.CoprocessorHConnection.locateRegion(byte[], byte[])"], ["org.apache.hadoop.hbase.HRegionLocation", "org.apache.hadoop.hbase.client.CoprocessorHConnection.locateRegion(org.apache.hadoop.hbase.TableName, byte[])"], ["java.util.List", "org.apache.hadoop.hbase.client.CoprocessorHConnection.locateRegions(byte[], boolean, boolean)"], ["java.util.List", "org.apache.hadoop.hbase.client.CoprocessorHConnection.locateRegions(org.apache.hadoop.hbase.TableName, boolean, boolean)"], ["java.util.List", "org.apache.hadoop.hbase.client.CoprocessorHConnection.locateRegions(byte[])"], ["java.util.List", "org.apache.hadoop.hbase.client.CoprocessorHConnection.locateRegions(org.apache.hadoop.hbase.TableName)"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isDeadServer(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.HRegionLocation", "org.apache.hadoop.hbase.client.CoprocessorHConnection.locateRegion(byte[])"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isTableAvailable(byte[], byte[][])"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isTableAvailable(org.apache.hadoop.hbase.TableName, byte[][])"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isTableAvailable(byte[])"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isTableAvailable(org.apache.hadoop.hbase.TableName)"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isTableDisabled(byte[])"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isTableDisabled(org.apache.hadoop.hbase.TableName)"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isTableEnabled(byte[])"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isTableEnabled(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.HRegionLocation", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getRegionLocation(byte[], byte[], boolean)"], ["org.apache.hadoop.hbase.HRegionLocation", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getRegionLocation(org.apache.hadoop.hbase.TableName, byte[], boolean)"], ["boolean", "org.apache.hadoop.hbase.client.CoprocessorHConnection.isMasterRunning()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getConfiguration()"], ["java.lang.String", "org.apache.hadoop.hbase.client.CoprocessorHConnection.toString()"], ["org.apache.hadoop.hbase.client.MetricsConnection", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getConnectionMetrics()"], ["org.apache.hadoop.hbase.client.Admin", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getAdmin()"], ["org.apache.hadoop.hbase.client.RegionLocator", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getRegionLocator(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.client.BufferedMutator", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getBufferedMutator(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.client.BufferedMutator", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getBufferedMutator(org.apache.hadoop.hbase.client.BufferedMutatorParams)"], ["org.apache.hadoop.hbase.client.HTableInterface", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getTable(org.apache.hadoop.hbase.TableName, java.util.concurrent.ExecutorService)"], ["org.apache.hadoop.hbase.client.HTableInterface", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getTable(byte[], java.util.concurrent.ExecutorService)"], ["org.apache.hadoop.hbase.client.HTableInterface", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getTable(java.lang.String, java.util.concurrent.ExecutorService)"], ["org.apache.hadoop.hbase.client.HTableInterface", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getTable(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.client.HTableInterface", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getTable(byte[])"], ["org.apache.hadoop.hbase.client.HTableInterface", "org.apache.hadoop.hbase.client.CoprocessorHConnection.getTable(java.lang.String)"], ["org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination$ZkOpenRegionDetails", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination$ZkOpenRegionDetails()"], ["org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination$ZkOpenRegionDetails", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination$ZkOpenRegionDetails(int)"], ["int", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination$ZkOpenRegionDetails.getVersionOfOfflineNode()"], ["void", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination$ZkOpenRegionDetails.setVersionOfOfflineNode(int)"], ["int", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination$ZkOpenRegionDetails.getVersion()"], ["void", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination$ZkOpenRegionDetails.setVersion(int)"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination$ZkOpenRegionDetails.getServerName()"], ["void", "org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination$ZkOpenRegionDetails.setServerName(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$DeleteAsyncCallback", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$DeleteAsyncCallback(org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$DeleteAsyncCallback.processResult(int, java.lang.String, java.lang.Object)"], ["org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$TaskFinisher$Status[]", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$TaskFinisher$Status.values()"], ["org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$TaskFinisher$Status", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$TaskFinisher$Status.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination(org.apache.hadoop.hbase.CoordinatedStateManager, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.init()"], ["java.lang.String", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.prepareTask(java.lang.String)"], ["int", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.remainingTasksInCoordination()"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.deleteTask(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.resubmitTask(java.lang.String, org.apache.hadoop.hbase.master.SplitLogManager$Task, org.apache.hadoop.hbase.master.SplitLogManager$ResubmitDirective)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.checkTasks()"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.submitTask(java.lang.String)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.checkTaskStillAvailable(java.lang.String)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.removeRecoveringRegions(java.util.Set<java.lang.String>, java.lang.Boolean)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.markRegionsRecovering(org.apache.hadoop.hbase.ServerName, java.util.Set<org.apache.hadoop.hbase.HRegionInfo>)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.nodeDataChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.removeStaleRecoveringRegions(java.util.Set<java.lang.String>)"], ["synchronized", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.boolean isReplaying()"], ["synchronized", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.boolean isSplitting()"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.setRecoveryMode(boolean)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.setDetails(org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination$SplitLogManagerDetails)"], ["org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination$SplitLogManagerDetails", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.getDetails()"], ["synchronized", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode getRecoveryMode()"], ["long", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.getLastRecoveryTime()"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.setIgnoreDeleteForTesting(boolean)"], ["org.apache.hadoop.hbase.coprocessor.BaseWALObserver", "org.apache.hadoop.hbase.coprocessor.BaseWALObserver()"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseWALObserver.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseWALObserver.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseWALObserver.preWALWrite(org.apache.hadoop.hbase.coprocessor.ObserverContext<? extends org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseWALObserver.preWALWrite(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.regionserver.wal.HLogKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseWALObserver.postWALWrite(org.apache.hadoop.hbase.coprocessor.ObserverContext<? extends org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseWALObserver.postWALWrite(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.regionserver.wal.HLogKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseWALObserver.preWALRoll(org.apache.hadoop.hbase.coprocessor.ObserverContext<? extends org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment>, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseWALObserver.postWALRoll(org.apache.hadoop.hbase.coprocessor.ObserverContext<? extends org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment>, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.errorhandling.ForeignException", "org.apache.hadoop.hbase.errorhandling.ForeignException(java.lang.String, java.lang.Throwable)"], ["org.apache.hadoop.hbase.errorhandling.ForeignException", "org.apache.hadoop.hbase.errorhandling.ForeignException(java.lang.String, java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.errorhandling.ForeignException.getSource()"], ["boolean", "org.apache.hadoop.hbase.errorhandling.ForeignException.isRemote()"], ["java.lang.String", "org.apache.hadoop.hbase.errorhandling.ForeignException.toString()"], ["byte[]", "org.apache.hadoop.hbase.errorhandling.ForeignException.serialize(java.lang.String, java.lang.Throwable)"], ["org.apache.hadoop.hbase.errorhandling.ForeignException", "org.apache.hadoop.hbase.errorhandling.ForeignException.deserialize(byte[])"], ["void", "org.apache.hadoop.hbase.executor.ExecutorService$ExecutorStatus.dumpTo(java.io.Writer, java.lang.String)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$3.compare(java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>, java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$3.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.generated.master.table_jsp", "org.apache.hadoop.hbase.generated.master.table_jsp()"], ["java.lang.Object", "org.apache.hadoop.hbase.generated.master.table_jsp.getDependants()"], ["void", "org.apache.hadoop.hbase.generated.master.table_jsp._jspService(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.http.HttpServer", "org.apache.hadoop.hbase.http.HttpServer(java.lang.String, java.lang.String, int, boolean)"], ["org.apache.hadoop.hbase.http.HttpServer", "org.apache.hadoop.hbase.http.HttpServer(java.lang.String, java.lang.String, int, boolean, org.apache.hadoop.conf.Configuration, org.mortbay.jetty.Connector)"], ["org.apache.hadoop.hbase.http.HttpServer", "org.apache.hadoop.hbase.http.HttpServer(java.lang.String, java.lang.String, int, boolean, org.apache.hadoop.conf.Configuration, java.lang.String[])"], ["org.apache.hadoop.hbase.http.HttpServer", "org.apache.hadoop.hbase.http.HttpServer(java.lang.String, java.lang.String, int, boolean, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.http.HttpServer", "org.apache.hadoop.hbase.http.HttpServer(java.lang.String, java.lang.String, int, boolean, org.apache.hadoop.conf.Configuration, org.apache.hadoop.security.authorize.AccessControlList)"], ["org.apache.hadoop.hbase.http.HttpServer", "org.apache.hadoop.hbase.http.HttpServer(java.lang.String, java.lang.String, int, boolean, org.apache.hadoop.conf.Configuration, org.apache.hadoop.security.authorize.AccessControlList, org.mortbay.jetty.Connector)"], ["org.apache.hadoop.hbase.http.HttpServer", "org.apache.hadoop.hbase.http.HttpServer(java.lang.String, java.lang.String, int, boolean, org.apache.hadoop.conf.Configuration, org.apache.hadoop.security.authorize.AccessControlList, org.mortbay.jetty.Connector, java.lang.String[])"], ["org.mortbay.jetty.Connector", "org.apache.hadoop.hbase.http.HttpServer.createBaseListener(org.apache.hadoop.conf.Configuration)"], ["org.mortbay.jetty.Connector", "org.apache.hadoop.hbase.http.HttpServer.createDefaultChannelConnector()"], ["void", "org.apache.hadoop.hbase.http.HttpServer.addContext(org.mortbay.jetty.servlet.Context, boolean)"], ["void", "org.apache.hadoop.hbase.http.HttpServer.setAttribute(java.lang.String, java.lang.Object)"], ["void", "org.apache.hadoop.hbase.http.HttpServer.addJerseyResourcePackage(java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.http.HttpServer.addServlet(java.lang.String, java.lang.String, java.lang.Class<? extends javax.servlet.http.HttpServlet>)"], ["void", "org.apache.hadoop.hbase.http.HttpServer.addInternalServlet(java.lang.String, java.lang.String, java.lang.Class<? extends javax.servlet.http.HttpServlet>)"], ["void", "org.apache.hadoop.hbase.http.HttpServer.addInternalServlet(java.lang.String, java.lang.String, java.lang.Class<? extends javax.servlet.http.HttpServlet>, boolean)"], ["void", "org.apache.hadoop.hbase.http.HttpServer.addFilter(java.lang.String, java.lang.String, java.util.Map<java.lang.String, java.lang.String>)"], ["void", "org.apache.hadoop.hbase.http.HttpServer.addGlobalFilter(java.lang.String, java.lang.String, java.util.Map<java.lang.String, java.lang.String>)"], ["void", "org.apache.hadoop.hbase.http.HttpServer.defineFilter(org.mortbay.jetty.servlet.Context, java.lang.String, java.lang.String, java.util.Map<java.lang.String, java.lang.String>, java.lang.String[])"], ["java.lang.Object", "org.apache.hadoop.hbase.http.HttpServer.getAttribute(java.lang.String)"], ["org.mortbay.jetty.webapp.WebAppContext", "org.apache.hadoop.hbase.http.HttpServer.getWebAppContext()"], ["java.lang.String", "org.apache.hadoop.hbase.http.HttpServer.getWebAppsPath(java.lang.String)"], ["int", "org.apache.hadoop.hbase.http.HttpServer.getPort()"], ["java.net.InetSocketAddress", "org.apache.hadoop.hbase.http.HttpServer.getConnectorAddress(int)"], ["void", "org.apache.hadoop.hbase.http.HttpServer.setThreads(int, int)"], ["void", "org.apache.hadoop.hbase.http.HttpServer.start()"], ["void", "org.apache.hadoop.hbase.http.HttpServer.stop()"], ["void", "org.apache.hadoop.hbase.http.HttpServer.join()"], ["boolean", "org.apache.hadoop.hbase.http.HttpServer.isAlive()"], ["java.lang.String", "org.apache.hadoop.hbase.http.HttpServer.toString()"], ["boolean", "org.apache.hadoop.hbase.http.HttpServer.isInstrumentationAccessAllowed(javax.servlet.ServletContext, javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["boolean", "org.apache.hadoop.hbase.http.HttpServer.hasAdministratorAccess(javax.servlet.ServletContext, javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["boolean", "org.apache.hadoop.hbase.http.HttpServer.userHasAdministratorAccess(javax.servlet.ServletContext, java.lang.String)"], ["org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$NotSeekedException", "org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$NotSeekedException()"], ["synchronized", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$BucketSizeInfo.void instantiateBucket(org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$BucketSizeInfo.sizeIndex()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$BucketSizeInfo.allocateBlock()"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$BucketSizeInfo.findAndRemoveCompletelyFreeBucket()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$BucketSizeInfo.freeBlock(org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$Bucket, long)"], ["synchronized", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$BucketSizeInfo.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics statistics()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$BucketSizeInfo.toString()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$WriterThread.run()"], ["org.apache.hadoop.hbase.io.hfile.CacheableDeserializerIdManager", "org.apache.hadoop.hbase.io.hfile.CacheableDeserializerIdManager()"], ["int", "org.apache.hadoop.hbase.io.hfile.CacheableDeserializerIdManager.registerDeserializer(org.apache.hadoop.hbase.io.hfile.CacheableDeserializer<org.apache.hadoop.hbase.io.hfile.Cacheable>)"], ["org.apache.hadoop.hbase.io.hfile.CacheConfig$ExternalBlockCaches[]", "org.apache.hadoop.hbase.io.hfile.CacheConfig$ExternalBlockCaches.values()"], ["org.apache.hadoop.hbase.io.hfile.CacheConfig$ExternalBlockCaches", "org.apache.hadoop.hbase.io.hfile.CacheConfig$ExternalBlockCaches.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.io.hfile.CombinedBlockCache", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache(org.apache.hadoop.hbase.io.hfile.LruBlockCache, org.apache.hadoop.hbase.io.hfile.BlockCache)"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.heapSize()"], ["void", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.cacheBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.cacheBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable)"], ["org.apache.hadoop.hbase.io.hfile.Cacheable", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.getBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, boolean, boolean, boolean)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.evictBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey)"], ["int", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.evictBlocksByHfileName(java.lang.String)"], ["org.apache.hadoop.hbase.io.hfile.CacheStats", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.getStats()"], ["void", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.shutdown()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.size()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.getMaxSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.getFreeSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.getCurrentSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.getCurrentDataSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.getBlockCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.getDataBlockCount()"], ["org.apache.hadoop.hbase.io.hfile.BlockCache[]", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.getBlockCaches()"], ["void", "org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.setMaxSize(long)"], ["org.apache.hadoop.hbase.io.hfile.HFile$FileInfo", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo()"], ["org.apache.hadoop.hbase.io.hfile.HFile$FileInfo", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.append(byte[], byte[], boolean)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.clear()"], ["java.util.Comparator<? super byte[]>", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.comparator()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.containsKey(java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.containsValue(java.lang.Object)"], ["java.util.Set<java.util.Map$Entry<byte[], byte[]>>", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.entrySet()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.equals(java.lang.Object)"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.firstKey()"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.get(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.hashCode()"], ["java.util.SortedMap<byte[], byte[]>", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.headMap(byte[])"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.isEmpty()"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.lastKey()"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.put(byte[], byte[])"], ["void", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.putAll(java.util.Map<? extends byte[], ? extends byte[]>)"], ["byte[]", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.remove(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.size()"], ["java.util.SortedMap<byte[], byte[]>", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.subMap(byte[], byte[])"], ["java.util.SortedMap<byte[], byte[]>", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.tailMap(byte[])"], ["java.lang.Object", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.lastKey()"], ["java.lang.Object", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.firstKey()"], ["java.util.SortedMap", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.tailMap(java.lang.Object)"], ["java.util.SortedMap", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.headMap(java.lang.Object)"], ["java.util.SortedMap", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.subMap(java.lang.Object, java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.remove(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.put(java.lang.Object, java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.io.hfile.HFile$FileInfo.get(java.lang.Object)"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock$Writer$State[]", "org.apache.hadoop.hbase.io.hfile.HFileBlock$Writer$State.values()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock$Writer$State", "org.apache.hadoop.hbase.io.hfile.HFileBlock$Writer$State.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.getNextIndexedKey()"], ["org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2(org.apache.hadoop.hbase.io.hfile.HFileReaderV2, boolean, boolean, boolean)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(byte[], int, int)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(byte[], int, int)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(org.apache.hadoop.hbase.Cell)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(org.apache.hadoop.hbase.Cell)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(org.apache.hadoop.hbase.Cell, boolean)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekBefore(byte[], int, int)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekBefore(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.io.encoding.DataBlockEncoding", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.getEffectiveDataBlockEncoding()"], ["org.apache.hadoop.hbase.io.hfile.BlockType", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2$1.getBlockType()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2$1.writeToBlock(java.io.DataOutput)"], ["org.apache.hadoop.hbase.io.hfile.HFile$Writer", "org.apache.hadoop.hbase.io.hfile.HFileWriterV3$WriterFactoryV3.createWriter(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FSDataOutputStream, org.apache.hadoop.hbase.KeyValue$KVComparator, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1.hasNext()"], ["org.apache.hadoop.hbase.io.hfile.CachedBlock", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1.next()"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1.remove()"], ["java.lang.Object", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1.next()"], ["org.apache.hadoop.hbase.io.MetricsIO", "org.apache.hadoop.hbase.io.MetricsIO(org.apache.hadoop.hbase.io.MetricsIOWrapper)"], ["org.apache.hadoop.hbase.io.MetricsIOSource", "org.apache.hadoop.hbase.io.MetricsIO.getMetricsSource()"], ["org.apache.hadoop.hbase.io.MetricsIOWrapper", "org.apache.hadoop.hbase.io.MetricsIO.getWrapper()"], ["void", "org.apache.hadoop.hbase.io.MetricsIO.updateFsReadTime(long)"], ["void", "org.apache.hadoop.hbase.io.MetricsIO.updateFsPreadTime(long)"], ["void", "org.apache.hadoop.hbase.io.MetricsIO.updateFsWriteTime(long)"], ["org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor(java.lang.String, int, int, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor(java.lang.String, int, java.lang.String, int, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor(java.lang.String, int, int, int)"], ["org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor(java.lang.String, int, int, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor(java.lang.String, int, int, java.lang.Class<? extends java.util.concurrent.BlockingQueue>, java.lang.Object...)"], ["org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor", "org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor(java.lang.String, int, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable, java.lang.Class<? extends java.util.concurrent.BlockingQueue>, java.lang.Object...)"], ["boolean", "org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor.dispatch(org.apache.hadoop.hbase.ipc.CallRunner)"], ["void", "org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run()"], ["org.apache.hadoop.hbase.ipc.RpcServer$Listener", "org.apache.hadoop.hbase.ipc.RpcServer$Listener(org.apache.hadoop.hbase.ipc.RpcServer, java.lang.String)"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer$Listener.run()"], ["org.apache.hadoop.hbase.JMXListener", "org.apache.hadoop.hbase.JMXListener()"], ["javax.management.remote.JMXServiceURL", "org.apache.hadoop.hbase.JMXListener.buildJMXServiceURL(int, int)"], ["void", "org.apache.hadoop.hbase.JMXListener.startConnectorServer(int, int)"], ["void", "org.apache.hadoop.hbase.JMXListener.stopConnectorServer()"], ["void", "org.apache.hadoop.hbase.JMXListener.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.JMXListener.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["org.apache.hadoop.hbase.mapred.RowCounter", "org.apache.hadoop.hbase.mapred.RowCounter()"], ["org.apache.hadoop.mapred.JobConf", "org.apache.hadoop.hbase.mapred.RowCounter.createSubmittableJob(java.lang.String[])"], ["int", "org.apache.hadoop.hbase.mapred.RowCounter.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapred.RowCounter.main(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapred.TableInputFormatBase$1.close()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapred.TableInputFormatBase$1.createKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapred.TableInputFormatBase$1.createValue()"], ["long", "org.apache.hadoop.hbase.mapred.TableInputFormatBase$1.getPos()"], ["float", "org.apache.hadoop.hbase.mapred.TableInputFormatBase$1.getProgress()"], ["boolean", "org.apache.hadoop.hbase.mapred.TableInputFormatBase$1.next(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapred.TableInputFormatBase$1.createValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapred.TableInputFormatBase$1.createKey()"], ["boolean", "org.apache.hadoop.hbase.mapred.TableInputFormatBase$1.next(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.mapred.TableMapReduceUtil", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil()"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.initTableMapJob(java.lang.String, java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableMap>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.initTableMapJob(java.lang.String, java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableMap>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapred.JobConf, boolean)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.initTableMapJob(java.lang.String, java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableMap>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapred.JobConf, boolean, java.lang.Class<? extends org.apache.hadoop.mapred.InputFormat>)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.initMultiTableSnapshotMapperJob(java.util.Map<java.lang.String, java.util.Collection<org.apache.hadoop.hbase.client.Scan>>, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableMap>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapred.JobConf, boolean, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.initTableSnapshotMapJob(java.lang.String, java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableMap>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapred.JobConf, boolean, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.initTableSnapshotMapJob(java.lang.String, java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableMap>, java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapred.JobConf, boolean, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.RegionSplitter$SplitAlgorithm, int)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.initTableReduceJob(java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableReduce>, org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.initTableReduceJob(java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableReduce>, org.apache.hadoop.mapred.JobConf, java.lang.Class)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.initTableReduceJob(java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableReduce>, org.apache.hadoop.mapred.JobConf, java.lang.Class, boolean)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.initCredentials(org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.limitNumReduceTasks(java.lang.String, org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.limitNumMapTasks(java.lang.String, org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.setNumReduceTasks(java.lang.String, org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.setNumMapTasks(java.lang.String, org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.setScannerCaching(org.apache.hadoop.mapred.JobConf, int)"], ["void", "org.apache.hadoop.hbase.mapred.TableMapReduceUtil.addDependencyJars(org.apache.hadoop.mapred.JobConf)"], ["org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit()"], ["org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit(org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit)"], ["org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, java.util.List<java.lang.String>, org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.fs.Path)"], ["long", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit.getLength()"], ["java.lang.String[]", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit.getLocations()"], ["void", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit.write(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat$TableSnapshotRegionSplit.readFields(java.io.DataInput)"], ["org.apache.hadoop.hbase.mapreduce.CellCreator", "org.apache.hadoop.hbase.mapreduce.CellCreator(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.mapreduce.CellCreator.create(byte[], int, int, byte[], int, int, byte[], int, int, long, byte[], int, int)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.mapreduce.CellCreator.create(byte[], int, int, byte[], int, int, byte[], int, int, long, byte[], int, int, java.lang.String)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.mapreduce.CellCreator.create(byte[], int, int, byte[], int, int, byte[], int, int, long, byte[], int, int, java.util.List<org.apache.hadoop.hbase.Tag>)"], ["org.apache.hadoop.hbase.mapreduce.VisibilityExpressionResolver", "org.apache.hadoop.hbase.mapreduce.CellCreator.getVisibilityExpressionResolver()"], ["org.apache.hadoop.hbase.mapreduce.HashTable$HashMapper", "org.apache.hadoop.hbase.mapreduce.HashTable$HashMapper()"], ["org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2()"], ["org.apache.hadoop.mapreduce.RecordWriter<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.Cell>", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configureIncrementalLoad(org.apache.hadoop.mapreduce.Job, org.apache.hadoop.hbase.client.HTable)"], ["void", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configureIncrementalLoad(org.apache.hadoop.mapreduce.Job, org.apache.hadoop.hbase.client.Table, org.apache.hadoop.hbase.client.RegionLocator)"], ["void", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configureIncrementalLoad(org.apache.hadoop.mapreduce.Job, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.client.RegionLocator)"], ["void", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configureIncrementalLoadMap(org.apache.hadoop.mapreduce.Job, org.apache.hadoop.hbase.client.Table)"], ["org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser(java.lang.String, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.hasTimestamp()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.getTimestampKeyColumnIndex()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.hasAttributes()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.hasCellVisibility()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.hasCellTTL()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.getAttributesKeyColumnIndex()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.getCellVisibilityColumnIndex()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.getCellTTLColumnIndex()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.getRowKeyColumnIndex()"], ["byte[]", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.getFamily(int)"], ["byte[]", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.getQualifier(int)"], ["org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser$ParsedLine", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.parse(byte[], int)"], ["org.apache.hadoop.hbase.util.Pair<java.lang.Integer, java.lang.Integer>", "org.apache.hadoop.hbase.mapreduce.ImportTsv$TsvParser.parseRowKey(byte[], int)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$3.call()"], ["org.apache.hadoop.hbase.HColumnDescriptor", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$5.bulkFamily(byte[])"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$5.bulkHFile(org.apache.hadoop.hbase.HColumnDescriptor, org.apache.hadoop.fs.FileStatus)"], ["void", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$5.bulkHFile(java.lang.Object, org.apache.hadoop.fs.FileStatus)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$5.bulkFamily(byte[])"], ["org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormat", "org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormat()"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormat.setInput(org.apache.hadoop.conf.Configuration, java.util.Map<java.lang.String, java.util.Collection<org.apache.hadoop.hbase.client.Scan>>, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$1.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$1.isAborted()"], ["org.apache.hadoop.hbase.mapreduce.SyncTable$SyncMapper$Counter[]", "org.apache.hadoop.hbase.mapreduce.SyncTable$SyncMapper$Counter.values()"], ["org.apache.hadoop.hbase.mapreduce.SyncTable$SyncMapper$Counter", "org.apache.hadoop.hbase.mapreduce.SyncTable$SyncMapper$Counter.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.mapreduce.SyncTable", "org.apache.hadoop.hbase.mapreduce.SyncTable(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.mapreduce.Job", "org.apache.hadoop.hbase.mapreduce.SyncTable.createSubmittableJob(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.SyncTable.main(java.lang.String[])"], ["int", "org.apache.hadoop.hbase.mapreduce.SyncTable.run(java.lang.String[])"], ["org.apache.hadoop.hbase.mapreduce.TableOutputFormat", "org.apache.hadoop.hbase.mapreduce.TableOutputFormat()"], ["org.apache.hadoop.mapreduce.RecordWriter<KEY, org.apache.hadoop.hbase.client.Mutation>", "org.apache.hadoop.hbase.mapreduce.TableOutputFormat.getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputFormat.checkOutputSpecs(org.apache.hadoop.mapreduce.JobContext)"], ["org.apache.hadoop.mapreduce.OutputCommitter", "org.apache.hadoop.hbase.mapreduce.TableOutputFormat.getOutputCommitter(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.mapreduce.TableOutputFormat.getConf()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableOutputFormat.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.mapreduce.TableSplit", "org.apache.hadoop.hbase.mapreduce.TableSplit()"], ["org.apache.hadoop.hbase.mapreduce.TableSplit", "org.apache.hadoop.hbase.mapreduce.TableSplit(byte[], org.apache.hadoop.hbase.client.Scan, byte[], byte[], java.lang.String)"], ["org.apache.hadoop.hbase.mapreduce.TableSplit", "org.apache.hadoop.hbase.mapreduce.TableSplit(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.client.Scan, byte[], byte[], java.lang.String)"], ["org.apache.hadoop.hbase.mapreduce.TableSplit", "org.apache.hadoop.hbase.mapreduce.TableSplit(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.client.Scan, byte[], byte[], java.lang.String, long)"], ["org.apache.hadoop.hbase.mapreduce.TableSplit", "org.apache.hadoop.hbase.mapreduce.TableSplit(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.client.Scan, byte[], byte[], java.lang.String, java.lang.String, long)"], ["org.apache.hadoop.hbase.mapreduce.TableSplit", "org.apache.hadoop.hbase.mapreduce.TableSplit(byte[], byte[], byte[], java.lang.String)"], ["org.apache.hadoop.hbase.mapreduce.TableSplit", "org.apache.hadoop.hbase.mapreduce.TableSplit(org.apache.hadoop.hbase.TableName, byte[], byte[], java.lang.String)"], ["org.apache.hadoop.hbase.mapreduce.TableSplit", "org.apache.hadoop.hbase.mapreduce.TableSplit(org.apache.hadoop.hbase.TableName, byte[], byte[], java.lang.String, long)"], ["org.apache.hadoop.hbase.client.Scan", "org.apache.hadoop.hbase.mapreduce.TableSplit.getScan()"], ["byte[]", "org.apache.hadoop.hbase.mapreduce.TableSplit.getTableName()"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.mapreduce.TableSplit.getTable()"], ["byte[]", "org.apache.hadoop.hbase.mapreduce.TableSplit.getStartRow()"], ["byte[]", "org.apache.hadoop.hbase.mapreduce.TableSplit.getEndRow()"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.TableSplit.getRegionLocation()"], ["java.lang.String[]", "org.apache.hadoop.hbase.mapreduce.TableSplit.getLocations()"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.TableSplit.getEncodedRegionName()"], ["long", "org.apache.hadoop.hbase.mapreduce.TableSplit.getLength()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSplit.readFields(java.io.DataInput)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSplit.write(java.io.DataOutput)"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.TableSplit.toString()"], ["int", "org.apache.hadoop.hbase.mapreduce.TableSplit.compareTo(org.apache.hadoop.hbase.mapreduce.TableSplit)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TableSplit.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.mapreduce.TableSplit.hashCode()"], ["int", "org.apache.hadoop.hbase.mapreduce.TableSplit.compareTo(java.lang.Object)"], ["void", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader.initialize(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader.nextKeyValue()"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader.getCurrentValue()"], ["float", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader.getProgress()"], ["void", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader.close()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader.getCurrentValue()"], ["void", "org.apache.hadoop.hbase.master.ActiveMasterManager.setInfoPort(int)"], ["void", "org.apache.hadoop.hbase.master.ActiveMasterManager.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.ActiveMasterManager.nodeDeleted(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.ActiveMasterManager.stop()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$4.run()"], ["int", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$2.compare(java.lang.Integer, java.lang.Integer)"], ["int", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$2.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$SwapRegionsAction", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$SwapRegionsAction(int, int, int, int)"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$SwapRegionsAction.undoAction()"], ["java.lang.String", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$SwapRegionsAction.toString()"], ["org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer", "org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer()"], ["void", "org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.setConf(org.apache.hadoop.conf.Configuration)"], ["java.util.Map<org.apache.hadoop.hbase.ServerName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>>", "org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.roundRobinAssignment(java.util.List<org.apache.hadoop.hbase.HRegionInfo>, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.randomAssignment(org.apache.hadoop.hbase.HRegionInfo, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.getConf()"], ["void", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.setConf(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.setServices(org.apache.hadoop.hbase.master.MasterServices)"], ["void", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.setClusterStatus(org.apache.hadoop.hbase.ClusterStatus)"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.getBlockDistribution(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.refreshAndWait(java.util.Collection<org.apache.hadoop.hbase.HRegionInfo>)"], ["int", "org.apache.hadoop.hbase.master.CatalogJanitor$SplitParentFirstComparator.compare(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["int", "org.apache.hadoop.hbase.master.CatalogJanitor$SplitParentFirstComparator.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.master.cleaner.BaseHFileCleanerDelegate", "org.apache.hadoop.hbase.master.cleaner.BaseHFileCleanerDelegate()"], ["void", "org.apache.hadoop.hbase.master.cleaner.BaseHFileCleanerDelegate.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.BaseHFileCleanerDelegate.isStopped()"], ["java.lang.Boolean", "org.apache.hadoop.hbase.master.cleaner.CleanerChore$CleanerTask$3.act()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.cleaner.CleanerChore$CleanerTask$3.act()"], ["java.lang.Boolean", "org.apache.hadoop.hbase.master.cleaner.CleanerChore$CleanerTask$5.act()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.cleaner.CleanerChore$CleanerTask$5.act()"], ["void", "org.apache.hadoop.hbase.master.cleaner.LogCleaner$1.run()"], ["org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner", "org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner()"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner.isLogDeletable(org.apache.hadoop.fs.FileStatus)"], ["void", "org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner.setConf(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner.isStopped()"], ["org.apache.hadoop.hbase.master.ClusterStatusPublisher", "org.apache.hadoop.hbase.master.ClusterStatusPublisher(org.apache.hadoop.hbase.master.HMaster, org.apache.hadoop.conf.Configuration, java.lang.Class<? extends org.apache.hadoop.hbase.master.ClusterStatusPublisher$Publisher>)"], ["org.apache.hadoop.hbase.master.GeneralBulkAssigner", "org.apache.hadoop.hbase.master.GeneralBulkAssigner(org.apache.hadoop.hbase.Server, java.util.Map<org.apache.hadoop.hbase.ServerName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>>, org.apache.hadoop.hbase.master.AssignmentManager, boolean)"], ["org.apache.hadoop.hbase.master.handler.EnableTableHandler", "org.apache.hadoop.hbase.master.handler.EnableTableHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.master.AssignmentManager, org.apache.hadoop.hbase.master.TableLockManager, boolean)"], ["org.apache.hadoop.hbase.master.handler.EnableTableHandler", "org.apache.hadoop.hbase.master.handler.EnableTableHandler(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.master.AssignmentManager, org.apache.hadoop.hbase.master.TableLockManager, boolean)"], ["org.apache.hadoop.hbase.master.handler.EnableTableHandler", "org.apache.hadoop.hbase.master.handler.EnableTableHandler.prepare()"], ["java.lang.String", "org.apache.hadoop.hbase.master.handler.EnableTableHandler.toString()"], ["void", "org.apache.hadoop.hbase.master.handler.EnableTableHandler.process()"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.master.handler.EnableTableHandler.prepare()"], ["void", "org.apache.hadoop.hbase.master.HMaster$2.run()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$101.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$112.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$14.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$20.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$27.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$34.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$36.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$55.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$8.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$82.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$96.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.master.MasterDumpServlet", "org.apache.hadoop.hbase.master.MasterDumpServlet()"], ["void", "org.apache.hadoop.hbase.master.MasterDumpServlet.doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.master.MasterStatusServlet", "org.apache.hadoop.hbase.master.MasterStatusServlet()"], ["void", "org.apache.hadoop.hbase.master.MasterStatusServlet.doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.master.MetricsMasterFileSystem", "org.apache.hadoop.hbase.master.MetricsMasterFileSystem()"], ["synchronized", "org.apache.hadoop.hbase.master.MetricsMasterFileSystem.void addSplit(long, long)"], ["synchronized", "org.apache.hadoop.hbase.master.MetricsMasterFileSystem.void addMetaWALSplit(long, long)"], ["org.apache.hadoop.hbase.master.normalizer.RegionNormalizerChore", "org.apache.hadoop.hbase.master.normalizer.RegionNormalizerChore(org.apache.hadoop.hbase.master.HMaster)"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure$1.run()"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure$2.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure$2.run()"], ["java.lang.Void", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure$1.run()"], ["org.apache.hadoop.hbase.master.procedure.EnableTableProcedure", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure()"], ["org.apache.hadoop.hbase.master.procedure.EnableTableProcedure", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, boolean)"], ["org.apache.hadoop.hbase.master.procedure.EnableTableProcedure", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, boolean, org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.deserializeStateData(java.io.InputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.abort(java.lang.Object)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil$NonceProcedureRunnable", "org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil$NonceProcedureRunnable(org.apache.hadoop.hbase.master.MasterServices, long, long)"], ["void", "org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch$NoopLatch.await()"], ["org.apache.hadoop.hbase.master.RegionPlan", "org.apache.hadoop.hbase.master.RegionPlan(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.RegionPlan.setDestination(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.master.RegionPlan.getSource()"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.master.RegionPlan.getDestination()"], ["java.lang.String", "org.apache.hadoop.hbase.master.RegionPlan.getRegionName()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.master.RegionPlan.getRegionInfo()"], ["int", "org.apache.hadoop.hbase.master.RegionPlan.compareTo(org.apache.hadoop.hbase.master.RegionPlan)"], ["int", "org.apache.hadoop.hbase.master.RegionPlan.hashCode()"], ["boolean", "org.apache.hadoop.hbase.master.RegionPlan.equals(java.lang.Object)"], ["java.lang.String", "org.apache.hadoop.hbase.master.RegionPlan.toString()"], ["int", "org.apache.hadoop.hbase.master.RegionPlan.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor, boolean)"], ["org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.prepare()"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.isFinished()"], ["long", "org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.getCompletionTimestamp()"], ["org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription", "org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.getSnapshot()"], ["void", "org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.cancel(java.lang.String)"], ["org.apache.hadoop.hbase.errorhandling.ForeignException", "org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.getExceptionIfFailed()"], ["void", "org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.rethrowExceptionIfFailed()"], ["org.apache.hadoop.hbase.master.handler.TableEventHandler", "org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.prepare()"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.prepare()"], ["org.apache.hadoop.hbase.master.TableLockManager$NullTableLockManager", "org.apache.hadoop.hbase.master.TableLockManager$NullTableLockManager()"], ["org.apache.hadoop.hbase.master.TableLockManager$TableLock", "org.apache.hadoop.hbase.master.TableLockManager$NullTableLockManager.writeLock(org.apache.hadoop.hbase.TableName, java.lang.String)"], ["org.apache.hadoop.hbase.master.TableLockManager$TableLock", "org.apache.hadoop.hbase.master.TableLockManager$NullTableLockManager.readLock(org.apache.hadoop.hbase.TableName, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$NullTableLockManager.reapAllExpiredLocks()"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$NullTableLockManager.reapWriteLocks()"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$NullTableLockManager.tableDeleted(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$NullTableLockManager.visitAllLocks(org.apache.hadoop.hbase.InterProcessLock$MetadataHandler)"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager$1.handleMetadata(byte[])"], ["int", "org.apache.hadoop.hbase.migration.UpgradeTo96.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.migration.UpgradeTo96.main(java.lang.String[])"], ["org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer", "org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer(long)"], ["synchronized", "org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer.void add(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer.void dumpTo(java.io.PrintWriter)"], ["org.apache.hadoop.hbase.namespace.NamespaceAuditor", "org.apache.hadoop.hbase.namespace.NamespaceAuditor(org.apache.hadoop.hbase.master.MasterServices)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.start()"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.checkQuotaToCreateTable(org.apache.hadoop.hbase.TableName, int)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.checkQuotaToUpdateRegion(org.apache.hadoop.hbase.TableName, int)"], ["int", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.getRegionCountOfTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.checkQuotaToSplitRegion(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.updateQuotaForRegionMerge(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.addNamespace(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.deleteNamespace(java.lang.String)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.removeFromNamespaceUsage(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.removeRegionFromNamespaceUsage(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.namespace.NamespaceTableAndRegionInfo", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.getState(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.namespace.NamespaceAuditor.isInitialized()"], ["java.lang.Void", "org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure$RegionFlushTask.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure$RegionFlushTask.call()"], ["org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager$FlushTableSubprocedureBuilder", "org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager$FlushTableSubprocedureBuilder(org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager)"], ["org.apache.hadoop.hbase.procedure.Subprocedure", "org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager$FlushTableSubprocedureBuilder.buildSubprocedure(java.lang.String, byte[])"], ["org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager", "org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager()"], ["void", "org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.start()"], ["void", "org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.stop(boolean)"], ["org.apache.hadoop.hbase.procedure.Subprocedure", "org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.buildSubprocedure(java.lang.String)"], ["void", "org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.initialize(org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.getProcedureSignature()"], ["org.apache.hadoop.hbase.procedure.RegionServerProcedureManager", "org.apache.hadoop.hbase.procedure.RegionServerProcedureManager()"], ["void", "org.apache.hadoop.hbase.procedure.Subprocedure$1.receive(org.apache.hadoop.hbase.errorhandling.ForeignException)"], ["org.apache.hadoop.hbase.quotas.DefaultOperationQuota", "org.apache.hadoop.hbase.quotas.DefaultOperationQuota(org.apache.hadoop.hbase.quotas.QuotaLimiter...)"], ["org.apache.hadoop.hbase.quotas.DefaultOperationQuota", "org.apache.hadoop.hbase.quotas.DefaultOperationQuota(java.util.List<org.apache.hadoop.hbase.quotas.QuotaLimiter>)"], ["void", "org.apache.hadoop.hbase.quotas.DefaultOperationQuota.checkQuota(int, int, int)"], ["void", "org.apache.hadoop.hbase.quotas.DefaultOperationQuota.close()"], ["long", "org.apache.hadoop.hbase.quotas.DefaultOperationQuota.getReadAvailable()"], ["long", "org.apache.hadoop.hbase.quotas.DefaultOperationQuota.getWriteAvailable()"], ["void", "org.apache.hadoop.hbase.quotas.DefaultOperationQuota.addGetResult(org.apache.hadoop.hbase.client.Result)"], ["void", "org.apache.hadoop.hbase.quotas.DefaultOperationQuota.addScanResult(java.util.List<org.apache.hadoop.hbase.client.Result>)"], ["void", "org.apache.hadoop.hbase.quotas.DefaultOperationQuota.addMutation(org.apache.hadoop.hbase.client.Mutation)"], ["org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$3.fetch()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$3.update(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$3.delete()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$3.preApply(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$3.postApply(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.checkQuota(long, long, long, long)"], ["void", "org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.grabQuota(long, long, long, long)"], ["void", "org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.consumeWrite(long)"], ["void", "org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.consumeRead(long)"], ["boolean", "org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.isBypass()"], ["long", "org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.getWriteAvailable()"], ["long", "org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.getReadAvailable()"], ["java.lang.String", "org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.toString()"], ["org.apache.hadoop.hbase.quotas.QuotaLimiter", "org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.get()"], ["org.apache.hadoop.hbase.quotas.QuotaCache", "org.apache.hadoop.hbase.quotas.QuotaCache(org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaCache.start()"], ["void", "org.apache.hadoop.hbase.quotas.QuotaCache.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.quotas.QuotaCache.isStopped()"], ["org.apache.hadoop.hbase.quotas.QuotaLimiter", "org.apache.hadoop.hbase.quotas.QuotaCache.getUserLimiter(org.apache.hadoop.security.UserGroupInformation, org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.quotas.UserQuotaState", "org.apache.hadoop.hbase.quotas.QuotaCache.getUserQuotaState(org.apache.hadoop.security.UserGroupInformation)"], ["org.apache.hadoop.hbase.quotas.QuotaLimiter", "org.apache.hadoop.hbase.quotas.QuotaCache.getTableLimiter(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.quotas.QuotaLimiter", "org.apache.hadoop.hbase.quotas.QuotaCache.getNamespaceLimiter(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.quotas.QuotaCache.isTEST_FORCE_REFRESH()"], ["void", "org.apache.hadoop.hbase.quotas.QuotaCache.setTEST_FORCE_REFRESH(boolean)"], ["org.apache.hadoop.hbase.regionserver.BusyRegionSplitPolicy", "org.apache.hadoop.hbase.regionserver.BusyRegionSplitPolicy()"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest$1.apply(org.apache.hadoop.hbase.regionserver.StoreFile)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest$1.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest$DisplayCompactionType[]", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest$DisplayCompactionType.values()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest$DisplayCompactionType", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest$DisplayCompactionType.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.DateTieredMultiFileWriter", "org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactor$1.createWriter(org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.compactions.Compactor$FileDetails, boolean)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactor$1.createWriter(org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.compactions.Compactor$FileDetails, boolean)"], ["org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory", "org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory(org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionWindow", "org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory.newIncomingWindow(long)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory.toString()"], ["org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy", "org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.StoreConfigInformation)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy.selectCompaction(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>, boolean, boolean, boolean)"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy.getNextMajorCompactTime(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy.throttleCompaction(long)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionWorker$1.getTempDir()"], ["org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy", "org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy()"], ["boolean", "org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.positiveJitterRate()"], ["org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner$StepDirection[]", "org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner$StepDirection.values()"], ["org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner$StepDirection", "org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner$StepDirection.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.DeleteTracker$DeleteResult[]", "org.apache.hadoop.hbase.regionserver.DeleteTracker$DeleteResult.values()"], ["org.apache.hadoop.hbase.regionserver.DeleteTracker$DeleteResult", "org.apache.hadoop.hbase.regionserver.DeleteTracker$DeleteResult.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.FlushPolicy", "org.apache.hadoop.hbase.regionserver.FlushPolicy()"], ["org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler", "org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.HRegionInfo, boolean, org.apache.hadoop.hbase.coordination.CloseRegionCoordination, org.apache.hadoop.hbase.coordination.CloseRegionCoordination$CloseRegionDetails)"], ["org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler", "org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.HRegionInfo, boolean, org.apache.hadoop.hbase.coordination.CloseRegionCoordination, org.apache.hadoop.hbase.coordination.CloseRegionCoordination$CloseRegionDetails, org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler", "org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.HRegionInfo, boolean, org.apache.hadoop.hbase.coordination.CloseRegionCoordination, org.apache.hadoop.hbase.coordination.CloseRegionCoordination$CloseRegionDetails, org.apache.hadoop.hbase.executor.EventType)"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.getRegionInfo()"], ["void", "org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process()"], ["org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext()"], ["long", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.getBlockedFlushCount()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.setBlockedFlushCount(long)"], ["long", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.getUnblockedFlushCount()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.setUnblockedFlushCount(long)"], ["long", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.getEvictCount()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.setEvictCount(long)"], ["float", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.getCurMemStoreSize()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.setCurMemStoreSize(float)"], ["float", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.getCurBlockCacheSize()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.setCurBlockCacheSize(float)"], ["long", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.getCacheMissCount()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.setCacheMissCount(long)"], ["float", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.getCurBlockCacheUsed()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.setCurBlockCacheUsed(float)"], ["float", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.getCurMemStoreUsed()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext.setCurMemStoreUsed(float)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion$6.add(int, org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion$6.addAll(int, java.util.Collection<? extends org.apache.hadoop.hbase.Cell>)"], ["org.apache.hadoop.hbase.KeyValue", "org.apache.hadoop.hbase.regionserver.HRegion$6.get(int)"], ["int", "org.apache.hadoop.hbase.regionserver.HRegion$6.size()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion$6.add(int, java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.HRegion$6.get(int)"], ["org.apache.hadoop.hbase.regionserver.HRegion$ReplayBatch", "org.apache.hadoop.hbase.regionserver.HRegion$ReplayBatch(org.apache.hadoop.hbase.wal.WALSplitter$MutationReplay[], long)"], ["org.apache.hadoop.hbase.client.Mutation", "org.apache.hadoop.hbase.regionserver.HRegion$ReplayBatch.getMutation(int)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion$ReplayBatch.getNonceGroup(int)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion$ReplayBatch.getNonce(int)"], ["org.apache.hadoop.hbase.client.Mutation[]", "org.apache.hadoop.hbase.regionserver.HRegion$ReplayBatch.getMutationsForCoprocs()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion$ReplayBatch.isInReplay()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion$ReplayBatch.getReplaySequenceId()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer$2.handle(sun.misc.Signal)"], ["org.apache.hadoop.hbase.regionserver.HRegionServer$MovedRegionInfo", "org.apache.hadoop.hbase.regionserver.HRegionServer$MovedRegionInfo(org.apache.hadoop.hbase.ServerName, long)"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.regionserver.HRegionServer$MovedRegionInfo.getServerName()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegionServer$MovedRegionInfo.getSeqNum()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegionServer$MovedRegionInfo.getMoveTime()"], ["org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine", "org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine(java.lang.Class<? extends org.apache.hadoop.hbase.regionserver.HRegionServer>)"], ["int", "org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.prepare()"], ["void", "org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(org.apache.hadoop.hbase.monitoring.MonitoredTask)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.commit(org.apache.hadoop.hbase.monitoring.MonitoredTask)"], ["long", "org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.getOutputFileSize()"], ["void", "org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.replayFlush(java.util.List<java.lang.String>, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.abort()"], ["org.apache.hadoop.hbase.regionserver.KeyValueHeap", "org.apache.hadoop.hbase.regionserver.KeyValueHeap(java.util.List<? extends org.apache.hadoop.hbase.regionserver.KeyValueScanner>, org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.KeyValueHeap.peek()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.KeyValueHeap.next()"], ["boolean", "org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(java.util.List<org.apache.hadoop.hbase.Cell>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(java.util.List<org.apache.hadoop.hbase.Cell>, org.apache.hadoop.hbase.regionserver.ScannerContext)"], ["void", "org.apache.hadoop.hbase.regionserver.KeyValueHeap.close()"], ["boolean", "org.apache.hadoop.hbase.regionserver.KeyValueHeap.seek(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.KeyValueHeap.requestSeek(org.apache.hadoop.hbase.Cell, boolean, boolean)"], ["long", "org.apache.hadoop.hbase.regionserver.KeyValueHeap.getScannerOrder()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.KeyValueHeap.getNextIndexedKey()"], ["void", "org.apache.hadoop.hbase.regionserver.LogRoller$1.logRollRequested(boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run()"], ["org.apache.hadoop.hbase.regionserver.MemStoreSnapshot", "org.apache.hadoop.hbase.regionserver.MemStoreSnapshot(long, int, long, org.apache.hadoop.hbase.regionserver.TimeRangeTracker, org.apache.hadoop.hbase.regionserver.KeyValueScanner, boolean)"], ["long", "org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.getId()"], ["int", "org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.getCellsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.getSize()"], ["org.apache.hadoop.hbase.regionserver.TimeRangeTracker", "org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.getTimeRangeTracker()"], ["org.apache.hadoop.hbase.regionserver.KeyValueScanner", "org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.getScanner()"], ["boolean", "org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.isTagsPresent()"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionServer", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer(org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.getMetricsSource()"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.getRegionServerWrapper()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updatePutBatch(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updatePut(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateDelete(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateDeleteBatch(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateCheckAndDelete(long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateCheckAndPut(long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateGet(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateIncrement(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateAppend(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateReplay(long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateScanSize(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateScanTime(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateSplitTime(long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.incrSplitRequest()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.incrSplitSuccess()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateFlush(long, long, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateCompaction(boolean, long, int, int, long, long)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServer.updateBulkLoad(long)"], ["boolean", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.readOnly()"], ["org.apache.hadoop.hbase.protobuf.generated.MultiRowMutationProtos$MultiRowMutationProcessorResponse", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.getResult()"], ["void", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.process(long, org.apache.hadoop.hbase.regionserver.HRegion, java.util.List<org.apache.hadoop.hbase.client.Mutation>, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.preProcess(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.preBatchMutate(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.postBatchMutate(org.apache.hadoop.hbase.regionserver.HRegion)"], ["void", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.postProcess(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.wal.WALEdit, boolean)"], ["org.apache.hadoop.hbase.protobuf.generated.MultiRowMutationProtos$MultiRowMutationProcessorRequest", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.getRequestData()"], ["void", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.initialize(org.apache.hadoop.hbase.protobuf.generated.MultiRowMutationProtos$MultiRowMutationProcessorRequest)"], ["org.apache.hadoop.hbase.client.Durability", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.useDurability()"], ["void", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.initialize(com.google.protobuf.Message)"], ["com.google.protobuf.Message", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.getRequestData()"], ["com.google.protobuf.Message", "org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.getResult()"], ["org.apache.hadoop.hbase.regionserver.OperationStatus", "org.apache.hadoop.hbase.regionserver.OperationStatus(org.apache.hadoop.hbase.HConstants$OperationStatusCode)"], ["org.apache.hadoop.hbase.regionserver.OperationStatus", "org.apache.hadoop.hbase.regionserver.OperationStatus(org.apache.hadoop.hbase.HConstants$OperationStatusCode, java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.OperationStatus", "org.apache.hadoop.hbase.regionserver.OperationStatus(org.apache.hadoop.hbase.HConstants$OperationStatusCode, java.lang.Exception)"], ["org.apache.hadoop.hbase.HConstants$OperationStatusCode", "org.apache.hadoop.hbase.regionserver.OperationStatus.getOperationStatusCode()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.OperationStatus.getExceptionMsg()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher.match(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher.hasNullColumnInQuery()"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher.isUserScan()"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher.moreRowsMayExistAfter(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.filter.Filter", "org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher.getFilter()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher.getNextKeyHint(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher", "org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher.create(org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.ScanInfo, java.util.NavigableSet<byte[]>, org.apache.hadoop.hbase.regionserver.ScanType, long, long, long, long, byte[], byte[], org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode[]", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode.values()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode.valueOf(java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$10.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$17.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$3.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$37.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$44.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$51.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$59.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$66.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$9.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.testTableCoprocessorAttrs(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HTableDescriptor)"], ["org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.createEnvironment(java.lang.Class<?>, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preOpen()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postOpen()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postLogReplay()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preClose(boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postClose(boolean)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preCompactScannerOpen(org.apache.hadoop.hbase.regionserver.Store, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFileScanner>, org.apache.hadoop.hbase.regionserver.ScanType, long, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest, long)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preCompactSelection(org.apache.hadoop.hbase.regionserver.Store, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postCompactSelection(org.apache.hadoop.hbase.regionserver.Store, com.google.common.collect.ImmutableList<org.apache.hadoop.hbase.regionserver.StoreFile>, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preCompact(org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.ScanType, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postCompact(org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.StoreFile, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preFlush(org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preFlush()"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preFlushScannerOpen(org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.KeyValueScanner, long)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postFlush()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postFlush(org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.StoreFile)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preSplit()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preSplit(byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postSplit(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preSplitBeforePONR(byte[], java.util.List<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preSplitAfterPONR()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preRollBackSplit()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postRollBackSplit()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postCompleteSplit()"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preGetClosestRowBefore(byte[], byte[], org.apache.hadoop.hbase.client.Result)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postGetClosestRowBefore(byte[], byte[], org.apache.hadoop.hbase.client.Result)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preGet(org.apache.hadoop.hbase.client.Get, java.util.List<org.apache.hadoop.hbase.Cell>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postGet(org.apache.hadoop.hbase.client.Get, java.util.List<org.apache.hadoop.hbase.Cell>)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preExists(org.apache.hadoop.hbase.client.Get)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postExists(org.apache.hadoop.hbase.client.Get, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.prePut(org.apache.hadoop.hbase.client.Put, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.prePrepareTimeStampForDeleteVersion(org.apache.hadoop.hbase.client.Mutation, org.apache.hadoop.hbase.Cell, byte[], org.apache.hadoop.hbase.client.Get)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postPut(org.apache.hadoop.hbase.client.Put, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preDelete(org.apache.hadoop.hbase.client.Delete, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postDelete(org.apache.hadoop.hbase.client.Delete, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preBatchMutate(org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postBatchMutate(org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postBatchMutateIndispensably(org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress<org.apache.hadoop.hbase.client.Mutation>, boolean)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preCheckAndPut(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Put)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preCheckAndPutAfterRowLock(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Put)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postCheckAndPut(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Put, boolean)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preCheckAndDelete(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Delete)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preCheckAndDeleteAfterRowLock(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Delete)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postCheckAndDelete(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Delete, boolean)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preAppend(org.apache.hadoop.hbase.client.Append)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preAppendAfterRowLock(org.apache.hadoop.hbase.client.Append)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preIncrement(org.apache.hadoop.hbase.client.Increment)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preIncrementAfterRowLock(org.apache.hadoop.hbase.client.Increment)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postAppend(org.apache.hadoop.hbase.client.Append, org.apache.hadoop.hbase.client.Result)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postIncrement(org.apache.hadoop.hbase.client.Increment, org.apache.hadoop.hbase.client.Result)"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preScannerOpen(org.apache.hadoop.hbase.client.Scan)"], ["org.apache.hadoop.hbase.regionserver.KeyValueScanner", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preStoreScannerOpen(org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.client.Scan, java.util.NavigableSet<byte[]>)"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postScannerOpen(org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.RegionScanner)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preScannerNext(org.apache.hadoop.hbase.regionserver.InternalScanner, java.util.List<org.apache.hadoop.hbase.client.Result>, int)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postScannerNext(org.apache.hadoop.hbase.regionserver.InternalScanner, java.util.List<org.apache.hadoop.hbase.client.Result>, int, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postScannerFilterRow(org.apache.hadoop.hbase.regionserver.InternalScanner, byte[], int, short)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preScannerClose(org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postScannerClose(org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preWALRestore(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preWALRestore(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.regionserver.wal.HLogKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postWALRestore(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postWALRestore(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.regionserver.wal.HLogKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preCommitStoreFile(byte[], java.util.List<org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path>>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postCommitStoreFile(byte[], org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preBulkLoadHFile(java.util.List<org.apache.hadoop.hbase.util.Pair<byte[], java.lang.String>>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postBulkLoadHFile(java.util.List<org.apache.hadoop.hbase.util.Pair<byte[], java.lang.String>>, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postStartRegionOperation(org.apache.hadoop.hbase.regionserver.Region$Operation)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postCloseRegionOperation(org.apache.hadoop.hbase.regionserver.Region$Operation)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Reader", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preStoreFileReaderOpen(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.FSDataInputStreamWrapper, long, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.io.Reference)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Reader", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postStoreFileReaderOpen(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.FSDataInputStreamWrapper, long, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.io.Reference, org.apache.hadoop.hbase.regionserver.StoreFile$Reader)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postMutationBeforeWAL(org.apache.hadoop.hbase.coprocessor.RegionObserver$MutationType, org.apache.hadoop.hbase.client.Mutation, org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.Cell)"], ["com.google.protobuf.Message", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preEndpointInvocation(com.google.protobuf.Service, java.lang.String, com.google.protobuf.Message)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postEndpointInvocation(com.google.protobuf.Service, java.lang.String, com.google.protobuf.Message, com.google.protobuf.Message$Builder)"], ["org.apache.hadoop.hbase.regionserver.DeleteTracker", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.postInstantiateDeleteTracker(org.apache.hadoop.hbase.regionserver.DeleteTracker)"], ["org.apache.hadoop.hbase.CoprocessorEnvironment", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.createEnvironment(java.lang.Class, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$CoprocessorOperation", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$CoprocessorOperation()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$CoprocessorOperation.postEnvCall(org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$RegionServerEnvironment)"], ["org.apache.hadoop.hbase.regionserver.RegionSplitPolicy", "org.apache.hadoop.hbase.regionserver.RegionSplitPolicy()"], ["org.apache.hadoop.hbase.regionserver.RegionSplitPolicy", "org.apache.hadoop.hbase.regionserver.RegionSplitPolicy.create(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.conf.Configuration)"], ["java.lang.Class<? extends org.apache.hadoop.hbase.regionserver.RegionSplitPolicy>", "org.apache.hadoop.hbase.regionserver.RegionSplitPolicy.getSplitPolicyClass(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.RSRpcServices$RegionScannerHolder", "org.apache.hadoop.hbase.regionserver.RSRpcServices$RegionScannerHolder(java.lang.String, org.apache.hadoop.hbase.regionserver.RegionScanner, org.apache.hadoop.hbase.regionserver.Region, boolean)"], ["long", "org.apache.hadoop.hbase.regionserver.RSRpcServices$RegionScannerHolder.getNextCallSeq()"], ["boolean", "org.apache.hadoop.hbase.regionserver.RSRpcServices$RegionScannerHolder.incNextCallSeq(long)"], ["org.apache.hadoop.hbase.regionserver.RSStatusServlet", "org.apache.hadoop.hbase.regionserver.RSStatusServlet()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.ScannerContext.getLastPeekedCell()"], ["void", "org.apache.hadoop.hbase.regionserver.ScannerContext.setLastPeekedCell(org.apache.hadoop.hbase.Cell)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.ScannerContext.toString()"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$Builder", "org.apache.hadoop.hbase.regionserver.ScannerContext.newBuilder()"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$Builder", "org.apache.hadoop.hbase.regionserver.ScannerContext.newBuilder(boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.ShutdownHook$DoNothingThread.run()"], ["org.apache.hadoop.hbase.regionserver.SplitLogWorker$TaskExecutor$Status[]", "org.apache.hadoop.hbase.regionserver.SplitLogWorker$TaskExecutor$Status.values()"], ["org.apache.hadoop.hbase.regionserver.SplitLogWorker$TaskExecutor$Status", "org.apache.hadoop.hbase.regionserver.SplitLogWorker$TaskExecutor$Status.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.SplitTransactionFactory", "org.apache.hadoop.hbase.regionserver.SplitTransactionFactory(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.regionserver.SplitTransactionFactory.getConf()"], ["void", "org.apache.hadoop.hbase.regionserver.SplitTransactionFactory.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.SplitTransaction", "org.apache.hadoop.hbase.regionserver.SplitTransactionFactory.create(org.apache.hadoop.hbase.regionserver.Region, byte[])"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators$GetPathName.apply(org.apache.hadoop.hbase.regionserver.StoreFile)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators$GetPathName.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.StoreFileInfo", "org.apache.hadoop.hbase.regionserver.StoreFileInfo(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.regionserver.StoreFileInfo", "org.apache.hadoop.hbase.regionserver.StoreFileInfo(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.FileStatus)"], ["org.apache.hadoop.hbase.regionserver.StoreFileInfo", "org.apache.hadoop.hbase.regionserver.StoreFileInfo(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.FileStatus, org.apache.hadoop.hbase.io.HFileLink)"], ["org.apache.hadoop.hbase.regionserver.StoreFileInfo", "org.apache.hadoop.hbase.regionserver.StoreFileInfo(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.FileStatus, org.apache.hadoop.hbase.io.Reference)"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.setRegionCoprocessorHost(org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost)"], ["org.apache.hadoop.hbase.io.Reference", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.getReference()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.isReference()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.isTopReference()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.isLink()"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.getHDFSBlockDistribution()"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Reader", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.open(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.io.hfile.CacheConfig, boolean)"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.computeHDFSBlocksDistribution(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.fs.FileStatus", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.getReferencedFileStatus(org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.getPath()"], ["org.apache.hadoop.fs.FileStatus", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.getFileStatus()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.getModificationTime()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.toString()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.isHFile(org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.isHFile(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.isReference(org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.isReference(java.lang.String)"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.getCreatedTimestamp()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.getReferredToFile(org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.validateStoreFileName(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.isValid(org.apache.hadoop.fs.FileStatus)"], ["int", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.hashCode()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFileInfo.equals(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter$SizeMultiWriter", "org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter$SizeMultiWriter(org.apache.hadoop.hbase.KeyValue$KVComparator, int, long, byte[], byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter$SizeMultiWriter.append(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.StripeStoreFileManager$CompactionOrFlushMergeCopy", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager$CompactionOrFlushMergeCopy(org.apache.hadoop.hbase.regionserver.StripeStoreFileManager, boolean)"], ["org.apache.hadoop.hbase.regionserver.TimeRangeTracker", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker()"], ["org.apache.hadoop.hbase.regionserver.TimeRangeTracker", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker(org.apache.hadoop.hbase.regionserver.TimeRangeTracker)"], ["org.apache.hadoop.hbase.regionserver.TimeRangeTracker", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker(long, long)"], ["void", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker.includeTimestamp(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker.includesTimeRange(org.apache.hadoop.hbase.io.TimeRange)"], ["long", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker.getMin()"], ["long", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker.getMax()"], ["void", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker.write(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker.readFields(java.io.DataInput)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker.toString()"], ["org.apache.hadoop.hbase.regionserver.TimeRangeTracker", "org.apache.hadoop.hbase.regionserver.TimeRangeTracker.getTimeRangeTracker(byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$SyncRunner.run()"], ["org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.init(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.append(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.close()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync()"], ["long", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.getLength()"], ["org.apache.hadoop.fs.FSDataOutputStream", "org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.getStream()"], ["org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader", "org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.close()"], ["long", "org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.getPosition()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.reset()"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.regionserver.wal.WALEdit()"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.regionserver.wal.WALEdit(boolean)"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.regionserver.wal.WALEdit(int)"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.regionserver.wal.WALEdit(int, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.isMetaEditFamily(byte[])"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.isMetaEditFamily(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.isMetaEdit()"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.isReplay()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.setCompressionContext(org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.add(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.isEmpty()"], ["int", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.size()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.setCells(java.util.ArrayList<org.apache.hadoop.hbase.Cell>)"], ["java.util.NavigableMap<byte[], java.lang.Integer>", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.getAndRemoveScopes()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.readFields(java.io.DataInput)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.write(java.io.DataOutput)"], ["int", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.readFromCells(org.apache.hadoop.hbase.codec.Codec$Decoder, int)"], ["long", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.heapSize()"], ["long", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.estimatedSerializedSizeOf()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.toString()"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.createFlushWALEdit(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.protobuf.generated.WALProtos$FlushDescriptor)"], ["org.apache.hadoop.hbase.protobuf.generated.WALProtos$FlushDescriptor", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.getFlushDescriptor(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.createRegionEventWALEdit(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.protobuf.generated.WALProtos$RegionEventDescriptor)"], ["org.apache.hadoop.hbase.protobuf.generated.WALProtos$RegionEventDescriptor", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.getRegionEventDescriptor(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.createCompaction(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.protobuf.generated.WALProtos$CompactionDescriptor)"], ["byte[]", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.getRowForRegion(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.protobuf.generated.WALProtos$CompactionDescriptor", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.getCompaction(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.isCompactionMarker(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.createBulkLoadEvent(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.protobuf.generated.WALProtos$BulkLoadDescriptor)"], ["org.apache.hadoop.hbase.protobuf.generated.WALProtos$BulkLoadDescriptor", "org.apache.hadoop.hbase.regionserver.wal.WALEdit.getBulkLoadDescriptor(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner$1.apply(org.apache.hadoop.fs.FileStatus)"], ["boolean", "org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner$1.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.replication.regionserver.DefaultSourceFSConfigurationProvider", "org.apache.hadoop.hbase.replication.regionserver.DefaultSourceFSConfigurationProvider()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.replication.regionserver.DefaultSourceFSConfigurationProvider.getConf(org.apache.hadoop.conf.Configuration, java.lang.String)"], ["org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint", "org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.init(org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.replicate(org.apache.hadoop.hbase.replication.ReplicationEndpoint$ReplicateContext)"], ["com.google.common.util.concurrent.Service$State", "org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.stopAndWait()"], ["org.apache.hadoop.hbase.replication.regionserver.Replication", "org.apache.hadoop.hbase.replication.regionserver.Replication(org.apache.hadoop.hbase.Server, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.replication.regionserver.Replication", "org.apache.hadoop.hbase.replication.regionserver.Replication()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.initialize(org.apache.hadoop.hbase.Server, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.Replication.isReplication(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.Replication.isReplicationForBulkLoadDataEnabled(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.wal.WALActionsListener", "org.apache.hadoop.hbase.replication.regionserver.Replication.getWALActionsListener()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.stopReplicationService()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.join()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.replicateLogEntries(java.util.List<org.apache.hadoop.hbase.protobuf.generated.AdminProtos$WALEntry>, org.apache.hadoop.hbase.CellScanner, java.lang.String, java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.startReplicationService()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager", "org.apache.hadoop.hbase.replication.regionserver.Replication.getReplicationManager()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.visitLogEntryBeforeWrite(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.scopeWALEdits(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.preLogRoll(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.postLogRoll(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.decorateMasterConfiguration(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication.decorateRegionServerConfiguration(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad", "org.apache.hadoop.hbase.replication.regionserver.Replication.refreshAndGetReplicationLoad()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager$NodeFailoverWorker", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager$NodeFailoverWorker(org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager, java.lang.String)"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager$NodeFailoverWorker", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager$NodeFailoverWorker(org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager, java.lang.String, org.apache.hadoop.hbase.replication.ReplicationQueues, org.apache.hadoop.hbase.replication.ReplicationPeers, java.util.UUID)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager$NodeFailoverWorker.run()"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream$1.progress()"], ["org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context(org.apache.hadoop.conf.Configuration, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, java.lang.String, java.util.UUID, org.apache.hadoop.hbase.replication.ReplicationPeer, org.apache.hadoop.hbase.replication.regionserver.MetricsSource, org.apache.hadoop.hbase.TableDescriptors, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context.getConfiguration()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context.getLocalConfiguration()"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context.getFilesystem()"], ["java.util.UUID", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context.getClusterId()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context.getPeerId()"], ["org.apache.hadoop.hbase.replication.ReplicationPeerConfig", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context.getPeerConfig()"], ["org.apache.hadoop.hbase.replication.ReplicationPeer", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context.getReplicationPeer()"], ["org.apache.hadoop.hbase.replication.regionserver.MetricsSource", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context.getMetrics()"], ["org.apache.hadoop.hbase.TableDescriptors", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context.getTableDescriptors()"], ["org.apache.hadoop.hbase.Abortable", "org.apache.hadoop.hbase.replication.ReplicationEndpoint$Context.getAbortable()"], ["org.apache.hadoop.hbase.replication.TableCfWALEntryFilter", "org.apache.hadoop.hbase.replication.TableCfWALEntryFilter(org.apache.hadoop.hbase.replication.ReplicationPeer)"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.replication.TableCfWALEntryFilter.filter(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.replication.TableCfWALEntryFilter.filterCell(org.apache.hadoop.hbase.wal.WAL$Entry, org.apache.hadoop.hbase.Cell)"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$12.run()"], ["java.lang.Void", "org.apache.hadoop.hbase.security.access.AccessController$8.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$8.run()"], ["org.apache.hadoop.hbase.security.access.AccessController$OpType[]", "org.apache.hadoop.hbase.security.access.AccessController$OpType.values()"], ["org.apache.hadoop.hbase.security.access.AccessController$OpType", "org.apache.hadoop.hbase.security.access.AccessController$OpType.valueOf(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.AccessController$OpType.toString()"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.toString()"], ["void", "org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.readFields(java.io.DataInput)"], ["void", "org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.write(java.io.DataOutput)"], ["long", "org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.getWritableSize()"], ["void", "org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.getConf()"], ["org.apache.hadoop.hbase.security.SecurityUtil", "org.apache.hadoop.hbase.security.SecurityUtil()"], ["java.lang.String", "org.apache.hadoop.hbase.security.SecurityUtil.getUserFromPrincipal(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.security.SecurityUtil.getPrincipalWithoutRealm(java.lang.String)"], ["org.apache.hadoop.hbase.security.token.AuthenticationKey", "org.apache.hadoop.hbase.security.token.AuthenticationKey()"], ["org.apache.hadoop.hbase.security.token.AuthenticationKey", "org.apache.hadoop.hbase.security.token.AuthenticationKey(int, long, javax.crypto.SecretKey)"], ["int", "org.apache.hadoop.hbase.security.token.AuthenticationKey.getKeyId()"], ["long", "org.apache.hadoop.hbase.security.token.AuthenticationKey.getExpiration()"], ["void", "org.apache.hadoop.hbase.security.token.AuthenticationKey.setExpiration(long)"], ["int", "org.apache.hadoop.hbase.security.token.AuthenticationKey.hashCode()"], ["boolean", "org.apache.hadoop.hbase.security.token.AuthenticationKey.equals(java.lang.Object)"], ["java.lang.String", "org.apache.hadoop.hbase.security.token.AuthenticationKey.toString()"], ["void", "org.apache.hadoop.hbase.security.token.AuthenticationKey.write(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.security.token.AuthenticationKey.readFields(java.io.DataInput)"], ["boolean", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl$2.evaluate(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode()"], ["org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode(org.apache.hadoop.hbase.security.visibility.expression.Operator)"], ["org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode(org.apache.hadoop.hbase.security.visibility.expression.Operator, java.util.List<org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode>)"], ["org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode(org.apache.hadoop.hbase.security.visibility.expression.Operator, org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode...)"], ["org.apache.hadoop.hbase.security.visibility.expression.Operator", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode.getOperator()"], ["void", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode.addChildExp(org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode)"], ["void", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode.addChildExps(java.util.List<org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode>)"], ["java.lang.String", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode.toString()"], ["boolean", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode.isSingleNode()"], ["org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode.deepClone()"], ["org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode", "org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode.deepClone()"], ["org.apache.hadoop.hbase.security.visibility.VisibilityController$DeleteVersionVisibilityExpressionFilter", "org.apache.hadoop.hbase.security.visibility.VisibilityController$DeleteVersionVisibilityExpressionFilter(java.util.List<org.apache.hadoop.hbase.Tag>, java.lang.Byte)"], ["org.apache.hadoop.hbase.filter.Filter$ReturnCode", "org.apache.hadoop.hbase.security.visibility.VisibilityController$DeleteVersionVisibilityExpressionFilter.filterKeyValue(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.security.visibility.VisibilityController$DeleteVersionVisibilityExpressionFilter.transformCell(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.security.visibility.VisibilityLabelServiceManager", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelServiceManager.getInstance()"], ["org.apache.hadoop.hbase.security.visibility.VisibilityLabelService", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelServiceManager.getVisibilityLabelService(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.security.visibility.VisibilityLabelService", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelServiceManager.getVisibilityLabelService()"], ["org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher", "org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.start()"], ["void", "org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.nodeDeleted(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.nodeDataChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.nodeChildrenChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.writeToZookeeper(byte[], boolean)"], ["org.apache.hadoop.hbase.snapshot.ExportSnapshot$Counter[]", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$Counter.values()"], ["org.apache.hadoop.hbase.snapshot.ExportSnapshot$Counter", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$Counter.valueOf(java.lang.String)"], ["void", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$1.editRegion(org.apache.hadoop.hbase.HRegionInfo)"], ["com.google.common.collect.ListMultimap<java.lang.String, org.apache.hadoop.hbase.security.access.TablePermission>", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils$1.run()"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$2.storeFile(org.apache.hadoop.hbase.HRegionInfo, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile)"], ["org.apache.hadoop.hbase.snapshot.SnapshotManifest", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.errorhandling.ForeignExceptionSnare)"], ["org.apache.hadoop.hbase.snapshot.SnapshotManifest", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.open(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.addTableDescriptor(org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.addRegion(org.apache.hadoop.hbase.regionserver.HRegion)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.addRegion(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.getSnapshotDir()"], ["org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.getSnapshotDescription()"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.getTableDescriptor()"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest>", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.getRegionManifestsMap()"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.consolidate()"], ["java.util.concurrent.ThreadPoolExecutor", "org.apache.hadoop.hbase.snapshot.SnapshotManifest.createExecutor(org.apache.hadoop.conf.Configuration, java.lang.String)"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.SplitLogTask.getServerName()"], ["org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode", "org.apache.hadoop.hbase.SplitLogTask.getMode()"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.isUnassigned(org.apache.hadoop.hbase.ServerName)"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.isUnassigned()"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.isOwned(org.apache.hadoop.hbase.ServerName)"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.isOwned()"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.isResigned(org.apache.hadoop.hbase.ServerName)"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.isResigned()"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.isDone(org.apache.hadoop.hbase.ServerName)"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.isDone()"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.isErr(org.apache.hadoop.hbase.ServerName)"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.isErr()"], ["java.lang.String", "org.apache.hadoop.hbase.SplitLogTask.toString()"], ["boolean", "org.apache.hadoop.hbase.SplitLogTask.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.SplitLogTask.hashCode()"], ["org.apache.hadoop.hbase.SplitLogTask", "org.apache.hadoop.hbase.SplitLogTask.parseFrom(byte[])"], ["byte[]", "org.apache.hadoop.hbase.SplitLogTask.toByteArray()"], ["org.apache.hadoop.hbase.SslRMIServerSocketFactorySecure", "org.apache.hadoop.hbase.SslRMIServerSocketFactorySecure()"], ["java.net.ServerSocket", "org.apache.hadoop.hbase.SslRMIServerSocketFactorySecure.createServerSocket(int)"], ["org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl$ImplData()"], ["void", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl$ImplData.setAssignmentManager(org.apache.hadoop.hbase.master.AssignmentManager)"], ["org.apache.hadoop.hbase.master.AssignmentManager", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl$ImplData.getAssignmentManager()"], ["void", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl$ImplData.setLimit(int)"], ["int", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl$ImplData.getLimit()"], ["boolean", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl$ImplData.getLimit__IsNotDefault()"], ["org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmplImpl", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmplImpl(org.jamon.TemplateManager, org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl$ImplData)"], ["void", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmplImpl.renderNoFlush(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl(org.jamon.TemplateManager)"], ["org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl()"], ["org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.setServers(java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["org.jamon.AbstractTemplateImpl", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.constructImpl(java.lang.Class<? extends org.jamon.AbstractTemplateImpl>)"], ["org.jamon.Renderer", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.makeRenderer(org.apache.hadoop.hbase.master.HMaster)"], ["void", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.render(java.io.Writer, org.apache.hadoop.hbase.master.HMaster)"], ["void", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.renderNoFlush(java.io.Writer, org.apache.hadoop.hbase.master.HMaster)"], ["org.jamon.AbstractTemplateProxy$ImplData", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData.setCacheConfig(org.apache.hadoop.hbase.io.hfile.CacheConfig)"], ["org.apache.hadoop.hbase.io.hfile.CacheConfig", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData.getCacheConfig()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData.getConf()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData.setBcn(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData.getBcn()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData.setBcv(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData.getBcv()"], ["org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl(org.jamon.TemplateManager)"], ["org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl()"], ["org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.getImplData()"], ["org.jamon.AbstractTemplateImpl", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.constructImpl(java.lang.Class<? extends org.jamon.AbstractTemplateImpl>)"], ["org.jamon.Renderer", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.makeRenderer(org.apache.hadoop.hbase.regionserver.HRegionServer, java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.render(java.io.Writer, org.apache.hadoop.hbase.regionserver.HRegionServer, java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.renderNoFlush(java.io.Writer, org.apache.hadoop.hbase.regionserver.HRegionServer, java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["org.jamon.AbstractTemplateProxy$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl$ImplData()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl$ImplData.setMWrap(org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper)"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl$ImplData.getMWrap()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl$ImplData.setMServerWrap(org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapper)"], ["org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapper", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl$ImplData.getMServerWrap()"], ["org.apache.hadoop.hbase.tool.Canary$RegionServerMonitor", "org.apache.hadoop.hbase.tool.Canary$RegionServerMonitor(org.apache.hadoop.hbase.client.Connection, java.lang.String[], boolean, org.apache.hadoop.hbase.tool.Canary$StdOutSink, java.util.concurrent.ExecutorService, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionServerMonitor.run()"], ["org.apache.hadoop.hbase.tool.Canary$ZookeeperTask", "org.apache.hadoop.hbase.tool.Canary$ZookeeperTask(org.apache.hadoop.hbase.client.Connection, java.lang.String, java.lang.String, int, org.apache.hadoop.hbase.tool.Canary$ZookeeperStdOutSink)"], ["java.lang.Void", "org.apache.hadoop.hbase.tool.Canary$ZookeeperTask.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.tool.Canary$ZookeeperTask.call()"], ["org.apache.hadoop.hbase.util.CompoundBloomFilterWriter", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter(int, float, int, int, boolean, org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["boolean", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.shouldWriteBlock(boolean)"], ["void", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.add(byte[], int, int)"], ["void", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.writeInlineBlock(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.blockWritten(long, int, int)"], ["org.apache.hadoop.hbase.io.hfile.BlockType", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.getInlineBlockType()"], ["org.apache.hadoop.io.Writable", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.getMetaWriter()"], ["void", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.compactBloom()"], ["void", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.allocBloom()"], ["org.apache.hadoop.io.Writable", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.getDataWriter()"], ["boolean", "org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.getCacheOnWrite()"], ["org.apache.hadoop.hbase.util.ConnectionCache", "org.apache.hadoop.hbase.util.ConnectionCache(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.security.UserProvider, int, int)"], ["void", "org.apache.hadoop.hbase.util.ConnectionCache.setEffectiveUser(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.util.ConnectionCache.getEffectiveUser()"], ["void", "org.apache.hadoop.hbase.util.ConnectionCache.shutdown()"], ["org.apache.hadoop.hbase.client.Admin", "org.apache.hadoop.hbase.util.ConnectionCache.getAdmin()"], ["org.apache.hadoop.hbase.client.Table", "org.apache.hadoop.hbase.util.ConnectionCache.getTable(java.lang.String)"], ["org.apache.hadoop.hbase.client.RegionLocator", "org.apache.hadoop.hbase.util.ConnectionCache.getRegionLocator(byte[])"], ["boolean", "org.apache.hadoop.hbase.util.ConnectionCache.updateConnectionAccessTime()"], ["org.apache.hadoop.hbase.util.FSTableDescriptors", "org.apache.hadoop.hbase.util.FSTableDescriptors(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.util.FSTableDescriptors", "org.apache.hadoop.hbase.util.FSTableDescriptors(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.util.FSTableDescriptors", "org.apache.hadoop.hbase.util.FSTableDescriptors(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.util.FSTableDescriptors.setCacheOn()"], ["void", "org.apache.hadoop.hbase.util.FSTableDescriptors.setCacheOff()"], ["boolean", "org.apache.hadoop.hbase.util.FSTableDescriptors.isUsecache()"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.util.FSTableDescriptors.get(org.apache.hadoop.hbase.TableName)"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.HTableDescriptor>", "org.apache.hadoop.hbase.util.FSTableDescriptors.getAll()"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.HTableDescriptor>", "org.apache.hadoop.hbase.util.FSTableDescriptors.getByNamespace(java.lang.String)"], ["void", "org.apache.hadoop.hbase.util.FSTableDescriptors.add(org.apache.hadoop.hbase.HTableDescriptor)"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.util.FSTableDescriptors.remove(org.apache.hadoop.hbase.TableName)"], ["boolean", "org.apache.hadoop.hbase.util.FSTableDescriptors.isTableInfoExists(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.fs.FileStatus", "org.apache.hadoop.hbase.util.FSTableDescriptors.getTableInfoPath(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorFromFs(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorFromFs(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.TableName, boolean)"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorFromFs(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorFromFs(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, boolean)"], ["void", "org.apache.hadoop.hbase.util.FSTableDescriptors.deleteTableDescriptorIfExists(org.apache.hadoop.hbase.TableName)"], ["boolean", "org.apache.hadoop.hbase.util.FSTableDescriptors.createTableDescriptor(org.apache.hadoop.hbase.HTableDescriptor)"], ["boolean", "org.apache.hadoop.hbase.util.FSTableDescriptors.createTableDescriptor(org.apache.hadoop.hbase.HTableDescriptor, boolean)"], ["boolean", "org.apache.hadoop.hbase.util.FSTableDescriptors.createTableDescriptorForTableDirectory(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HTableDescriptor, boolean)"], ["org.apache.hadoop.hbase.util.HashedBytes", "org.apache.hadoop.hbase.util.HashedBytes(byte[])"], ["byte[]", "org.apache.hadoop.hbase.util.HashedBytes.getBytes()"], ["int", "org.apache.hadoop.hbase.util.HashedBytes.hashCode()"], ["boolean", "org.apache.hadoop.hbase.util.HashedBytes.equals(java.lang.Object)"], ["java.lang.String", "org.apache.hadoop.hbase.util.HashedBytes.toString()"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck$5.compare(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck$5.compare(java.lang.Object, java.lang.Object)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.int getReplicaId()"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.void addServer(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.java.lang.String toString()"], ["byte[]", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.getStartKey()"], ["byte[]", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.getEndKey()"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.getTableName()"], ["java.lang.String", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.getRegionNameAsString()"], ["byte[]", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.getRegionName()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.getPrimaryHRIForDeployedReplica()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.setSkipChecks(boolean)"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.isSkipChecks()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.setMerged(boolean)"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo.isMerged()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo.addRegionInfo(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo.addServer(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo.getName()"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo.getNumRegions()"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo.checkRegionChain(org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandler)"], ["void", "org.apache.hadoop.hbase.util.hbck.TableLockChecker$1.handleMetadata(byte[])"], ["void", "org.apache.hadoop.hbase.util.JSONBean$1.flush()"], ["void", "org.apache.hadoop.hbase.util.JSONBean$1.close()"], ["void", "org.apache.hadoop.hbase.util.JSONBean$1.write(java.lang.String, java.lang.String)"], ["int", "org.apache.hadoop.hbase.util.JSONBean$1.write(javax.management.MBeanServer, javax.management.ObjectName, java.lang.String, boolean)"], ["org.apache.hadoop.hbase.util.JSONBean", "org.apache.hadoop.hbase.util.JSONBean()"], ["org.apache.hadoop.hbase.util.JSONBean$Writer", "org.apache.hadoop.hbase.util.JSONBean.open(java.io.PrintWriter)"], ["java.lang.String", "org.apache.hadoop.hbase.util.JSONBean.dumpRegionServerMetrics()"], ["void", "org.apache.hadoop.hbase.util.JSONBean.dumpAllBeans()"], ["void", "org.apache.hadoop.hbase.util.JSONBean.main(java.lang.String[])"], ["org.apache.hadoop.hbase.util.ManualEnvironmentEdge", "org.apache.hadoop.hbase.util.ManualEnvironmentEdge()"], ["void", "org.apache.hadoop.hbase.util.ManualEnvironmentEdge.setValue(long)"], ["void", "org.apache.hadoop.hbase.util.ManualEnvironmentEdge.incValue(long)"], ["long", "org.apache.hadoop.hbase.util.ManualEnvironmentEdge.currentTime()"], ["java.lang.Void", "org.apache.hadoop.hbase.util.ModifyRegionUtils$2.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.util.ModifyRegionUtils$2.call()"], ["org.apache.hadoop.hbase.util.MunkresAssignment", "org.apache.hadoop.hbase.util.MunkresAssignment(float[][])"], ["int[]", "org.apache.hadoop.hbase.util.MunkresAssignment.solve()"], ["org.apache.hadoop.hbase.util.ServerRegionReplicaUtil", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.getRegionInfoForFs(org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.isReadOnly(org.apache.hadoop.hbase.regionserver.HRegion)"], ["boolean", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.shouldReplayRecoveredEdits(org.apache.hadoop.hbase.regionserver.HRegion)"], ["org.apache.hadoop.hbase.regionserver.StoreFileInfo", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.getStoreFileInfo(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, java.lang.String, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.setupRegionReplicaReplication(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.isRegionReplicaReplicationEnabled(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.isRegionReplicaWaitForPrimaryFlushEnabled(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.isRegionReplicaStoreFileRefreshEnabled(org.apache.hadoop.conf.Configuration)"], ["double", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.getRegionReplicaStoreFileRefreshMultiplier(org.apache.hadoop.conf.Configuration)"], ["java.lang.String", "org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.getReplicationPeerId()"], ["void", "org.apache.hadoop.hbase.util.ZKDataMigrator$ZKDataMigratorAbortable.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.util.ZKDataMigrator$ZKDataMigratorAbortable.isAborted()"], ["org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL(org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, java.util.List<org.apache.hadoop.hbase.regionserver.wal.WALActionsListener>)"], ["void", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.registerWALActionsListener(org.apache.hadoop.hbase.regionserver.wal.WALActionsListener)"], ["boolean", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.unregisterWALActionsListener(org.apache.hadoop.hbase.regionserver.wal.WALActionsListener)"], ["byte[][]", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.rollWriter()"], ["byte[][]", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.rollWriter(boolean)"], ["void", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.shutdown()"], ["void", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.close()"], ["long", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.append(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit, boolean)"], ["void", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.sync()"], ["void", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.sync(long)"], ["java.lang.Long", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.startCacheFlush(byte[], java.util.Set<byte[]>)"], ["void", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.completeCacheFlush(byte[])"], ["void", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.abortCacheFlush(byte[])"], ["org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.getCoprocessorHost()"], ["long", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.getEarliestMemstoreSeqNum(byte[])"], ["long", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.getEarliestMemstoreSeqNum(byte[], byte[])"], ["java.lang.String", "org.apache.hadoop.hbase.wal.DisabledWALProvider$DisabledWAL.toString()"], ["org.apache.hadoop.hbase.wal.WALFactory$Providers[]", "org.apache.hadoop.hbase.wal.WALFactory$Providers.values()"], ["org.apache.hadoop.hbase.wal.WALFactory$Providers", "org.apache.hadoop.hbase.wal.WALFactory$Providers.valueOf(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.wal.WALSplitter$2.accept(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink", "org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink(org.apache.hadoop.hbase.wal.WALSplitter, org.apache.hadoop.hbase.wal.WALSplitter$PipelineController, org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers, int)"], ["void", "org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.append(org.apache.hadoop.hbase.wal.WALSplitter$RegionEntryBuffer)"], ["boolean", "org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.flush()"], ["boolean", "org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.keepRegionEvent(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["java.util.Map<byte[], java.lang.Long>", "org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.getOutputCounts()"], ["int", "org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.getNumberOfRecoveredRegions()"], ["org.apache.hadoop.hbase.zookeeper.DrainingServerTracker", "org.apache.hadoop.hbase.zookeeper.DrainingServerTracker(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.Abortable, org.apache.hadoop.hbase.master.ServerManager)"], ["void", "org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.start()"], ["void", "org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.nodeDeleted(java.lang.String)"], ["void", "org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.nodeChildrenChanged(java.lang.String)"], ["org.apache.hadoop.hbase.zookeeper.MasterMaintenanceModeTracker", "org.apache.hadoop.hbase.zookeeper.MasterMaintenanceModeTracker(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.MasterMaintenanceModeTracker.isInMaintenanceMode()"], ["void", "org.apache.hadoop.hbase.zookeeper.MasterMaintenanceModeTracker.start()"], ["void", "org.apache.hadoop.hbase.zookeeper.MasterMaintenanceModeTracker.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.zookeeper.MasterMaintenanceModeTracker.nodeDeleted(java.lang.String)"], ["void", "org.apache.hadoop.hbase.zookeeper.MasterMaintenanceModeTracker.nodeChildrenChanged(java.lang.String)"], ["org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker$SwitchStateTracker", "org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker$SwitchStateTracker(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String, org.apache.hadoop.hbase.Abortable)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker$SwitchStateTracker.isSwitchEnabled()"], ["void", "org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker$SwitchStateTracker.setSwitchEnabled(boolean)"], ["void", "org.apache.hadoop.hbase.backup.HFileArchiver.archiveRegion(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.backup.HFileArchiver.archiveRegion(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.backup.HFileArchiver.archiveFamily(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.fs.Path, byte[])"], ["void", "org.apache.hadoop.hbase.backup.HFileArchiver.archiveStoreFiles(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.fs.Path, byte[], java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["void", "org.apache.hadoop.hbase.backup.HFileArchiver.archiveStoreFile(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.fs.Path, byte[], org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.codec.MessageCodec", "org.apache.hadoop.hbase.codec.MessageCodec()"], ["org.apache.hadoop.hbase.codec.Codec$Decoder", "org.apache.hadoop.hbase.codec.MessageCodec.getDecoder(java.io.InputStream)"], ["org.apache.hadoop.hbase.codec.Codec$Encoder", "org.apache.hadoop.hbase.codec.MessageCodec.getEncoder(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.constraint.Constraints.enable(org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.constraint.Constraints.disable(org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.constraint.Constraints.remove(org.apache.hadoop.hbase.HTableDescriptor)"], ["boolean", "org.apache.hadoop.hbase.constraint.Constraints.has(org.apache.hadoop.hbase.HTableDescriptor, java.lang.Class<? extends org.apache.hadoop.hbase.constraint.Constraint>)"], ["void", "org.apache.hadoop.hbase.constraint.Constraints.add(org.apache.hadoop.hbase.HTableDescriptor, java.lang.Class<? extends org.apache.hadoop.hbase.constraint.Constraint>...)"], ["void", "org.apache.hadoop.hbase.constraint.Constraints.add(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.util.Pair<java.lang.Class<? extends org.apache.hadoop.hbase.constraint.Constraint>, org.apache.hadoop.conf.Configuration>...)"], ["void", "org.apache.hadoop.hbase.constraint.Constraints.add(org.apache.hadoop.hbase.HTableDescriptor, java.lang.Class<? extends org.apache.hadoop.hbase.constraint.Constraint>, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.constraint.Constraints.setConfiguration(org.apache.hadoop.hbase.HTableDescriptor, java.lang.Class<? extends org.apache.hadoop.hbase.constraint.Constraint>, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.constraint.Constraints.remove(org.apache.hadoop.hbase.HTableDescriptor, java.lang.Class<? extends org.apache.hadoop.hbase.constraint.Constraint>)"], ["void", "org.apache.hadoop.hbase.constraint.Constraints.enableConstraint(org.apache.hadoop.hbase.HTableDescriptor, java.lang.Class<? extends org.apache.hadoop.hbase.constraint.Constraint>)"], ["void", "org.apache.hadoop.hbase.constraint.Constraints.disableConstraint(org.apache.hadoop.hbase.HTableDescriptor, java.lang.Class<? extends org.apache.hadoop.hbase.constraint.Constraint>)"], ["boolean", "org.apache.hadoop.hbase.constraint.Constraints.enabled(org.apache.hadoop.hbase.HTableDescriptor, java.lang.Class<? extends org.apache.hadoop.hbase.constraint.Constraint>)"], ["org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination$ZkCloseRegionDetails", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination$ZkCloseRegionDetails()"], ["org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination$ZkCloseRegionDetails", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination$ZkCloseRegionDetails(boolean, int)"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination$ZkCloseRegionDetails.isPublishStatusInZk()"], ["void", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination$ZkCloseRegionDetails.setPublishStatusInZk(boolean)"], ["int", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination$ZkCloseRegionDetails.getExpectedVersion()"], ["void", "org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination$ZkCloseRegionDetails.setExpectedVersion(int)"], ["org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager", "org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager()"], ["void", "org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.initialize(org.apache.hadoop.hbase.Server)"], ["org.apache.hadoop.hbase.Server", "org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.getServer()"], ["org.apache.hadoop.hbase.TableStateManager", "org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.getTableStateManager()"], ["org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination", "org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.getSplitLogWorkerCoordination()"], ["org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination", "org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.getSplitLogManagerCoordination()"], ["org.apache.hadoop.hbase.coordination.SplitTransactionCoordination", "org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.getSplitTransactionCoordination()"], ["org.apache.hadoop.hbase.coordination.CloseRegionCoordination", "org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.getCloseRegionCoordination()"], ["org.apache.hadoop.hbase.coordination.OpenRegionCoordination", "org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.getOpenRegionCoordination()"], ["org.apache.hadoop.hbase.coordination.RegionMergeCoordination", "org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.getRegionMergeCoordination()"], ["org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$ZkSplitTaskDetails", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$ZkSplitTaskDetails()"], ["org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$ZkSplitTaskDetails", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$ZkSplitTaskDetails(java.lang.String, org.apache.commons.lang.mutable.MutableInt)"], ["java.lang.String", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$ZkSplitTaskDetails.getTaskNode()"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$ZkSplitTaskDetails.setTaskNode(java.lang.String)"], ["org.apache.commons.lang.mutable.MutableInt", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$ZkSplitTaskDetails.getCurTaskZKVersion()"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$ZkSplitTaskDetails.setCurTaskZKVersion(org.apache.commons.lang.mutable.MutableInt)"], ["java.lang.String", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$ZkSplitTaskDetails.getWALFile()"], ["org.apache.hadoop.hbase.coprocessor.BaseRegionObserver", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver()"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postLogReplay(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preClose(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postClose(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, boolean)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preFlushScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.KeyValueScanner, org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preFlushScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.KeyValueScanner, org.apache.hadoop.hbase.regionserver.InternalScanner, long)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preFlush(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postFlush(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preFlush(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postFlush(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.StoreFile)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], java.util.List<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, com.google.common.collect.ImmutableList<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, com.google.common.collect.ImmutableList<org.apache.hadoop.hbase.regionserver.StoreFile>, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.ScanType)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.ScanType, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, java.util.List<? extends org.apache.hadoop.hbase.regionserver.KeyValueScanner>, org.apache.hadoop.hbase.regionserver.ScanType, long, org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, java.util.List<? extends org.apache.hadoop.hbase.regionserver.KeyValueScanner>, org.apache.hadoop.hbase.regionserver.ScanType, long, org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, java.util.List<? extends org.apache.hadoop.hbase.regionserver.KeyValueScanner>, org.apache.hadoop.hbase.regionserver.ScanType, long, org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest, long)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.StoreFile)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.StoreFile, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preGetClosestRowBefore(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], org.apache.hadoop.hbase.client.Result)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postGetClosestRowBefore(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], org.apache.hadoop.hbase.client.Result)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preGetOp(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Get, java.util.List<org.apache.hadoop.hbase.Cell>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postGetOp(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Get, java.util.List<org.apache.hadoop.hbase.Cell>)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preExists(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Get, boolean)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postExists(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Get, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.prePut(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Put, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postPut(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Put, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preDelete(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Delete, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.prePrepareTimeStampForDeleteVersion(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Mutation, org.apache.hadoop.hbase.Cell, byte[], org.apache.hadoop.hbase.client.Get)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postDelete(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Delete, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preBatchMutate(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postBatchMutate(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress<org.apache.hadoop.hbase.client.Mutation>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postBatchMutateIndispensably(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress<org.apache.hadoop.hbase.client.Mutation>, boolean)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCheckAndPut(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Put, boolean)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCheckAndPutAfterRowLock(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Put, boolean)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postCheckAndPut(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Put, boolean)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCheckAndDelete(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Delete, boolean)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCheckAndDeleteAfterRowLock(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Delete, boolean)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postCheckAndDelete(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Delete, boolean)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preAppend(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Append)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preAppendAfterRowLock(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Append)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postAppend(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Append, org.apache.hadoop.hbase.client.Result)"], ["long", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preIncrementColumnValue(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], long, boolean)"], ["long", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postIncrementColumnValue(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], byte[], byte[], long, boolean, long)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preIncrement(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Increment)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preIncrementAfterRowLock(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Increment)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postIncrement(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Increment, org.apache.hadoop.hbase.client.Result)"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.RegionScanner)"], ["org.apache.hadoop.hbase.regionserver.KeyValueScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preStoreScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.client.Scan, java.util.NavigableSet<byte[]>, org.apache.hadoop.hbase.regionserver.KeyValueScanner)"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.RegionScanner)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preScannerNext(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner, java.util.List<org.apache.hadoop.hbase.client.Result>, int, boolean)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postScannerNext(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner, java.util.List<org.apache.hadoop.hbase.client.Result>, int, boolean)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postScannerFilterRow(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner, byte[], int, short, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preScannerClose(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postScannerClose(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.InternalScanner)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preWALRestore(org.apache.hadoop.hbase.coprocessor.ObserverContext<? extends org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preWALRestore(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.regionserver.wal.HLogKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postWALRestore(org.apache.hadoop.hbase.coprocessor.ObserverContext<? extends org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postWALRestore(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.regionserver.wal.HLogKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preBulkLoadHFile(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.util.Pair<byte[], java.lang.String>>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preCommitStoreFile(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], java.util.List<org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path>>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postCommitStoreFile(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postBulkLoadHFile(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.util.Pair<byte[], java.lang.String>>, boolean)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Reader", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.preStoreFileReaderOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.FSDataInputStreamWrapper, long, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.io.Reference, org.apache.hadoop.hbase.regionserver.StoreFile$Reader)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Reader", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postStoreFileReaderOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.FSDataInputStreamWrapper, long, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.io.Reference, org.apache.hadoop.hbase.regionserver.StoreFile$Reader)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postMutationBeforeWAL(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.coprocessor.RegionObserver$MutationType, org.apache.hadoop.hbase.client.Mutation, org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postStartRegionOperation(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region$Operation)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postCloseRegionOperation(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.Region$Operation)"], ["org.apache.hadoop.hbase.regionserver.DeleteTracker", "org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.postInstantiateDeleteTracker(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.regionserver.DeleteTracker)"], ["org.apache.hadoop.hbase.coprocessor.MetricsCoprocessor", "org.apache.hadoop.hbase.coprocessor.MetricsCoprocessor()"], ["org.apache.hadoop.hbase.metrics.MetricRegistry", "org.apache.hadoop.hbase.coprocessor.MetricsCoprocessor.createRegistryForMasterCoprocessor(java.lang.String)"], ["org.apache.hadoop.hbase.metrics.MetricRegistry", "org.apache.hadoop.hbase.coprocessor.MetricsCoprocessor.createRegistryForRSCoprocessor(java.lang.String)"], ["org.apache.hadoop.hbase.metrics.MetricRegistryInfo", "org.apache.hadoop.hbase.coprocessor.MetricsCoprocessor.createRegistryInfoForRegionCoprocessor(java.lang.String)"], ["org.apache.hadoop.hbase.metrics.MetricRegistry", "org.apache.hadoop.hbase.coprocessor.MetricsCoprocessor.createRegistryForRegionCoprocessor(java.lang.String)"], ["org.apache.hadoop.hbase.metrics.MetricRegistryInfo", "org.apache.hadoop.hbase.coprocessor.MetricsCoprocessor.createRegistryInfoForWALCoprocessor(java.lang.String)"], ["org.apache.hadoop.hbase.metrics.MetricRegistry", "org.apache.hadoop.hbase.coprocessor.MetricsCoprocessor.createRegistryForWALCoprocessor(java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.MetricsCoprocessor.removeRegistry(org.apache.hadoop.hbase.metrics.MetricRegistry)"], ["org.apache.hadoop.hbase.executor.ExecutorService$RunningEventStatus", "org.apache.hadoop.hbase.executor.ExecutorService$RunningEventStatus(java.lang.Thread, org.apache.hadoop.hbase.executor.EventHandler)"], ["int", "org.apache.hadoop.hbase.generated.master.procedures_jsp$1.compare(org.apache.hadoop.hbase.ProcedureInfo, org.apache.hadoop.hbase.ProcedureInfo)"], ["int", "org.apache.hadoop.hbase.generated.master.procedures_jsp$1.compare(java.lang.Object, java.lang.Object)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$5.compare(java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>, java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$5.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.http.jmx.JMXJsonServlet", "org.apache.hadoop.hbase.http.jmx.JMXJsonServlet()"], ["void", "org.apache.hadoop.hbase.http.jmx.JMXJsonServlet.init()"], ["void", "org.apache.hadoop.hbase.http.jmx.JMXJsonServlet.doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.http.SslSocketConnectorSecure", "org.apache.hadoop.hbase.http.SslSocketConnectorSecure()"], ["org.apache.hadoop.hbase.io.HalfStoreFileReader", "org.apache.hadoop.hbase.io.HalfStoreFileReader(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.io.Reference, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.HalfStoreFileReader", "org.apache.hadoop.hbase.io.HalfStoreFileReader(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.FSDataInputStreamWrapper, long, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.io.Reference, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.HFileScanner", "org.apache.hadoop.hbase.io.HalfStoreFileReader.getScanner(boolean, boolean, boolean)"], ["boolean", "org.apache.hadoop.hbase.io.HalfStoreFileReader.passesKeyRangeFilter(org.apache.hadoop.hbase.client.Scan)"], ["byte[]", "org.apache.hadoop.hbase.io.HalfStoreFileReader.getLastKey()"], ["byte[]", "org.apache.hadoop.hbase.io.HalfStoreFileReader.midkey()"], ["byte[]", "org.apache.hadoop.hbase.io.HalfStoreFileReader.getFirstKey()"], ["long", "org.apache.hadoop.hbase.io.HalfStoreFileReader.getEntries()"], ["long", "org.apache.hadoop.hbase.io.HalfStoreFileReader.getFilterEntries()"], ["org.apache.hadoop.hbase.io.hfile.BlockPriority[]", "org.apache.hadoop.hbase.io.hfile.BlockPriority.values()"], ["org.apache.hadoop.hbase.io.hfile.BlockPriority", "org.apache.hadoop.hbase.io.hfile.BlockPriority.valueOf(java.lang.String)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$1.compare(java.lang.Integer, java.lang.Integer)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$1.compare(java.lang.Object, java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2.hasNext()"], ["org.apache.hadoop.hbase.io.hfile.CachedBlock", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2.next()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2.remove()"], ["java.lang.Object", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2.next()"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$RAMQueueEntry", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$RAMQueueEntry(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable, long, boolean)"], ["org.apache.hadoop.hbase.io.hfile.Cacheable", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$RAMQueueEntry.getData()"], ["org.apache.hadoop.hbase.io.hfile.BlockCacheKey", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$RAMQueueEntry.getKey()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$RAMQueueEntry.access(long)"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$RAMQueueEntry.writeToCache(org.apache.hadoop.hbase.io.hfile.bucket.IOEngine, org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator, org.apache.hadoop.hbase.io.hfile.bucket.UniqueIndexMap<java.lang.Integer>, java.util.concurrent.atomic.AtomicLong)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.CacheFullException.bucketIndex()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.CacheFullException.requestedSize()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.bucket.CacheFullException.toString()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock", "org.apache.hadoop.hbase.io.hfile.HFileBlock$1.deserialize(java.nio.ByteBuffer, boolean)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlock$1.getDeserialiserIdentifier()"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock", "org.apache.hadoop.hbase.io.hfile.HFileBlock$1.deserialize(java.nio.ByteBuffer)"], ["org.apache.hadoop.hbase.io.hfile.Cacheable", "org.apache.hadoop.hbase.io.hfile.HFileBlock$1.deserialize(java.nio.ByteBuffer, boolean)"], ["org.apache.hadoop.hbase.io.hfile.Cacheable", "org.apache.hadoop.hbase.io.hfile.HFileBlock$1.deserialize(java.nio.ByteBuffer)"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl", "org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl(org.apache.hadoop.hbase.io.FSDataInputStreamWrapper, long, org.apache.hadoop.hbase.fs.HFileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock", "org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.readBlockData(long, long, boolean, boolean)"], ["org.apache.hadoop.hbase.io.encoding.HFileBlockDecodingContext", "org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.getBlockDecodingContext()"], ["org.apache.hadoop.hbase.io.encoding.HFileBlockDecodingContext", "org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.getDefaultBlockDecodingContext()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.closeStreams()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.unbufferStream()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.toString()"], ["org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter()"], ["org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.setPrintStreams(java.io.PrintStream, java.io.PrintStream)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.parseOptions(java.lang.String[])"], ["int", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.run(java.lang.String[])"], ["int", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.processFile(org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.main(java.lang.String[])"], ["org.apache.hadoop.hbase.io.hfile.LruBlockCache", "org.apache.hadoop.hbase.io.hfile.LruBlockCache(long, long)"], ["org.apache.hadoop.hbase.io.hfile.LruBlockCache", "org.apache.hadoop.hbase.io.hfile.LruBlockCache(long, long, boolean)"], ["org.apache.hadoop.hbase.io.hfile.LruBlockCache", "org.apache.hadoop.hbase.io.hfile.LruBlockCache(long, long, boolean, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.LruBlockCache", "org.apache.hadoop.hbase.io.hfile.LruBlockCache(long, long, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.LruBlockCache", "org.apache.hadoop.hbase.io.hfile.LruBlockCache(long, long, boolean, int, float, int, float, float, float, float, float, float, boolean, long)"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.setMaxSize(long)"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.cacheBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.cacheBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.Cacheable)"], ["org.apache.hadoop.hbase.io.hfile.Cacheable", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.getBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey, boolean, boolean, boolean)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.containsBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.evictBlock(org.apache.hadoop.hbase.io.hfile.BlockCacheKey)"], ["int", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.evictBlocksByHfileName(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.toString()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.getMaxSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.getCurrentSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.getCurrentDataSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.getFreeSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.size()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.getBlockCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.getDataBlockCount()"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.logStats()"], ["org.apache.hadoop.hbase.io.hfile.CacheStats", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.getStats()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.heapSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.calculateOverhead(long, long, int)"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.shutdown()"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.clearCache()"], ["java.util.Map<org.apache.hadoop.hbase.io.encoding.DataBlockEncoding, java.lang.Integer>", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.getEncodingCountsForTest()"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.setVictimCache(org.apache.hadoop.hbase.io.hfile.BlockCache)"], ["org.apache.hadoop.hbase.io.hfile.BlockCache[]", "org.apache.hadoop.hbase.io.hfile.LruBlockCache.getBlockCaches()"], ["org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue(int, int, int, double, java.util.concurrent.atomic.AtomicLong, java.util.concurrent.atomic.AtomicLong)"], ["void", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.updateTunables(int, int, double)"], ["org.apache.hadoop.hbase.ipc.CallRunner", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.take()"], ["org.apache.hadoop.hbase.ipc.CallRunner", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.poll()"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.offer(org.apache.hadoop.hbase.ipc.CallRunner)"], ["int", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.size()"], ["java.lang.String", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.toString()"], ["org.apache.hadoop.hbase.ipc.CallRunner", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.poll(long, java.util.concurrent.TimeUnit)"], ["org.apache.hadoop.hbase.ipc.CallRunner", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.peek()"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.remove(java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.contains(java.lang.Object)"], ["java.lang.Object[]", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.toArray()"], ["<T> T[]", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.toArray(T[])"], ["void", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.clear()"], ["int", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.drainTo(java.util.Collection<? super org.apache.hadoop.hbase.ipc.CallRunner>)"], ["int", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.drainTo(java.util.Collection<? super org.apache.hadoop.hbase.ipc.CallRunner>, int)"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.add(org.apache.hadoop.hbase.ipc.CallRunner)"], ["org.apache.hadoop.hbase.ipc.CallRunner", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.remove()"], ["org.apache.hadoop.hbase.ipc.CallRunner", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.element()"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.addAll(java.util.Collection<? extends org.apache.hadoop.hbase.ipc.CallRunner>)"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.isEmpty()"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.containsAll(java.util.Collection<?>)"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.removeAll(java.util.Collection<?>)"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.retainAll(java.util.Collection<?>)"], ["int", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.remainingCapacity()"], ["void", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.put(org.apache.hadoop.hbase.ipc.CallRunner)"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.offer(org.apache.hadoop.hbase.ipc.CallRunner, long, java.util.concurrent.TimeUnit)"], ["java.lang.Object", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.poll(long, java.util.concurrent.TimeUnit)"], ["java.lang.Object", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.take()"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.offer(java.lang.Object, long, java.util.concurrent.TimeUnit)"], ["void", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.put(java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.offer(java.lang.Object)"], ["boolean", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.add(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.peek()"], ["java.lang.Object", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.element()"], ["java.lang.Object", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.poll()"], ["java.lang.Object", "org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.remove()"], ["org.apache.hadoop.hbase.ipc.FifoRpcScheduler", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler(org.apache.hadoop.conf.Configuration, int)"], ["void", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.init(org.apache.hadoop.hbase.ipc.RpcScheduler$Context)"], ["void", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.start()"], ["void", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.stop()"], ["boolean", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.dispatch(org.apache.hadoop.hbase.ipc.CallRunner)"], ["int", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getGeneralQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getPriorityQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getReplicationQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getActiveRpcHandlerCount()"], ["long", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getNumGeneralCallsDropped()"], ["long", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getNumLifoModeSwitches()"], ["int", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getWriteQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getReadQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getScanQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getActiveWriteRpcHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getActiveReadRpcHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.FifoRpcScheduler.getActiveScanRpcHandlerCount()"], ["org.apache.hadoop.hbase.ipc.RpcExecutor$CallPriorityComparator", "org.apache.hadoop.hbase.ipc.RpcExecutor$CallPriorityComparator(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.ipc.PriorityFunction)"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor$CallPriorityComparator.compare(org.apache.hadoop.hbase.ipc.CallRunner, org.apache.hadoop.hbase.ipc.CallRunner)"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor$CallPriorityComparator.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.ipc.RpcServer$Connection", "org.apache.hadoop.hbase.ipc.RpcServer$Connection(org.apache.hadoop.hbase.ipc.RpcServer, java.nio.channels.SocketChannel, long)"], ["java.lang.String", "org.apache.hadoop.hbase.ipc.RpcServer$Connection.toString()"], ["java.lang.String", "org.apache.hadoop.hbase.ipc.RpcServer$Connection.getHostAddress()"], ["java.net.InetAddress", "org.apache.hadoop.hbase.ipc.RpcServer$Connection.getHostInetAddress()"], ["int", "org.apache.hadoop.hbase.ipc.RpcServer$Connection.getRemotePort()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer$Connection.setLastContact(long)"], ["org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$VersionInfo", "org.apache.hadoop.hbase.ipc.RpcServer$Connection.getVersionInfo()"], ["int", "org.apache.hadoop.hbase.ipc.RpcServer$Connection.readAndProcess()"], ["org.apache.hadoop.hbase.mapred.RowCounter$RowCounterMapper$Counters[]", "org.apache.hadoop.hbase.mapred.RowCounter$RowCounterMapper$Counters.values()"], ["org.apache.hadoop.hbase.mapred.RowCounter$RowCounterMapper$Counters", "org.apache.hadoop.hbase.mapred.RowCounter$RowCounterMapper$Counters.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter", "org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter(org.apache.hadoop.hbase.client.BufferedMutator)"], ["org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter", "org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter(org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter.close(org.apache.hadoop.mapred.Reporter)"], ["void", "org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter.write(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Put)"], ["void", "org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter.write(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.mapred.TableRecordReader", "org.apache.hadoop.hbase.mapred.TableRecordReader()"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReader.restart(byte[])"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReader.init()"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReader.setHTable(org.apache.hadoop.hbase.client.Table)"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReader.setInputColumns(byte[][])"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReader.setStartRow(byte[])"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReader.setEndRow(byte[])"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReader.setRowFilter(org.apache.hadoop.hbase.filter.Filter)"], ["void", "org.apache.hadoop.hbase.mapred.TableRecordReader.close()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapred.TableRecordReader.createKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapred.TableRecordReader.createValue()"], ["long", "org.apache.hadoop.hbase.mapred.TableRecordReader.getPos()"], ["float", "org.apache.hadoop.hbase.mapred.TableRecordReader.getProgress()"], ["boolean", "org.apache.hadoop.hbase.mapred.TableRecordReader.next(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapred.TableRecordReader.createValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapred.TableRecordReader.createKey()"], ["boolean", "org.apache.hadoop.hbase.mapred.TableRecordReader.next(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.CellCounter$CellCounterMapper$Counters[]", "org.apache.hadoop.hbase.mapreduce.CellCounter$CellCounterMapper$Counters.values()"], ["org.apache.hadoop.hbase.mapreduce.CellCounter$CellCounterMapper$Counters", "org.apache.hadoop.hbase.mapreduce.CellCounter$CellCounterMapper$Counters.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver", "org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver.getConf()"], ["void", "org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver.setConf(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver.init()"], ["org.apache.hadoop.hbase.mapreduce.HashTable$ResultHasher", "org.apache.hadoop.hbase.mapreduce.HashTable$ResultHasher()"], ["void", "org.apache.hadoop.hbase.mapreduce.HashTable$ResultHasher.startBatch(org.apache.hadoop.hbase.io.ImmutableBytesWritable)"], ["void", "org.apache.hadoop.hbase.mapreduce.HashTable$ResultHasher.hashResult(org.apache.hadoop.hbase.client.Result)"], ["void", "org.apache.hadoop.hbase.mapreduce.HashTable$ResultHasher.finishBatch()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.HashTable$ResultHasher.isBatchStarted()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.HashTable$ResultHasher.getBatchStartKey()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.HashTable$ResultHasher.getBatchHash()"], ["long", "org.apache.hadoop.hbase.mapreduce.HashTable$ResultHasher.getBatchSize()"], ["org.apache.hadoop.hbase.mapreduce.HashTable", "org.apache.hadoop.hbase.mapreduce.HashTable(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.mapreduce.Job", "org.apache.hadoop.hbase.mapreduce.HashTable.createSubmittableJob(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.HashTable.main(java.lang.String[])"], ["int", "org.apache.hadoop.hbase.mapreduce.HashTable.run(java.lang.String[])"], ["org.apache.hadoop.hbase.mapreduce.IdentityTableMapper", "org.apache.hadoop.hbase.mapreduce.IdentityTableMapper()"], ["void", "org.apache.hadoop.hbase.mapreduce.IdentityTableMapper.initJob(java.lang.String, org.apache.hadoop.hbase.client.Scan, java.lang.Class<? extends org.apache.hadoop.hbase.mapreduce.TableMapper>, org.apache.hadoop.mapreduce.Job)"], ["void", "org.apache.hadoop.hbase.mapreduce.IdentityTableMapper.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.IdentityTableMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["org.apache.hadoop.hbase.mapreduce.Import$KeyValueImporter", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueImporter()"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueImporter.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.KeyValue>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueImporter.setup(org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.KeyValue>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueImporter.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueDeserializer", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueDeserializer()"], ["void", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueDeserializer.close()"], ["org.apache.hadoop.hbase.KeyValue", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueDeserializer.deserialize(org.apache.hadoop.hbase.KeyValue)"], ["void", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueDeserializer.open(java.io.InputStream)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueDeserializer.deserialize(java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueSerializer", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueSerializer()"], ["void", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueSerializer.close()"], ["void", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueSerializer.open(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueSerializer.serialize(org.apache.hadoop.hbase.KeyValue)"], ["void", "org.apache.hadoop.hbase.mapreduce.KeyValueSerialization$KeyValueSerializer.serialize(java.lang.Object)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase$1.close()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase$1.getCurrentKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase$1.getCurrentValue()"], ["float", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase$1.getProgress()"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase$1.initialize(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase$1.nextKeyValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase$1.getCurrentValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase$1.getCurrentKey()"], ["org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat$MultiTableRecordWriter", "org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat$MultiTableRecordWriter(org.apache.hadoop.conf.Configuration, boolean)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat$MultiTableRecordWriter.close(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat$MultiTableRecordWriter.write(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Mutation)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat$MultiTableRecordWriter.write(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.MutationSerialization", "org.apache.hadoop.hbase.mapreduce.MutationSerialization()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.MutationSerialization.accept(java.lang.Class<?>)"], ["org.apache.hadoop.hbase.mapreduce.SyncTable$SyncMapper$CellScanner", "org.apache.hadoop.hbase.mapreduce.SyncTable$SyncMapper$CellScanner(java.util.Iterator<org.apache.hadoop.hbase.client.Result>)"], ["byte[]", "org.apache.hadoop.hbase.mapreduce.SyncTable$SyncMapper$CellScanner.nextRow()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.mapreduce.SyncTable$SyncMapper$CellScanner.nextCellInRow()"], ["org.apache.hadoop.hbase.mapreduce.TableMapper", "org.apache.hadoop.hbase.mapreduce.TableMapper()"], ["org.apache.hadoop.hbase.mapreduce.TableRecordReader", "org.apache.hadoop.hbase.mapreduce.TableRecordReader()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.restart(byte[])"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.setHTable(org.apache.hadoop.hbase.client.Table)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.setTable(org.apache.hadoop.hbase.client.Table)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.setScan(org.apache.hadoop.hbase.client.Scan)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.close()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.getCurrentKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.getCurrentValue()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.initialize(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.nextKeyValue()"], ["float", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.getProgress()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.getCurrentValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.TableRecordReader.getCurrentKey()"], ["org.apache.hadoop.hbase.mapreduce.TableSplit$Version[]", "org.apache.hadoop.hbase.mapreduce.TableSplit$Version.values()"], ["org.apache.hadoop.hbase.mapreduce.TableSplit$Version", "org.apache.hadoop.hbase.mapreduce.TableSplit$Version.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper", "org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper()"], ["boolean", "org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper.getSkipBadLines()"], ["org.apache.hadoop.mapreduce.Counter", "org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper.getBadLineCount()"], ["void", "org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper.incrementBadLineCount(int)"], ["void", "org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper.map(org.apache.hadoop.io.LongWritable, org.apache.hadoop.io.Text, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.io.LongWritable, org.apache.hadoop.io.Text, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.io.Text>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["org.apache.hadoop.hbase.mapreduce.WALInputFormat", "org.apache.hadoop.hbase.mapreduce.WALInputFormat()"], ["org.apache.hadoop.mapreduce.RecordReader<org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit>", "org.apache.hadoop.hbase.mapreduce.WALInputFormat.createRecordReader(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["java.lang.Object", "org.apache.hadoop.hbase.master.AssignmentManager$12.call()"], ["java.lang.String", "org.apache.hadoop.hbase.master.AssignmentManager$7.getRegionName()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$7.run()"], ["org.apache.hadoop.hbase.master.AssignmentVerificationReport", "org.apache.hadoop.hbase.master.AssignmentVerificationReport()"], ["void", "org.apache.hadoop.hbase.master.AssignmentVerificationReport.fillUp(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta, java.util.Map<java.lang.String, java.util.Map<java.lang.String, java.lang.Float>>)"], ["void", "org.apache.hadoop.hbase.master.AssignmentVerificationReport.fillUpDispersion(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta, org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan)"], ["void", "org.apache.hadoop.hbase.master.AssignmentVerificationReport.print(boolean)"], ["org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper", "org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper(java.util.List<org.apache.hadoop.hbase.ServerName>, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper", "org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper(java.util.List<org.apache.hadoop.hbase.ServerName>, org.apache.hadoop.hbase.master.RackManager)"], ["void", "org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.updateMetaWithFavoredNodesInfo(java.util.Map<org.apache.hadoop.hbase.HRegionInfo, java.util.List<org.apache.hadoop.hbase.ServerName>>, org.apache.hadoop.hbase.client.Connection)"], ["void", "org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.updateMetaWithFavoredNodesInfo(java.util.Map<org.apache.hadoop.hbase.HRegionInfo, java.util.List<org.apache.hadoop.hbase.ServerName>>, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.ServerName[]", "org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.getFavoredNodesList(byte[])"], ["byte[]", "org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.getFavoredNodes(java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["java.util.Map<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName[]>", "org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.placeSecondaryAndTertiaryWithRestrictions(java.util.Map<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName>)"], ["void", "org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.initialize()"], ["java.lang.String", "org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.getFavoredNodesAsString(java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["org.apache.hadoop.hbase.master.BulkAssigner", "org.apache.hadoop.hbase.master.BulkAssigner(org.apache.hadoop.hbase.Server)"], ["boolean", "org.apache.hadoop.hbase.master.BulkAssigner.bulkAssign()"], ["boolean", "org.apache.hadoop.hbase.master.BulkAssigner.bulkAssign(boolean)"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.CleanerChore$CleanerTask$2.accept(org.apache.hadoop.fs.FileStatus)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.master.cleaner.CleanerChore$CleanerTask$4.act()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.cleaner.CleanerChore$CleanerTask$4.act()"], ["org.apache.hadoop.hbase.master.cleaner.HFileCleaner", "org.apache.hadoop.hbase.master.cleaner.HFileCleaner(int, org.apache.hadoop.hbase.Stoppable, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner$ReplicationQueueDeletor", "org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner$ReplicationQueueDeletor(org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["void", "org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner$ReplicationQueueDeletor.removeQueue(java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner$ReplicationQueueDeletor.removeHFileRefsQueue(java.lang.String)"], ["org.apache.hadoop.hbase.master.handler.CreateTableHandler", "org.apache.hadoop.hbase.master.handler.CreateTableHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.master.MasterFileSystem, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HRegionInfo[], org.apache.hadoop.hbase.master.MasterServices)"], ["org.apache.hadoop.hbase.master.handler.CreateTableHandler", "org.apache.hadoop.hbase.master.handler.CreateTableHandler.prepare()"], ["java.lang.String", "org.apache.hadoop.hbase.master.handler.CreateTableHandler.toString()"], ["void", "org.apache.hadoop.hbase.master.handler.CreateTableHandler.process()"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.master.handler.CreateTableHandler.prepare()"], ["boolean", "org.apache.hadoop.hbase.master.HMaster$10.processRow(org.apache.hadoop.hbase.client.Result)"], ["org.apache.hadoop.hbase.master.HMaster$RedirectServlet", "org.apache.hadoop.hbase.master.HMaster$RedirectServlet(org.apache.hadoop.hbase.http.InfoServer, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.HMaster$RedirectServlet.doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$11.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$16.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$22.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$3.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$37.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$44.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$56.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$60.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$72.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$74.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$80.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$93.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$CoprocessorOperationWithResult.setResult(T)"], ["T", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$CoprocessorOperationWithResult.getResult()"], ["org.apache.hadoop.hbase.master.MasterCoprocessorHost", "org.apache.hadoop.hbase.master.MasterCoprocessorHost(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.master.MasterCoprocessorHost$MasterEnvironment", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.createEnvironment(java.lang.Class<?>, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preCreateNamespace(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postCreateNamespace(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preDeleteNamespace(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postDeleteNamespace(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preModifyNamespace(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postModifyNamespace(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preGetNamespaceDescriptor(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postGetNamespaceDescriptor(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preListNamespaceDescriptors(java.util.List<org.apache.hadoop.hbase.NamespaceDescriptor>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postListNamespaceDescriptors(java.util.List<org.apache.hadoop.hbase.NamespaceDescriptor>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preCreateTable(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postCreateTable(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preCreateTableHandler(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postCreateTableHandler(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preDeleteTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postDeleteTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preDeleteTableHandler(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postDeleteTableHandler(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preTruncateTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postTruncateTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preTruncateTableHandler(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postTruncateTableHandler(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preModifyTable(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postModifyTable(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preModifyTableHandler(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postModifyTableHandler(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preAddColumn(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postAddColumn(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preAddColumnHandler(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postAddColumnHandler(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preModifyColumn(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postModifyColumn(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preModifyColumnHandler(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postModifyColumnHandler(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preDeleteColumn(org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postDeleteColumn(org.apache.hadoop.hbase.TableName, byte[])"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preDeleteColumnHandler(org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postDeleteColumnHandler(org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preEnableTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postEnableTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preEnableTableHandler(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postEnableTableHandler(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preDisableTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postDisableTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preDisableTableHandler(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postDisableTableHandler(org.apache.hadoop.hbase.TableName)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preAbortProcedure(org.apache.hadoop.hbase.procedure2.ProcedureExecutor<org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv>, long)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postAbortProcedure()"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preListProcedures()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postListProcedures(java.util.List<org.apache.hadoop.hbase.ProcedureInfo>)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preMove(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postMove(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerName)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preAssign(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postAssign(org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preUnassign(org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postUnassign(org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preRegionOffline(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postRegionOffline(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preDispatchMerge(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postDispatchMerge(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preBalance()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postBalance(java.util.List<org.apache.hadoop.hbase.master.RegionPlan>)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preSetSplitOrMergeEnabled(boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postSetSplitOrMergeEnabled(boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preBalanceSwitch(boolean)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postBalanceSwitch(boolean, boolean)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preShutdown()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preStopMaster()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preMasterInitialization()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postStartMaster()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preListSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postListSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preCloneSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postCloneSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preRestoreSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postRestoreSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preDeleteSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postDeleteSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preGetTableDescriptors(java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postGetTableDescriptors(java.util.List<org.apache.hadoop.hbase.HTableDescriptor>)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preGetTableDescriptors(java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postGetTableDescriptors(java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preGetTableNames(java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postGetTableNames(java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preTableFlush(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postTableFlush(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preSetUserQuota(java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postSetUserQuota(java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preSetUserQuota(java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postSetUserQuota(java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preSetUserQuota(java.lang.String, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postSetUserQuota(java.lang.String, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preSetTableQuota(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postSetTableQuota(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preSetNamespaceQuota(java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postSetNamespaceQuota(java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preGetClusterStatus()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postGetClusterStatus(org.apache.hadoop.hbase.ClusterStatus)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preClearDeadServers()"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postClearDeadServers(java.util.List<org.apache.hadoop.hbase.ServerName>, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preMoveServers(java.util.Set<org.apache.hadoop.hbase.net.Address>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postMoveServers(java.util.Set<org.apache.hadoop.hbase.net.Address>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preMoveTables(java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postMoveTables(java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preMoveServersAndTables(java.util.Set<org.apache.hadoop.hbase.net.Address>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postMoveServersAndTables(java.util.Set<org.apache.hadoop.hbase.net.Address>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preRemoveServers(java.util.Set<org.apache.hadoop.hbase.net.Address>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postRemoveServers(java.util.Set<org.apache.hadoop.hbase.net.Address>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preAddRSGroup(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postAddRSGroup(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preRemoveRSGroup(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postRemoveRSGroup(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.preBalanceRSGroup(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.postBalanceRSGroup(java.lang.String, boolean)"], ["org.apache.hadoop.hbase.CoprocessorEnvironment", "org.apache.hadoop.hbase.master.MasterCoprocessorHost.createEnvironment(java.lang.Class, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.master.normalizer.EmptyNormalizationPlan", "org.apache.hadoop.hbase.master.normalizer.EmptyNormalizationPlan.getInstance()"], ["void", "org.apache.hadoop.hbase.master.normalizer.EmptyNormalizationPlan.execute(org.apache.hadoop.hbase.client.Admin)"], ["org.apache.hadoop.hbase.master.normalizer.NormalizationPlan$PlanType", "org.apache.hadoop.hbase.master.normalizer.EmptyNormalizationPlan.getType()"], ["org.apache.hadoop.hbase.master.normalizer.MergeNormalizationPlan", "org.apache.hadoop.hbase.master.normalizer.MergeNormalizationPlan(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.master.normalizer.NormalizationPlan$PlanType", "org.apache.hadoop.hbase.master.normalizer.MergeNormalizationPlan.getType()"], ["java.lang.String", "org.apache.hadoop.hbase.master.normalizer.MergeNormalizationPlan.toString()"], ["void", "org.apache.hadoop.hbase.master.normalizer.MergeNormalizationPlan.execute(org.apache.hadoop.hbase.client.Admin)"], ["org.apache.hadoop.hbase.master.procedure.CreateTableProcedure", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure()"], ["org.apache.hadoop.hbase.master.procedure.CreateTableProcedure", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["org.apache.hadoop.hbase.master.procedure.CreateTableProcedure", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[], org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["void", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.deserializeStateData(java.io.InputStream)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.abort(java.lang.Object)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue(org.apache.hadoop.hbase.ServerName)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.requireExclusiveLock(org.apache.hadoop.hbase.procedure2.Procedure)"], ["int", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.size()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.isEmpty()"], ["org.apache.hadoop.hbase.procedure2.Procedure", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.poll()"], ["org.apache.hadoop.hbase.procedure2.Procedure", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.peek()"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.add(org.apache.hadoop.hbase.procedure2.Procedure, boolean)"], ["java.lang.String", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.toString()"], ["int", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.compareTo(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.isAvailable()"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.releaseExclusiveLock()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.tryExclusiveLock(long)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.releaseSharedLock()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.trySharedLock()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.hasExclusiveLock()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.isLocked()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ServerQueue.isSuspended()"], ["org.apache.hadoop.hbase.protobuf.generated.RPCProtos$UserInformation", "org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil.toProtoUserInfo(org.apache.hadoop.security.UserGroupInformation)"], ["org.apache.hadoop.security.UserGroupInformation", "org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil.toUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos$UserInformation)"], ["long", "org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil.submitProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil$NonceProcedureRunnable)"], ["void", "org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch$CompatibilityLatch.await()"], ["org.apache.hadoop.hbase.quotas.MasterQuotaManager", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait$4.evaluate()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait$4.evaluate()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType[]", "org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType.values()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.master.RegionPlacementMaintainer", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.master.RegionPlacementMaintainer", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer(org.apache.hadoop.conf.Configuration, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.setTargetTableName(java.lang.String[])"], ["org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.getRegionAssignmentSnapshot()"], ["org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.getNewAssignmentPlan()"], ["void", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.printAssignmentPlan(org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan)"], ["void", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.updateAssignmentPlanToMeta(org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan)"], ["void", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.updateAssignmentPlan(org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan)"], ["java.util.Map<org.apache.hadoop.hbase.TableName, java.lang.Integer>", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.getRegionsMovement(org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan)"], ["void", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.checkDifferencesWithOldPlan(java.util.Map<org.apache.hadoop.hbase.TableName, java.lang.Integer>, java.util.Map<java.lang.String, java.util.Map<java.lang.String, java.lang.Float>>, org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan)"], ["void", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.printDispersionScores(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta, int, org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan, boolean)"], ["void", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.printLocalityAndDispersionForCurrentPlan(java.util.Map<java.lang.String, java.util.Map<java.lang.String, java.lang.Float>>)"], ["void", "org.apache.hadoop.hbase.master.RegionPlacementMaintainer.main(java.lang.String[])"], ["org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier", "org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.verifySnapshot(org.apache.hadoop.fs.Path, java.util.Set<java.lang.String>)"], ["org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta", "org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta(org.apache.hadoop.hbase.client.Connection)"], ["org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta", "org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta(org.apache.hadoop.hbase.client.Connection, java.util.Set<org.apache.hadoop.hbase.TableName>, boolean)"], ["void", "org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.initialize()"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.HRegionInfo>", "org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.getRegionNameToRegionInfoMap()"], ["java.util.Map<org.apache.hadoop.hbase.TableName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>>", "org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.getTableToRegionMap()"], ["java.util.Map<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName>", "org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.getRegionToRegionServerMap()"], ["java.util.Map<org.apache.hadoop.hbase.ServerName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>>", "org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.getRegionServerToRegionMap()"], ["org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan", "org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.getExistingAssignmentPlan()"], ["org.apache.hadoop.hbase.MetaMigrationConvertingToPB$ConvertToPBMetaVisitor", "org.apache.hadoop.hbase.MetaMigrationConvertingToPB$ConvertToPBMetaVisitor(org.apache.hadoop.hbase.master.MasterServices)"], ["boolean", "org.apache.hadoop.hbase.MetaMigrationConvertingToPB$ConvertToPBMetaVisitor.visit(org.apache.hadoop.hbase.client.Result)"], ["boolean", "org.apache.hadoop.hbase.migration.NamespaceUpgrade$1.accept(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer$LogMessage", "org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer$LogMessage(java.lang.String, long)"], ["long", "org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer$LogMessage.estimateHeapUsage()"], ["org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl()"], ["synchronized", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl clone()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.getStartTime()"], ["java.lang.String", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.getDescription()"], ["java.lang.String", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.getStatus()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.getStatusTime()"], ["org.apache.hadoop.hbase.monitoring.MonitoredTask$State", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.getState()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.getStateTime()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.getWarnTime()"], ["long", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.getCompletionTimestamp()"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.markComplete(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.pause(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.resume(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.abort(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.setStatus(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.setDescription(java.lang.String)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.setWarnTime(long)"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.cleanup()"], ["void", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.expireNow()"], ["java.util.Map<java.lang.String, java.lang.Object>", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.toMap()"], ["java.lang.String", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.toJSON()"], ["java.lang.String", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.toString()"], ["java.lang.Object", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.clone()"], ["org.apache.hadoop.hbase.monitoring.MonitoredTask", "org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.clone()"], ["org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure", "org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure(org.apache.hadoop.hbase.procedure.ProcedureMember, org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher, long, long, java.util.List<org.apache.hadoop.hbase.regionserver.Region>, java.lang.String, org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager$FlushTableSubprocedurePool)"], ["void", "org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.acquireBarrier()"], ["byte[]", "org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.insideBarrier()"], ["void", "org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.cleanup(java.lang.Exception)"], ["void", "org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.releaseBarrier()"], ["org.apache.hadoop.hbase.procedure.ProcedureMember", "org.apache.hadoop.hbase.procedure.ProcedureMember(org.apache.hadoop.hbase.procedure.ProcedureMemberRpcs, java.util.concurrent.ThreadPoolExecutor, org.apache.hadoop.hbase.procedure.SubprocedureFactory)"], ["java.util.concurrent.ThreadPoolExecutor", "org.apache.hadoop.hbase.procedure.ProcedureMember.defaultPool(java.lang.String, int)"], ["java.util.concurrent.ThreadPoolExecutor", "org.apache.hadoop.hbase.procedure.ProcedureMember.defaultPool(java.lang.String, int, long)"], ["org.apache.hadoop.hbase.procedure.Subprocedure", "org.apache.hadoop.hbase.procedure.ProcedureMember.createSubprocedure(java.lang.String, byte[])"], ["boolean", "org.apache.hadoop.hbase.procedure.ProcedureMember.submitSubprocedure(org.apache.hadoop.hbase.procedure.Subprocedure)"], ["void", "org.apache.hadoop.hbase.procedure.ProcedureMember.receivedReachedGlobalBarrier(java.lang.String)"], ["void", "org.apache.hadoop.hbase.procedure.ProcedureMember.close()"], ["void", "org.apache.hadoop.hbase.procedure.ProcedureMember.controllerConnectionFailure(java.lang.String, java.lang.Throwable, java.lang.String)"], ["void", "org.apache.hadoop.hbase.procedure.ProcedureMember.receiveAbortProcedure(java.lang.String, org.apache.hadoop.hbase.errorhandling.ForeignException)"], ["org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs", "org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.sendGlobalBarrierAcquire(org.apache.hadoop.hbase.procedure.Procedure, byte[], java.util.List<java.lang.String>)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.sendGlobalBarrierReached(org.apache.hadoop.hbase.procedure.Procedure, java.util.List<java.lang.String>)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.resetMembers(org.apache.hadoop.hbase.procedure.Procedure)"], ["boolean", "org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.start(org.apache.hadoop.hbase.procedure.ProcedureCoordinator)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.sendAbortToMembers(org.apache.hadoop.hbase.procedure.Procedure, org.apache.hadoop.hbase.errorhandling.ForeignException)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.close()"], ["org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$1.fetch()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$1.update(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$1.delete()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$1.preApply(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$1.postApply(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["org.apache.hadoop.hbase.client.Get", "org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore$2.makeGet(java.util.Map$Entry<org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.quotas.QuotaState>)"], ["java.util.Map<org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.quotas.QuotaState>", "org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore$2.fetchEntries(java.util.List<org.apache.hadoop.hbase.client.Get>)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil$1.visitUserQuotas(java.lang.String, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil$1.visitUserQuotas(java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.QuotaUtil$1.visitUserQuotas(java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["org.apache.hadoop.hbase.quotas.RegionServerQuotaManager", "org.apache.hadoop.hbase.quotas.RegionServerQuotaManager(org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["void", "org.apache.hadoop.hbase.quotas.RegionServerQuotaManager.start(org.apache.hadoop.hbase.ipc.RpcScheduler)"], ["void", "org.apache.hadoop.hbase.quotas.RegionServerQuotaManager.stop()"], ["boolean", "org.apache.hadoop.hbase.quotas.RegionServerQuotaManager.isQuotaEnabled()"], ["org.apache.hadoop.hbase.quotas.OperationQuota", "org.apache.hadoop.hbase.quotas.RegionServerQuotaManager.getQuota(org.apache.hadoop.security.UserGroupInformation, org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.quotas.OperationQuota", "org.apache.hadoop.hbase.quotas.RegionServerQuotaManager.checkQuota(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.quotas.OperationQuota$OperationType)"], ["org.apache.hadoop.hbase.quotas.OperationQuota", "org.apache.hadoop.hbase.quotas.RegionServerQuotaManager.checkQuota(org.apache.hadoop.hbase.regionserver.Region, java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos$Action>)"], ["org.apache.hadoop.hbase.regionserver.CompactedHFilesDischargeHandler", "org.apache.hadoop.hbase.regionserver.CompactedHFilesDischargeHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.executor.EventType, org.apache.hadoop.hbase.regionserver.HStore)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactedHFilesDischargeHandler.process()"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.regionserver.compactions.Compactor$2.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.compactions.Compactor$2.run()"], ["int", "org.apache.hadoop.hbase.regionserver.compactions.CurrentHourProvider.getCurrentHour()"], ["org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy", "org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.StoreConfigInformation)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$SplitStripeCompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$SplitStripeCompactionRequest(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest, byte[], byte[], int, long)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$SplitStripeCompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$SplitStripeCompactionRequest(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest, byte[], byte[], long)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$SplitStripeCompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$SplitStripeCompactionRequest(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, byte[], byte[], long)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$SplitStripeCompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$SplitStripeCompactionRequest(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, byte[], byte[], int, long)"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$SplitStripeCompactionRequest.setMajorRangeFull()"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor$StripeInternalScannerFactory", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor$StripeInternalScannerFactory(org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor, byte[], byte[])"], ["org.apache.hadoop.hbase.regionserver.ScanType", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor$StripeInternalScannerFactory.getScanType(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.InternalScanner", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor$StripeInternalScannerFactory.createScanner(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFileScanner>, org.apache.hadoop.hbase.regionserver.ScanType, org.apache.hadoop.hbase.regionserver.compactions.Compactor$FileDetails, long)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactSplitThread$Rejection.rejectedExecution(java.lang.Runnable, java.util.concurrent.ThreadPoolExecutor)"], ["org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher", "org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.Store)"], ["org.apache.hadoop.hbase.regionserver.FifoRpcSchedulerFactory", "org.apache.hadoop.hbase.regionserver.FifoRpcSchedulerFactory()"], ["org.apache.hadoop.hbase.ipc.RpcScheduler", "org.apache.hadoop.hbase.regionserver.FifoRpcSchedulerFactory.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.ipc.RpcScheduler", "org.apache.hadoop.hbase.regionserver.FifoRpcSchedulerFactory.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.ipc.PriorityFunction)"], ["void", "org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run()"], ["org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler", "org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination, org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination$SplitTaskDetails, org.apache.hadoop.hbase.util.CancelableProgressable, java.util.concurrent.atomic.AtomicInteger, org.apache.hadoop.hbase.regionserver.SplitLogWorker$TaskExecutor, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode)"], ["void", "org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.process()"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.HRegion$4.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.HRegion$4.call()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegionServer$1.uncaughtException(java.lang.Thread, java.lang.Throwable)"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.HStore$2.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.HStore$2.call()"], ["org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy", "org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy()"], ["org.apache.hadoop.hbase.regionserver.KeyValueHeap$KVScannerComparator", "org.apache.hadoop.hbase.regionserver.KeyValueHeap$KVScannerComparator(org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["int", "org.apache.hadoop.hbase.regionserver.KeyValueHeap$KVScannerComparator.compare(org.apache.hadoop.hbase.regionserver.KeyValueScanner, org.apache.hadoop.hbase.regionserver.KeyValueScanner)"], ["int", "org.apache.hadoop.hbase.regionserver.KeyValueHeap$KVScannerComparator.compare(org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.regionserver.KeyValueHeap$KVScannerComparator.getComparator()"], ["int", "org.apache.hadoop.hbase.regionserver.KeyValueHeap$KVScannerComparator.compare(java.lang.Object, java.lang.Object)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.Leases$Lease.getLeaseName()"], ["org.apache.hadoop.hbase.regionserver.LeaseListener", "org.apache.hadoop.hbase.regionserver.Leases$Lease.getListener()"], ["boolean", "org.apache.hadoop.hbase.regionserver.Leases$Lease.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.regionserver.Leases$Lease.hashCode()"], ["long", "org.apache.hadoop.hbase.regionserver.Leases$Lease.getDelay(java.util.concurrent.TimeUnit)"], ["int", "org.apache.hadoop.hbase.regionserver.Leases$Lease.compareTo(java.util.concurrent.Delayed)"], ["void", "org.apache.hadoop.hbase.regionserver.Leases$Lease.resetExpirationTime()"], ["int", "org.apache.hadoop.hbase.regionserver.Leases$Lease.compareTo(java.lang.Object)"], ["K", "org.apache.hadoop.hbase.regionserver.LruHashMap$Entry.getKey()"], ["V", "org.apache.hadoop.hbase.regionserver.LruHashMap$Entry.getValue()"], ["V", "org.apache.hadoop.hbase.regionserver.LruHashMap$Entry.setValue(V)"], ["boolean", "org.apache.hadoop.hbase.regionserver.LruHashMap$Entry.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.regionserver.LruHashMap$Entry.hashCode()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.LruHashMap$Entry.toString()"], ["long", "org.apache.hadoop.hbase.regionserver.LruHashMap$Entry.heapSize()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.LruHashMap$Entry.setValue(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.LruHashMap$Entry.getValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.LruHashMap$Entry.getKey()"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl(org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getClusterId()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getStartCode()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getZookeeperQuorum()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getCoprocessors()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getServerName()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getNumOnlineRegions()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getTotalRequestCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getTotalRowActionRequestCount()"], ["int", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getSplitQueueSize()"], ["int", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getCompactionQueueSize()"], ["int", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getSmallCompactionQueueSize()"], ["int", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getLargeCompactionQueueSize()"], ["int", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getFlushQueueSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCacheCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCacheSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCacheFreeSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCacheHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCachePrimaryHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCacheMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCachePrimaryMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCacheEvictedCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCachePrimaryEvictedCount()"], ["double", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCacheHitPercent()"], ["double", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCacheHitCachingPercent()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockCacheFailedInsertions()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getL1CacheHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getL1CacheMissCount()"], ["double", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getL1CacheHitRatio()"], ["double", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getL1CacheMissRatio()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getL2CacheHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getL2CacheMissCount()"], ["double", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getL2CacheHitRatio()"], ["double", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getL2CacheMissRatio()"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.forceRecompute()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getNumStores()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getNumWALFiles()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getWALFileSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getNumStoreFiles()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getMaxStoreFileAge()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getMinStoreFileAge()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getAvgStoreFileAge()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getNumReferenceFiles()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getMemstoreSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getStoreFileSize()"], ["double", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getRequestsPerSecond()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getReadRequestsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getWriteRequestsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getRpcGetRequestsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getRpcScanRequestsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getRpcMultiRequestsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getRpcMutateRequestsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getCheckAndMutateChecksFailed()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getCheckAndMutateChecksPassed()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getStoreFileIndexSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getTotalStaticIndexSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getTotalStaticBloomSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getNumMutationsWithoutWAL()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getDataInMemoryWithoutWAL()"], ["double", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getPercentFileLocal()"], ["double", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getPercentFileLocalSecondaryRegions()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getUpdatesBlockedTime()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getFlushedCellsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getCompactedCellsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getMajorCompactedCellsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getFlushedCellsSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getCompactedCellsSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getMajorCompactedCellsSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBlockedRequestsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getAverageRegionSize()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getDataMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getLeafIndexMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBloomChunkMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getMetaMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getRootIndexMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getIntermediateIndexMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getFileInfoMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getGeneralBloomMetaMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getDeleteFamilyBloomMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getTrailerMissCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getDataHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getLeafIndexHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getBloomChunkHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getMetaHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getRootIndexHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getIntermediateIndexHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getFileInfoHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getGeneralBloomMetaHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getDeleteFamilyBloomHitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.getTrailerHitCount()"], ["org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl()"], ["org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl(long)"], ["void", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.advanceTo(long)"], ["org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl$WriteEntry", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.begin()"], ["org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl$WriteEntry", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.begin(java.lang.Runnable)"], ["void", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.await()"], ["void", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.completeAndWait(org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl$WriteEntry)"], ["boolean", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.complete(org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl$WriteEntry)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.toString()"], ["long", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.getReadPoint()"], ["long", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.getWritePoint()"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.CompactionScanQueryMatcher.hasNullColumnInQuery()"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.CompactionScanQueryMatcher.isUserScan()"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.CompactionScanQueryMatcher.moreRowsMayExistAfter(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.filter.Filter", "org.apache.hadoop.hbase.regionserver.querymatcher.CompactionScanQueryMatcher.getFilter()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.querymatcher.CompactionScanQueryMatcher.getNextKeyHint(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.CompactionScanQueryMatcher", "org.apache.hadoop.hbase.regionserver.querymatcher.CompactionScanQueryMatcher.create(org.apache.hadoop.hbase.regionserver.ScanInfo, org.apache.hadoop.hbase.regionserver.ScanType, long, long, long, long, byte[], byte[], org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.RawScanQueryMatcher.match(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.RawScanQueryMatcher", "org.apache.hadoop.hbase.regionserver.querymatcher.RawScanQueryMatcher.create(org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.ScanInfo, org.apache.hadoop.hbase.regionserver.querymatcher.ColumnTracker, boolean, long, long)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.StripeCompactionScanQueryMatcher$DropDeletesInOutput[]", "org.apache.hadoop.hbase.regionserver.querymatcher.StripeCompactionScanQueryMatcher$DropDeletesInOutput.values()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.StripeCompactionScanQueryMatcher$DropDeletesInOutput", "org.apache.hadoop.hbase.regionserver.querymatcher.StripeCompactionScanQueryMatcher$DropDeletesInOutput.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.Region$Operation[]", "org.apache.hadoop.hbase.regionserver.Region$Operation.values()"], ["org.apache.hadoop.hbase.regionserver.Region$Operation", "org.apache.hadoop.hbase.regionserver.Region$Operation.valueOf(java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$19.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$26.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$39.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$46.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$53.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$56.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$69.call(org.apache.hadoop.hbase.coprocessor.EndpointObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$EndpointOperationWithResult.setResult(T)"], ["T", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$EndpointOperationWithResult.getResult()"], ["org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment(org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.RegionServerServices, java.util.concurrent.ConcurrentMap<java.lang.String, java.lang.Object>)"], ["org.apache.hadoop.hbase.regionserver.Region", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment.getRegion()"], ["org.apache.hadoop.hbase.regionserver.RegionServerServices", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment.getRegionServerServices()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment.shutdown()"], ["java.util.concurrent.ConcurrentMap<java.lang.String, java.lang.Object>", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment.getSharedData()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment.getRegionInfo()"], ["org.apache.hadoop.hbase.metrics.MetricRegistry", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$RegionEnvironment.getMetricRegistryForRegionServer()"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$2.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$2.run()"], ["org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, boolean)"], ["org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, boolean, long)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.prepare(org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.execute(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.execute(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.security.User)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.stepsAfterPONR(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.regionserver.HRegion)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.stepsAfterPONR(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.security.User)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.prepareMutationsForMerge(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, java.util.List<org.apache.hadoop.hbase.client.Mutation>, int)"], ["org.apache.hadoop.hbase.client.Put", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.addLocation(org.apache.hadoop.hbase.client.Put, org.apache.hadoop.hbase.ServerName, long)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.stepsBeforePONR(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, boolean)"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.getMergedRegionInfo(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.rollback(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.rollback(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.security.User)"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.getMergedRegionInfo()"], ["org.apache.hadoop.hbase.regionserver.RegionMergeTransaction", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.registerTransactionListener(org.apache.hadoop.hbase.regionserver.RegionMergeTransaction$TransactionListener)"], ["org.apache.hadoop.hbase.Server", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.getServer()"], ["org.apache.hadoop.hbase.regionserver.RegionServerServices", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.getRegionServerServices()"], ["org.apache.hadoop.hbase.regionserver.Region", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.execute(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.security.User)"], ["org.apache.hadoop.hbase.regionserver.Region", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.execute(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics", "org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.updatePut(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.updatePutBatch(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.updateGet(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.updateIncrement(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.updateAppend(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.updateDelete(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.updateDeleteBatch(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.updateScanTime(org.apache.hadoop.hbase.TableName, long)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.updateScanSize(org.apache.hadoop.hbase.TableName, long)"], ["org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap(java.util.List<? extends org.apache.hadoop.hbase.regionserver.KeyValueScanner>, org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.seek(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.reseek(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.requestSeek(org.apache.hadoop.hbase.Cell, boolean, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.seekToPreviousRow(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.backwardSeek(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.next()"], ["boolean", "org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.seekToLastRow()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.RSRpcServices$2.java.lang.Throwable fillInStackTrace()"], ["org.apache.hadoop.hbase.regionserver.ScanType[]", "org.apache.hadoop.hbase.regionserver.ScanType.values()"], ["org.apache.hadoop.hbase.regionserver.ScanType", "org.apache.hadoop.hbase.regionserver.ScanType.valueOf(java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.ShutdownHook$ShutdownHookThread.run()"], ["org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager$SnapshotSubprocedureBuilder", "org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager$SnapshotSubprocedureBuilder(org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager)"], ["org.apache.hadoop.hbase.procedure.Subprocedure", "org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager$SnapshotSubprocedureBuilder.buildSubprocedure(java.lang.String, byte[])"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.SplitRequest.toString()"], ["void", "org.apache.hadoop.hbase.regionserver.SplitRequest.run()"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$3.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$3.run()"], ["org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$StoreFileSplitter", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$StoreFileSplitter(org.apache.hadoop.hbase.regionserver.SplitTransactionImpl, byte[], org.apache.hadoop.hbase.regionserver.StoreFile)"], ["org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path>", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$StoreFileSplitter.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$StoreFileSplitter.call()"], ["java.lang.Long", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators$GetFileSize.apply(org.apache.hadoop.hbase.regionserver.StoreFile)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators$GetFileSize.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.withTimeRangeTracker(org.apache.hadoop.hbase.regionserver.TimeRangeTracker)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.withOutputDir(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.withFilePath(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.withFavoredNodes(java.net.InetSocketAddress[])"], ["org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.withComparator(org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.withBloomType(org.apache.hadoop.hbase.regionserver.BloomType)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.withMaxKeyCount(long)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.withFileContext(org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.withShouldDropCacheBehind(boolean)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Writer", "org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build()"], ["org.apache.hadoop.hbase.regionserver.StoreScanner$StoreScannerCompactionRace[]", "org.apache.hadoop.hbase.regionserver.StoreScanner$StoreScannerCompactionRace.values()"], ["org.apache.hadoop.hbase.regionserver.StoreScanner$StoreScannerCompactionRace", "org.apache.hadoop.hbase.regionserver.StoreScanner$StoreScannerCompactionRace.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.StripeStoreConfig", "org.apache.hadoop.hbase.regionserver.StripeStoreConfig(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.StoreConfigInformation)"], ["float", "org.apache.hadoop.hbase.regionserver.StripeStoreConfig.getMaxSplitImbalance()"], ["int", "org.apache.hadoop.hbase.regionserver.StripeStoreConfig.getLevel0MinFiles()"], ["int", "org.apache.hadoop.hbase.regionserver.StripeStoreConfig.getStripeCompactMinFiles()"], ["int", "org.apache.hadoop.hbase.regionserver.StripeStoreConfig.getStripeCompactMaxFiles()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StripeStoreConfig.isUsingL0Flush()"], ["long", "org.apache.hadoop.hbase.regionserver.StripeStoreConfig.getSplitSize()"], ["int", "org.apache.hadoop.hbase.regionserver.StripeStoreConfig.getInitialCount()"], ["float", "org.apache.hadoop.hbase.regionserver.StripeStoreConfig.getSplitCount()"], ["long", "org.apache.hadoop.hbase.regionserver.StripeStoreConfig.getSplitPartSize()"], ["org.apache.hadoop.hbase.regionserver.throttle.ThroughputController", "org.apache.hadoop.hbase.regionserver.throttle.CompactionThroughputControllerFactory.create(org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.conf.Configuration)"], ["java.lang.Class<? extends org.apache.hadoop.hbase.regionserver.throttle.ThroughputController>", "org.apache.hadoop.hbase.regionserver.throttle.CompactionThroughputControllerFactory.getThroughputControllerClass(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.wal.DamagedWALException", "org.apache.hadoop.hbase.regionserver.wal.DamagedWALException()"], ["org.apache.hadoop.hbase.regionserver.wal.DamagedWALException", "org.apache.hadoop.hbase.regionserver.wal.DamagedWALException(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.wal.DamagedWALException", "org.apache.hadoop.hbase.regionserver.wal.DamagedWALException(java.lang.String, java.lang.Throwable)"], ["org.apache.hadoop.hbase.regionserver.wal.DamagedWALException", "org.apache.hadoop.hbase.regionserver.wal.DamagedWALException(java.lang.Throwable)"], ["org.apache.hadoop.hbase.regionserver.wal.MetricsWAL", "org.apache.hadoop.hbase.regionserver.wal.MetricsWAL()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.MetricsWAL.postSync(long, int)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.MetricsWAL.postAppend(long, long, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.MetricsWAL.logRollRequested(boolean)"], ["org.apache.hadoop.hbase.regionserver.wal.ReplayHLogKey", "org.apache.hadoop.hbase.regionserver.wal.ReplayHLogKey(byte[], org.apache.hadoop.hbase.TableName, long, java.util.List<java.util.UUID>, long, long, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["org.apache.hadoop.hbase.regionserver.wal.ReplayHLogKey", "org.apache.hadoop.hbase.regionserver.wal.ReplayHLogKey(byte[], org.apache.hadoop.hbase.TableName, long, long, java.util.List<java.util.UUID>, long, long, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["long", "org.apache.hadoop.hbase.regionserver.wal.ReplayHLogKey.getSequenceId()"], ["org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter", "org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter()"], ["org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base.preLogRoll(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base.postLogRoll(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base.preLogArchive(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base.postLogArchive(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base.logRollRequested(boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base.logCloseRequested()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base.visitLogEntryBeforeWrite(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base.visitLogEntryBeforeWrite(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base.postAppend(long, long, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALActionsListener$Base.postSync(long, int)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$CompressedKvEncoder", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$CompressedKvEncoder(java.io.OutputStream, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$CompressedKvEncoder.write(org.apache.hadoop.hbase.Cell)"], ["long", "org.apache.hadoop.hbase.regionserver.wal.WALUtil.writeCompactionMarker(org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.protobuf.generated.WALProtos$CompactionDescriptor, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["long", "org.apache.hadoop.hbase.regionserver.wal.WALUtil.writeFlushMarker(org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.protobuf.generated.WALProtos$FlushDescriptor, boolean, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["long", "org.apache.hadoop.hbase.regionserver.wal.WALUtil.writeRegionEventMarker(org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.protobuf.generated.WALProtos$RegionEventDescriptor, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["long", "org.apache.hadoop.hbase.regionserver.wal.WALUtil.writeBulkLoadMarkerAndSync(org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.protobuf.generated.WALProtos$BulkLoadDescriptor, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["org.apache.hadoop.hbase.replication.BaseWALEntryFilter", "org.apache.hadoop.hbase.replication.BaseWALEntryFilter()"], ["org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint", "org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint()"], ["synchronized", "org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint.java.util.UUID getPeerUUID()"], ["void", "org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint.isAborted()"], ["synchronized", "org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint.void setRegionServers(java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["long", "org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint.getLastRegionServerUpdate()"], ["org.apache.hadoop.hbase.replication.regionserver.MetricsSource", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource(java.lang.String)"], ["org.apache.hadoop.hbase.replication.regionserver.MetricsSource", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource(java.lang.String, org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceSource, org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceSource)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.setAgeOfLastShippedOp(long, java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.refreshAgeOfLastShippedOp(java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrSizeOfLogQueue()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.decrSizeOfLogQueue()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrLogEditsRead()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrLogEditsFiltered(long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrLogEditsFiltered()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.shipBatch(long, int)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.shipBatch(long, int, long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrLogReadInBytes(long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.clear()"], ["java.lang.Long", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.getAgeOfLastShippedOp()"], ["int", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.getSizeOfLogQueue()"], ["long", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.getTimeStampOfLastShippedOp()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.getPeerID()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrSizeOfHFileRefsQueue(long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.decrSizeOfHFileRefsQueue(int)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrUnknownFileLengthForClosedWAL()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrUncleanlyClosedWALs()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrBytesSkippedInUncleanlyClosedWALs(long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrRestartedWALReading()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrRepeatedFileBytes(long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrCompletedWAL()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incrCompletedRecoveryQueue()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.init()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.setGauge(java.lang.String, long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incGauge(java.lang.String, long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.decGauge(java.lang.String, long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.removeMetric(java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.incCounters(java.lang.String, long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.updateHistogram(java.lang.String, long)"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.getMetricsContext()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.getMetricsDescription()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.getMetricsJmxContext()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.getMetricsName()"], ["org.apache.hadoop.hbase.metrics.MetricRegistryInfo", "org.apache.hadoop.hbase.replication.regionserver.MetricsSource.getMetricRegistryInfo()"], ["org.apache.hadoop.hbase.replication.regionserver.Replication$ReplicationStatisticsThread", "org.apache.hadoop.hbase.replication.regionserver.Replication$ReplicationStatisticsThread(org.apache.hadoop.hbase.replication.regionserver.ReplicationSink, org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.Replication$ReplicationStatisticsThread.run()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp.setConfigure(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp.main(java.lang.String[])"], ["int", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp.run(java.lang.String[])"], ["org.apache.hadoop.hbase.replication.regionserver.WALEntryStream$WALEntryStreamRuntimeException", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream$WALEntryStreamRuntimeException(java.lang.Exception)"], ["org.apache.hadoop.hbase.replication.SystemTableWALEntryFilter", "org.apache.hadoop.hbase.replication.SystemTableWALEntryFilter()"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.replication.SystemTableWALEntryFilter.filter(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["org.apache.hadoop.hbase.security.access.AccessControlFilter$Strategy[]", "org.apache.hadoop.hbase.security.access.AccessControlFilter$Strategy.values()"], ["org.apache.hadoop.hbase.security.access.AccessControlFilter$Strategy", "org.apache.hadoop.hbase.security.access.AccessControlFilter$Strategy.valueOf(java.lang.String)"], ["java.lang.Void", "org.apache.hadoop.hbase.security.access.AccessController$2.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$2.run()"], ["org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration$NullInstance", "org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration$NullInstance()"], ["org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration$NullInstance", "org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration$NullInstance(java.lang.Class<?>, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration$NullInstance.readFields(java.io.DataInput)"], ["void", "org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration$NullInstance.write(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager$PermissionCache.putUser(java.lang.String, T)"], ["void", "org.apache.hadoop.hbase.security.access.TableAuthManager$PermissionCache.putGroup(java.lang.String, T)"], ["com.google.common.collect.ListMultimap<java.lang.String, T>", "org.apache.hadoop.hbase.security.access.TableAuthManager$PermissionCache.getAllPermissions()"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher$4.run()"], ["org.apache.hadoop.hbase.security.HBaseSaslRpcServer", "org.apache.hadoop.hbase.security.HBaseSaslRpcServer()"], ["void", "org.apache.hadoop.hbase.security.HBaseSaslRpcServer.init(org.apache.hadoop.conf.Configuration)"], ["java.util.Map<java.lang.String, java.lang.String>", "org.apache.hadoop.hbase.security.HBaseSaslRpcServer.getSaslProps()"], ["<T extends org.apache.hadoop.security.token.TokenIdentifier> T", "org.apache.hadoop.hbase.security.HBaseSaslRpcServer.getIdentifier(java.lang.String, org.apache.hadoop.security.token.SecretManager<T>)"], ["boolean", "org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl$1.evaluate(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.security.visibility.ParseException", "org.apache.hadoop.hbase.security.visibility.ParseException()"], ["org.apache.hadoop.hbase.security.visibility.ParseException", "org.apache.hadoop.hbase.security.visibility.ParseException(java.lang.String)"], ["org.apache.hadoop.hbase.security.visibility.ParseException", "org.apache.hadoop.hbase.security.visibility.ParseException(java.lang.Throwable)"], ["org.apache.hadoop.hbase.security.visibility.ParseException", "org.apache.hadoop.hbase.security.visibility.ParseException(java.lang.String, java.lang.Throwable)"], ["org.apache.hadoop.hbase.snapshot.ExportSnapshot", "org.apache.hadoop.hbase.snapshot.ExportSnapshot()"], ["int", "org.apache.hadoop.hbase.snapshot.ExportSnapshot.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.snapshot.ExportSnapshot.main(java.lang.String[])"], ["org.apache.hadoop.hbase.snapshot.SnapshotInfo", "org.apache.hadoop.hbase.snapshot.SnapshotInfo()"], ["int", "org.apache.hadoop.hbase.snapshot.SnapshotInfo.run(java.lang.String[])"], ["org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats", "org.apache.hadoop.hbase.snapshot.SnapshotInfo.getSnapshotStats(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["org.apache.hadoop.hbase.snapshot.SnapshotInfo$SnapshotStats", "org.apache.hadoop.hbase.snapshot.SnapshotInfo.getSnapshotStats(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, java.util.Map<org.apache.hadoop.fs.Path, java.lang.Integer>)"], ["java.util.Map<org.apache.hadoop.fs.Path, java.lang.Integer>", "org.apache.hadoop.hbase.snapshot.SnapshotInfo.getSnapshotsFilesMap(org.apache.hadoop.conf.Configuration, java.util.concurrent.atomic.AtomicLong, java.util.concurrent.atomic.AtomicLong)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotInfo.main(java.lang.String[])"], ["java.lang.Void", "org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil$2.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil$2.call()"], ["org.apache.hadoop.hbase.SplitLogTask$Done", "org.apache.hadoop.hbase.SplitLogTask$Done(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode)"], ["org.apache.hadoop.hbase.SslRMIClientSocketFactorySecure", "org.apache.hadoop.hbase.SslRMIClientSocketFactorySecure()"], ["java.net.Socket", "org.apache.hadoop.hbase.SslRMIClientSocketFactorySecure.createSocket(java.lang.String, int)"], ["org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData()"], ["void", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData.setFilter(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData.getFilter()"], ["boolean", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData.getFilter__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData.setFormat(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData.getFormat()"], ["boolean", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData.getFormat__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData.setTaskMonitor(org.apache.hadoop.hbase.monitoring.TaskMonitor)"], ["org.apache.hadoop.hbase.monitoring.TaskMonitor", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData.getTaskMonitor()"], ["boolean", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$ImplData.getTaskMonitor__IsNotDefault()"], ["org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl(org.jamon.TemplateManager)"], ["org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl()"], ["org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.setLimit(int)"], ["org.jamon.AbstractTemplateImpl", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.constructImpl(java.lang.Class<? extends org.jamon.AbstractTemplateImpl>)"], ["org.jamon.Renderer", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.makeRenderer(org.apache.hadoop.hbase.master.AssignmentManager)"], ["void", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.render(java.io.Writer, org.apache.hadoop.hbase.master.AssignmentManager)"], ["void", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.renderNoFlush(java.io.Writer, org.apache.hadoop.hbase.master.AssignmentManager)"], ["org.jamon.AbstractTemplateProxy$ImplData", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl$ImplData()"], ["void", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl$ImplData.setMaster(org.apache.hadoop.hbase.master.HMaster)"], ["org.apache.hadoop.hbase.master.HMaster", "org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl$ImplData.getMaster()"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl(org.jamon.TemplateManager)"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl()"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.setCatalogJanitorEnabled(boolean)"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.setServerManager(org.apache.hadoop.hbase.master.ServerManager)"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.setFormat(java.lang.String)"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.setFrags(java.util.Map<java.lang.String, java.lang.Integer>)"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.setAssignmentManager(org.apache.hadoop.hbase.master.AssignmentManager)"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.setMetaLocation(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.setDeadServers(java.util.Set<org.apache.hadoop.hbase.ServerName>)"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.setServers(java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.setFilter(java.lang.String)"], ["org.jamon.AbstractTemplateImpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.constructImpl(java.lang.Class<? extends org.jamon.AbstractTemplateImpl>)"], ["org.jamon.Renderer", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.makeRenderer(org.apache.hadoop.hbase.master.HMaster)"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.render(java.io.Writer, org.apache.hadoop.hbase.master.HMaster)"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.renderNoFlush(java.io.Writer, org.apache.hadoop.hbase.master.HMaster)"], ["org.jamon.AbstractTemplateProxy$ImplData", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmplImpl", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmplImpl(org.jamon.TemplateManager, org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl$ImplData)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmplImpl.renderNoFlush(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmplImpl", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmplImpl(org.jamon.TemplateManager, org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl$ImplData)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmplImpl.renderNoFlush(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl(org.jamon.TemplateManager)"], ["org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl()"], ["org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.getImplData()"], ["org.jamon.AbstractTemplateImpl", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.constructImpl(java.lang.Class<? extends org.jamon.AbstractTemplateImpl>)"], ["org.jamon.Renderer", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.makeRenderer(org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper, org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapper)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.render(java.io.Writer, org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper, org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapper)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.renderNoFlush(java.io.Writer, org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper, org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapper)"], ["org.jamon.AbstractTemplateProxy$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.getImplData()"], ["org.apache.hadoop.hbase.tool.Canary$RegionTask$TaskType[]", "org.apache.hadoop.hbase.tool.Canary$RegionTask$TaskType.values()"], ["org.apache.hadoop.hbase.tool.Canary$RegionTask$TaskType", "org.apache.hadoop.hbase.tool.Canary$RegionTask$TaskType.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.tool.Canary", "org.apache.hadoop.hbase.tool.Canary()"], ["org.apache.hadoop.hbase.tool.Canary", "org.apache.hadoop.hbase.tool.Canary(java.util.concurrent.ExecutorService, org.apache.hadoop.hbase.tool.Canary$Sink)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.tool.Canary.getConf()"], ["void", "org.apache.hadoop.hbase.tool.Canary.setConf(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.tool.Canary.run(java.lang.String[])"], ["java.util.Map<java.lang.String, java.lang.String>", "org.apache.hadoop.hbase.tool.Canary.getReadFailures()"], ["java.util.Map<java.lang.String, java.lang.String>", "org.apache.hadoop.hbase.tool.Canary.getWriteFailures()"], ["org.apache.hadoop.hbase.tool.Canary$Monitor", "org.apache.hadoop.hbase.tool.Canary.newMonitor(org.apache.hadoop.hbase.client.Connection, int, java.lang.String[])"], ["void", "org.apache.hadoop.hbase.tool.Canary.main(java.lang.String[])"], ["org.apache.hadoop.hbase.util.CompoundBloomFilter", "org.apache.hadoop.hbase.util.CompoundBloomFilter(java.io.DataInput, org.apache.hadoop.hbase.io.hfile.HFile$Reader)"], ["boolean", "org.apache.hadoop.hbase.util.CompoundBloomFilter.contains(byte[], int, int, java.nio.ByteBuffer)"], ["boolean", "org.apache.hadoop.hbase.util.CompoundBloomFilter.supportsAutoLoading()"], ["int", "org.apache.hadoop.hbase.util.CompoundBloomFilter.getNumChunks()"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.util.CompoundBloomFilter.getComparator()"], ["void", "org.apache.hadoop.hbase.util.CompoundBloomFilter.enableTestingStats()"], ["java.lang.String", "org.apache.hadoop.hbase.util.CompoundBloomFilter.formatTestingStats()"], ["long", "org.apache.hadoop.hbase.util.CompoundBloomFilter.getNumQueriesForTesting(int)"], ["long", "org.apache.hadoop.hbase.util.CompoundBloomFilter.getNumPositivesForTesting(int)"], ["java.lang.String", "org.apache.hadoop.hbase.util.CompoundBloomFilter.toString()"], ["void", "org.apache.hadoop.hbase.util.ConnectionCache$2.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.util.ConnectionCache$2.isStopped()"], ["org.apache.hadoop.hbase.util.FSMapRUtils", "org.apache.hadoop.hbase.util.FSMapRUtils()"], ["void", "org.apache.hadoop.hbase.util.FSMapRUtils.recoverFileLease(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["org.apache.hadoop.hbase.util.FSUtils$FileFilter", "org.apache.hadoop.hbase.util.FSUtils$FileFilter(org.apache.hadoop.fs.FileSystem)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$1.run()"], ["org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter$ERROR_CODE[]", "org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter$ERROR_CODE.values()"], ["org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter$ERROR_CODE", "org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter$ERROR_CODE.valueOf(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.util.HBaseFsck$OnlineEntry.toString()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$WorkItemHdfsDir$1.run()"], ["org.apache.hadoop.hbase.util.HBaseFsck", "org.apache.hadoop.hbase.util.HBaseFsck(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.util.HBaseFsck", "org.apache.hadoop.hbase.util.HBaseFsck(org.apache.hadoop.conf.Configuration, java.util.concurrent.ExecutorService)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.connect()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.offlineHdfsIntegrityRepair()"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck.onlineConsistencyRepair()"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck.onlineHbck()"], ["byte[]", "org.apache.hadoop.hbase.util.HBaseFsck.keyOnly(byte[])"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.close()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.checkRegionBoundaries()"], ["org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter", "org.apache.hadoop.hbase.util.HBaseFsck.getErrors()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.fixEmptyMetaCells()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.fixOrphanTables()"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck.rebuildMeta(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.loadHdfsRegionDirs()"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck.mergeRegionDirs(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.dumpOverlapProblems(com.google.common.collect.Multimap<byte[], org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo>)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.dumpSidelinedRegions(java.util.Map<org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo>)"], ["com.google.common.collect.Multimap<byte[], org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo>", "org.apache.hadoop.hbase.util.HBaseFsck.getOverlapGroups(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setDisplayFullReport()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setForceExclusive()"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck.isExclusive()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixTableLocks(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixReplication(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixTableZNodes(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixAssignments(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixMeta(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixEmptyMetaCells(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setCheckHdfs(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixHdfsHoles(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixTableOrphans(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixHdfsOverlaps(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixHdfsOrphans(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixVersionFile(boolean)"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck.shouldFixVersionFile()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setSidelineBigOverlaps(boolean)"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck.shouldSidelineBigOverlaps()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixSplitParents(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setRemoveParents(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixReferenceFiles(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setFixHFileLinks(boolean)"], ["boolean", "org.apache.hadoop.hbase.util.HBaseFsck.shouldIgnorePreCheckPermission()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setIgnorePreCheckPermission(boolean)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setMaxMerge(int)"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck.getMaxMerge()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setMaxOverlapsToSideline(int)"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck.getMaxOverlapsToSideline()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.includeTable(org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setTimeLag(long)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setSidelineDir(java.lang.String)"], ["org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker", "org.apache.hadoop.hbase.util.HBaseFsck.getHFilecorruptionChecker()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setHFileCorruptionChecker(org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.setRetCode(int)"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck.getRetCode()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.main(java.lang.String[])"], ["org.apache.hadoop.hbase.util.HBaseFsck", "org.apache.hadoop.hbase.util.HBaseFsck.exec(java.util.concurrent.ExecutorService, java.lang.String[])"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.debugLsr(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck.debugLsr(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter)"], ["com.yammer.metrics.core.Histogram", "org.apache.hadoop.hbase.util.YammerHistogramUtils.newHistogram(com.yammer.metrics.stats.Sample)"], ["java.lang.String", "org.apache.hadoop.hbase.util.YammerHistogramUtils.getShortHistogramReport(com.yammer.metrics.core.Histogram)"], ["java.lang.String", "org.apache.hadoop.hbase.util.YammerHistogramUtils.getHistogramReport(com.yammer.metrics.core.Histogram)"], ["java.lang.String", "org.apache.hadoop.hbase.util.YammerHistogramUtils.getPrettyHistogramReport(com.yammer.metrics.core.Histogram)"], ["void", "org.apache.hadoop.hbase.wal.DisabledWALProvider.init(org.apache.hadoop.hbase.wal.WALFactory, org.apache.hadoop.conf.Configuration, java.util.List<org.apache.hadoop.hbase.regionserver.wal.WALActionsListener>, java.lang.String)"], ["org.apache.hadoop.hbase.wal.WAL", "org.apache.hadoop.hbase.wal.DisabledWALProvider.getWAL(byte[], byte[])"], ["void", "org.apache.hadoop.hbase.wal.DisabledWALProvider.close()"], ["void", "org.apache.hadoop.hbase.wal.DisabledWALProvider.shutdown()"], ["long", "org.apache.hadoop.hbase.wal.DisabledWALProvider.getNumLogFiles()"], ["long", "org.apache.hadoop.hbase.wal.DisabledWALProvider.getLogFileSize()"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.wal.WAL$Entry()"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.wal.WAL$Entry(org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["org.apache.hadoop.hbase.regionserver.wal.WALEdit", "org.apache.hadoop.hbase.wal.WAL$Entry.getEdit()"], ["org.apache.hadoop.hbase.wal.WALKey", "org.apache.hadoop.hbase.wal.WAL$Entry.getKey()"], ["void", "org.apache.hadoop.hbase.wal.WAL$Entry.setCompressionContext(org.apache.hadoop.hbase.regionserver.wal.CompressionContext)"], ["java.lang.String", "org.apache.hadoop.hbase.wal.WAL$Entry.toString()"], ["org.apache.hadoop.hbase.wal.WALPrettyPrinter", "org.apache.hadoop.hbase.wal.WALPrettyPrinter()"], ["org.apache.hadoop.hbase.wal.WALPrettyPrinter", "org.apache.hadoop.hbase.wal.WALPrettyPrinter(boolean, boolean, long, java.lang.String, java.lang.String, boolean, java.io.PrintStream)"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.enableValues()"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.disableValues()"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.enableJSON()"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.disableJSON()"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.setSequenceFilter(long)"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.setRegionFilter(java.lang.String)"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.setRowFilter(java.lang.String)"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.beginPersistentOutput()"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.endPersistentOutput()"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.processFile(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.main(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.wal.WALPrettyPrinter.run(java.lang.String[])"], ["org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers", "org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers(org.apache.hadoop.hbase.wal.WALSplitter$PipelineController, long)"], ["org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers", "org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers(org.apache.hadoop.hbase.wal.WALSplitter$PipelineController, long, boolean)"], ["void", "org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers.appendEntry(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["void", "org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers.waitUntilDrained()"], ["void", "org.apache.hadoop.hbase.ZNodeClearer$1.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.ZNodeClearer$1.isAborted()"], ["void", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase.acquire()"], ["boolean", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase.tryAcquire(long)"], ["void", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase.release()"], ["void", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase.reapAllLocks()"], ["void", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase.reapExpiredLocks(long)"], ["void", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase.visitLocks(org.apache.hadoop.hbase.InterProcessLock$MetadataHandler)"], ["org.apache.hadoop.hbase.zookeeper.ZKSplitLog", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog()"], ["java.lang.String", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.getEncodedNodeName(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.getFileName(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.getRescanNode(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.isRescanNode(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.isRescanNode(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.isTaskPath(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.getSplitLogDir(org.apache.hadoop.fs.Path, java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.getSplitLogDirTmpComponent(java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.markCorrupted(org.apache.hadoop.fs.Path, java.lang.String, org.apache.hadoop.fs.FileSystem)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.isCorrupted(org.apache.hadoop.fs.Path, java.lang.String, org.apache.hadoop.fs.FileSystem)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.isRegionMarkedRecoveringInZK(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String)"], ["long", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.parseLastFlushedSequenceIdFrom(byte[])"], ["void", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.deleteRecoveringRegionZNodes(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.util.List<java.lang.String>)"], ["org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos$RegionStoreSequenceIds", "org.apache.hadoop.hbase.zookeeper.ZKSplitLog.getRegionFlushedSequenceId(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String, java.lang.String)"], ["org.apache.hadoop.hbase.client.TableSnapshotScanner", "org.apache.hadoop.hbase.client.TableSnapshotScanner(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path, java.lang.String, org.apache.hadoop.hbase.client.Scan)"], ["org.apache.hadoop.hbase.client.TableSnapshotScanner", "org.apache.hadoop.hbase.client.TableSnapshotScanner(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, java.lang.String, org.apache.hadoop.hbase.client.Scan)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.client.TableSnapshotScanner.next()"], ["void", "org.apache.hadoop.hbase.client.TableSnapshotScanner.close()"], ["boolean", "org.apache.hadoop.hbase.client.TableSnapshotScanner.renewLease()"], ["org.apache.hadoop.hbase.constraint.BaseConstraint", "org.apache.hadoop.hbase.constraint.BaseConstraint()"], ["org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager", "org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager()"], ["void", "org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.initialize(org.apache.hadoop.hbase.Server)"], ["void", "org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.start()"], ["void", "org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.stop()"], ["org.apache.hadoop.hbase.Server", "org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.getServer()"], ["org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination(org.apache.hadoop.hbase.CoordinatedStateManager, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["org.apache.hadoop.hbase.coordination.RegionMergeCoordination$RegionMergeDetails", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination.getDefaultDetails()"], ["void", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination.waitForRegionMergeTransaction(org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.coordination.RegionMergeCoordination$RegionMergeDetails)"], ["void", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination.startRegionMergeTransaction(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination.clean(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination.completeRegionMergeTransaction(org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.coordination.RegionMergeCoordination$RegionMergeDetails, org.apache.hadoop.hbase.regionserver.HRegion)"], ["void", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination.confirmRegionMergeTransaction(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.coordination.RegionMergeCoordination$RegionMergeDetails)"], ["void", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination.processRegionMergeRequest(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.coordination.RegionMergeCoordination$RegionMergeDetails)"], ["org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$CreateRescanAsyncCallback", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$CreateRescanAsyncCallback(org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination)"], ["void", "org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination$CreateRescanAsyncCallback.processResult(int, java.lang.String, java.lang.Object, java.lang.String)"], ["org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination(org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.nodeChildrenChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.nodeDataChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.init(org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.SplitLogWorker$TaskExecutor, org.apache.hadoop.hbase.regionserver.SplitLogWorker)"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.getDataSetWatchAsync()"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.taskLoop()"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.markCorrupted(org.apache.hadoop.fs.Path, java.lang.String, org.apache.hadoop.fs.FileSystem)"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.isReady()"], ["int", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.getTaskReadySeq()"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.registerListener()"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.removeListener()"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.stopProcessingTasks()"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.isStop()"], ["org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos$RegionStoreSequenceIds", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.getRegionFlushedSequenceId(java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.endTask(org.apache.hadoop.hbase.SplitLogTask, java.util.concurrent.atomic.AtomicLong, org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination$SplitTaskDetails)"], ["org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment(org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.startup()"], ["org.apache.hadoop.hbase.Coprocessor", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.getInstance()"], ["java.lang.ClassLoader", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.getClassLoader()"], ["int", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.getPriority()"], ["int", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.getLoadSequence()"], ["int", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.getVersion()"], ["java.lang.String", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.getHBaseVersion()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.getConfiguration()"], ["org.apache.hadoop.hbase.client.HTableInterface", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.getTable(org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.client.HTableInterface", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.getTable(org.apache.hadoop.hbase.TableName, java.util.concurrent.ExecutorService)"], ["java.lang.Object", "org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(java.lang.Object, java.lang.reflect.Method, java.lang.Object[])"], ["org.apache.hadoop.hbase.generated.master.master_jsp", "org.apache.hadoop.hbase.generated.master.master_jsp()"], ["java.lang.Object", "org.apache.hadoop.hbase.generated.master.master_jsp.getDependants()"], ["void", "org.apache.hadoop.hbase.generated.master.master_jsp._jspService(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.generated.master.snapshot_jsp", "org.apache.hadoop.hbase.generated.master.snapshot_jsp()"], ["java.lang.Object", "org.apache.hadoop.hbase.generated.master.snapshot_jsp.getDependants()"], ["void", "org.apache.hadoop.hbase.generated.master.snapshot_jsp._jspService(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight", "org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight(java.lang.String, long)"], ["void", "org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight.addWeight(long)"], ["java.lang.String", "org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight.getHost()"], ["long", "org.apache.hadoop.hbase.HDFSBlocksDistribution$HostAndWeight.getWeight()"], ["org.apache.hadoop.hbase.http.AdminAuthorizedServlet", "org.apache.hadoop.hbase.http.AdminAuthorizedServlet()"], ["void", "org.apache.hadoop.hbase.http.HtmlQuoting$1.write(byte[], int, int)"], ["void", "org.apache.hadoop.hbase.http.HtmlQuoting$1.write(int)"], ["void", "org.apache.hadoop.hbase.http.HtmlQuoting$1.flush()"], ["void", "org.apache.hadoop.hbase.http.HtmlQuoting$1.close()"], ["org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter()"], ["void", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter.init(javax.servlet.FilterConfig)"], ["void", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter.destroy()"], ["void", "org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter.doFilter(javax.servlet.ServletRequest, javax.servlet.ServletResponse, javax.servlet.FilterChain)"], ["org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$User", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$User(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$User.getName()"], ["int", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$User.hashCode()"], ["boolean", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$User.equals(java.lang.Object)"], ["java.lang.String", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$User.toString()"], ["org.apache.hadoop.hbase.http.lib.StaticUserWebFilter", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter()"], ["void", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter.initFilter(org.apache.hadoop.hbase.http.FilterContainer, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.FSDataInputStreamWrapper", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.io.FSDataInputStreamWrapper", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, boolean)"], ["org.apache.hadoop.hbase.io.FSDataInputStreamWrapper", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.io.FileLink)"], ["org.apache.hadoop.hbase.io.FSDataInputStreamWrapper", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.io.FileLink, boolean)"], ["void", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.prepareForBlockReader(boolean)"], ["org.apache.hadoop.hbase.io.FSDataInputStreamWrapper", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper(org.apache.hadoop.fs.FSDataInputStream)"], ["org.apache.hadoop.hbase.io.FSDataInputStreamWrapper", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper(org.apache.hadoop.fs.FSDataInputStream, org.apache.hadoop.fs.FSDataInputStream)"], ["boolean", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.shouldUseHBaseChecksum()"], ["org.apache.hadoop.fs.FSDataInputStream", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.getStream(boolean)"], ["org.apache.hadoop.fs.FSDataInputStream", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.fallbackToFsChecksum(int)"], ["void", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.checksumOk()"], ["void", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.close()"], ["org.apache.hadoop.hbase.fs.HFileSystem", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.getHfs()"], ["void", "org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.unbuffer()"], ["org.apache.hadoop.hbase.io.hfile.BlockCacheKey", "org.apache.hadoop.hbase.io.hfile.BlockCacheKey(java.lang.String, long)"], ["org.apache.hadoop.hbase.io.hfile.BlockCacheKey", "org.apache.hadoop.hbase.io.hfile.BlockCacheKey(java.lang.String, long, boolean, org.apache.hadoop.hbase.io.hfile.BlockType)"], ["int", "org.apache.hadoop.hbase.io.hfile.BlockCacheKey.hashCode()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.BlockCacheKey.equals(java.lang.Object)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.BlockCacheKey.toString()"], ["long", "org.apache.hadoop.hbase.io.hfile.BlockCacheKey.heapSize()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.BlockCacheKey.getHfileName()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.BlockCacheKey.isPrimary()"], ["long", "org.apache.hadoop.hbase.io.hfile.BlockCacheKey.getOffset()"], ["org.apache.hadoop.hbase.io.hfile.BlockType", "org.apache.hadoop.hbase.io.hfile.BlockCacheKey.getBlockType()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.toString()"], ["org.apache.hadoop.hbase.io.hfile.BlockPriority", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.getBlockPriority()"], ["org.apache.hadoop.hbase.io.hfile.BlockType", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.getBlockType()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.getOffset()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.getSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.getCachedTime()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.getFilename()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.compareTo(org.apache.hadoop.hbase.io.hfile.CachedBlock)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.hashCode()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$2$1.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup(org.apache.hadoop.hbase.io.hfile.bucket.BucketCache, long, long, long)"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup.add(java.util.Map$Entry<org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry>)"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup.free(long)"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup.overflow()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup.totalSize()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup.compareTo(org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup.hashCode()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntryGroup.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine", "org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine(long, boolean)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.toString()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.isPersistent()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.read(java.nio.ByteBuffer, long)"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.write(java.nio.ByteBuffer, long)"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.sync()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.shutdown()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine$FileReadAccessor.access(java.nio.channels.FileChannel, java.nio.ByteBuffer, long)"], ["org.apache.hadoop.hbase.io.hfile.CacheConfig", "org.apache.hadoop.hbase.io.hfile.CacheConfig(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HColumnDescriptor)"], ["org.apache.hadoop.hbase.io.hfile.CacheConfig", "org.apache.hadoop.hbase.io.hfile.CacheConfig(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.CacheConfig", "org.apache.hadoop.hbase.io.hfile.CacheConfig(org.apache.hadoop.hbase.io.hfile.CacheConfig)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.isBlockCacheEnabled()"], ["org.apache.hadoop.hbase.io.hfile.BlockCache", "org.apache.hadoop.hbase.io.hfile.CacheConfig.getBlockCache()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldCacheDataOnRead()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldDropBehindCompaction()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldCacheBlockOnRead(org.apache.hadoop.hbase.io.hfile.BlockType$BlockCategory)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.isInMemory()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.isCacheDataInL1()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldCacheDataOnWrite()"], ["void", "org.apache.hadoop.hbase.io.hfile.CacheConfig.setCacheDataOnWrite(boolean)"], ["void", "org.apache.hadoop.hbase.io.hfile.CacheConfig.setCacheDataInL1(boolean)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldCacheIndexesOnWrite()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldCacheBloomsOnWrite()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldEvictOnClose()"], ["void", "org.apache.hadoop.hbase.io.hfile.CacheConfig.setEvictOnClose(boolean)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldCacheDataCompressed()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldCacheCompressed(org.apache.hadoop.hbase.io.hfile.BlockType$BlockCategory)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldPrefetchOnOpen()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldReadBlockFromCache(org.apache.hadoop.hbase.io.hfile.BlockType)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.CacheConfig.shouldLockOnCacheMiss(org.apache.hadoop.hbase.io.hfile.BlockType)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.CacheConfig.toString()"], ["org.apache.hadoop.hbase.io.hfile.CacheStats", "org.apache.hadoop.hbase.io.hfile.CacheConfig.getL1Stats()"], ["org.apache.hadoop.hbase.io.hfile.CacheStats", "org.apache.hadoop.hbase.io.hfile.CacheConfig.getL2Stats()"], ["synchronized", "org.apache.hadoop.hbase.io.hfile.CacheConfig.org.apache.hadoop.hbase.io.hfile.BlockCache instantiateBlockCache(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader", "org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader(long, org.apache.hadoop.hbase.fs.HFileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock$BlockIterator", "org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader.blockRange(long, long)"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock", "org.apache.hadoop.hbase.io.hfile.HFileBlock(org.apache.hadoop.hbase.io.hfile.BlockType, int, int, long, java.nio.ByteBuffer, boolean, long, int, int, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getNextBlockOnDiskSize()"], ["org.apache.hadoop.hbase.io.hfile.BlockType", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getBlockType()"], ["short", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getDataBlockEncodingId()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getOnDiskSizeWithHeader()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getUncompressedSizeWithoutHeader()"], ["java.nio.ByteBuffer", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getBufferWithoutHeader()"], ["java.nio.ByteBuffer", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getBufferReadOnly()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.HFileBlock.toString()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileBlock.isUnpacked()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlock.sanityCheckUncompressedSize()"], ["java.io.DataInputStream", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getByteStream()"], ["long", "org.apache.hadoop.hbase.io.hfile.HFileBlock.heapSize()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getSerializedLength()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileBlock.serialize(java.nio.ByteBuffer, boolean)"], ["java.nio.ByteBuffer", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getMetaData()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlock.hashCode()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFileBlock.equals(java.lang.Object)"], ["org.apache.hadoop.hbase.io.encoding.DataBlockEncoding", "org.apache.hadoop.hbase.io.hfile.HFileBlock.getDataBlockEncoding()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlock.headerSize()"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlock.headerSize(boolean)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileReaderV2$1.run()"], ["org.apache.hadoop.hbase.io.hfile.HFileReaderV3", "org.apache.hadoop.hbase.io.hfile.HFileReaderV3(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.hfile.FixedFileTrailer, org.apache.hadoop.hbase.io.FSDataInputStreamWrapper, long, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.fs.HFileSystem, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.HFileScanner", "org.apache.hadoop.hbase.io.hfile.HFileReaderV3.getScanner(boolean, boolean, boolean)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileReaderV3.getMajorVersion()"], ["org.apache.hadoop.hbase.io.hfile.HFile$Writer", "org.apache.hadoop.hbase.io.hfile.HFileWriterV2$WriterFactoryV2.createWriter(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FSDataOutputStream, org.apache.hadoop.hbase.KeyValue$KVComparator, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["org.apache.hadoop.hbase.io.hfile.HFileWriterV3", "org.apache.hadoop.hbase.io.hfile.HFileWriterV3(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FSDataOutputStream, org.apache.hadoop.hbase.KeyValue$KVComparator, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileWriterV3.append(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket(org.apache.hadoop.hbase.io.hfile.LruBlockCache, java.lang.String, long, long, long)"], ["void", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket.add(org.apache.hadoop.hbase.io.hfile.LruCachedBlock)"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket.free(long)"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket.overflow()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket.totalSize()"], ["int", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket.compareTo(org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket.hashCode()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket.toString()"], ["int", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$BlockBucket.compareTo(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.encode(org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext, java.io.DataOutputStream)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.useEncodedScanner()"], ["void", "org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.saveMetadata(org.apache.hadoop.hbase.io.hfile.HFile$Writer)"], ["org.apache.hadoop.hbase.io.encoding.DataBlockEncoding", "org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.getDataBlockEncoding()"], ["org.apache.hadoop.hbase.io.encoding.DataBlockEncoding", "org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.getEffectiveEncodingInCache(boolean)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.toString()"], ["org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext", "org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.newDataBlockEncodingContext(byte[], org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["org.apache.hadoop.hbase.io.encoding.HFileBlockDecodingContext", "org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.newDataBlockDecodingContext(org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["void", "org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.startBlockEncoding(org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext, java.io.DataOutputStream)"], ["void", "org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.endBlockEncoding(org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext, java.io.DataOutputStream, byte[], org.apache.hadoop.hbase.io.hfile.BlockType)"], ["org.apache.hadoop.hbase.ipc.RpcExecutor", "org.apache.hadoop.hbase.ipc.RpcExecutor(java.lang.String, int, int)"], ["org.apache.hadoop.hbase.ipc.RpcExecutor", "org.apache.hadoop.hbase.ipc.RpcExecutor(java.lang.String, int, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.ipc.RpcExecutor", "org.apache.hadoop.hbase.ipc.RpcExecutor(java.lang.String, int, int, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["org.apache.hadoop.hbase.ipc.RpcExecutor", "org.apache.hadoop.hbase.ipc.RpcExecutor(java.lang.String, int, java.lang.String, int, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["void", "org.apache.hadoop.hbase.ipc.RpcExecutor.start(int)"], ["void", "org.apache.hadoop.hbase.ipc.RpcExecutor.stop()"], ["org.apache.hadoop.hbase.ipc.RpcExecutor$QueueBalancer", "org.apache.hadoop.hbase.ipc.RpcExecutor.getBalancer(int)"], ["boolean", "org.apache.hadoop.hbase.ipc.RpcExecutor.isDeadlineQueueType(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.ipc.RpcExecutor.isCodelQueueType(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.ipc.RpcExecutor.isFifoQueueType(java.lang.String)"], ["long", "org.apache.hadoop.hbase.ipc.RpcExecutor.getNumGeneralCallsDropped()"], ["long", "org.apache.hadoop.hbase.ipc.RpcExecutor.getNumLifoModeSwitches()"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor.getActiveHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor.getActiveWriteHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor.getActiveReadHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor.getActiveScanHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor.getQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor.getReadQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor.getScanQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.RpcExecutor.getWriteQueueLength()"], ["java.lang.String", "org.apache.hadoop.hbase.ipc.RpcExecutor.getName()"], ["void", "org.apache.hadoop.hbase.ipc.RpcExecutor.resizeQueues(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.ipc.RpcExecutor.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.mapred.Driver", "org.apache.hadoop.hbase.mapred.Driver()"], ["void", "org.apache.hadoop.hbase.mapred.Driver.main(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.CellCounter$CellCounterMapper.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.io.Text, org.apache.hadoop.io.IntWritable>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.CellCounter$CellCounterMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["org.apache.hadoop.hbase.mapreduce.HFileOutputFormat", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat()"], ["org.apache.hadoop.mapreduce.RecordWriter<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.KeyValue>", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.configureIncrementalLoad(org.apache.hadoop.mapreduce.Job, org.apache.hadoop.hbase.client.HTable)"], ["org.apache.hadoop.hbase.mapreduce.Import$Importer", "org.apache.hadoop.hbase.mapreduce.Import$Importer()"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$Importer.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Mutation>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$Importer.setup(org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Mutation>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$Importer.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["org.apache.hadoop.hbase.mapreduce.Import$KeyValueSortImporter", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueSortImporter()"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueSortImporter.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable, org.apache.hadoop.hbase.KeyValue>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueSortImporter.setup(org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable, org.apache.hadoop.hbase.KeyValue>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueSortImporter.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["org.apache.hadoop.hbase.mapreduce.JarFinder", "org.apache.hadoop.hbase.mapreduce.JarFinder()"], ["void", "org.apache.hadoop.hbase.mapreduce.JarFinder.jarDir(java.io.File, java.lang.String, java.util.zip.ZipOutputStream)"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.JarFinder.getJar(java.lang.Class)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$4.call(int)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$4.call(int)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordReader.close()"], ["float", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordReader.getProgress()"], ["void", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordReader.initialize(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["boolean", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordReader.nextKeyValue()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordReader.getCurrentKey()"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordReader.getCurrentValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordReader.getCurrentValue()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordReader.getCurrentKey()"], ["org.apache.hadoop.mapreduce.Counter", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapStatusReporter.getCounter(java.lang.Enum<?>)"], ["org.apache.hadoop.mapreduce.Counter", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapStatusReporter.getCounter(java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapStatusReporter.progress()"], ["void", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapStatusReporter.setStatus(java.lang.String)"], ["float", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapStatusReporter.getProgress()"], ["org.apache.hadoop.hbase.mapreduce.PutSortReducer", "org.apache.hadoop.hbase.mapreduce.PutSortReducer()"], ["void", "org.apache.hadoop.hbase.mapreduce.RowCounter$RowCounterMapper.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.RowCounter$RowCounterMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["org.apache.hadoop.hbase.mapreduce.TableInputFormatBase", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase()"], ["org.apache.hadoop.mapreduce.RecordReader<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.createRecordReader(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["byte[]", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.getSplitKey(byte[], byte[], boolean)"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.reverseDNS(java.net.InetAddress)"], ["org.apache.hadoop.hbase.client.Scan", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.getScan()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.setScan(org.apache.hadoop.hbase.client.Scan)"], ["org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit()"], ["org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, java.util.List<java.lang.String>, org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit.getHtd()"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit.getScan()"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit.getRestoreDir()"], ["long", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit.getLength()"], ["java.lang.String[]", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit.getLocations()"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit.getTableDescriptor()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit.getRegionInfo()"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit.write(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit.readFields(java.io.DataInput)"], ["org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit()"], ["org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit(java.lang.String, long, long, long)"], ["long", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit.getLength()"], ["java.lang.String[]", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit.getLocations()"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit.getLogFileName()"], ["long", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit.getStartTime()"], ["long", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit.getEndTime()"], ["void", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit.readFields(java.io.DataInput)"], ["void", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit.write(java.io.DataOutput)"], ["java.lang.String", "org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALSplit.toString()"], ["org.apache.hadoop.hbase.master.AssignmentManager$DelayedAssignCallable", "org.apache.hadoop.hbase.master.AssignmentManager$DelayedAssignCallable(java.util.concurrent.Callable<?>)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$DelayedAssignCallable.run()"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action$Type[]", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action$Type.values()"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action$Type", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$Action$Type.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$LocalityType[]", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$LocalityType.values()"], ["org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$LocalityType", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster$LocalityType.valueOf(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.tablesOnMaster(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.userTablesOnMaster(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.setConf(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.shouldBeOnMaster(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.getConf()"], ["synchronized", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.void setClusterStatus(org.apache.hadoop.hbase.ClusterStatus)"], ["void", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.setMasterServices(org.apache.hadoop.hbase.master.MasterServices)"], ["void", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.postMasterStartupInitialize()"], ["void", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.setRackManager(org.apache.hadoop.hbase.master.RackManager)"], ["java.util.Map<org.apache.hadoop.hbase.ServerName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>>", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.roundRobinAssignment(java.util.List<org.apache.hadoop.hbase.HRegionInfo>, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["java.util.Map<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName>", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.immediateAssignment(java.util.List<org.apache.hadoop.hbase.HRegionInfo>, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.randomAssignment(org.apache.hadoop.hbase.HRegionInfo, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["java.util.Map<org.apache.hadoop.hbase.ServerName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>>", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.retainAssignment(java.util.Map<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName>, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["void", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.initialize()"], ["void", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.regionOnline(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.regionOffline(org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.isStopped()"], ["void", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.stop(java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.master.CatalogJanitor$1.processRow(org.apache.hadoop.hbase.client.Result)"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.BaseFileCleanerDelegate$1.apply(org.apache.hadoop.fs.FileStatus)"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.BaseFileCleanerDelegate$1.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.master.cleaner.BaseLogCleanerDelegate", "org.apache.hadoop.hbase.master.cleaner.BaseLogCleanerDelegate()"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.BaseLogCleanerDelegate.isFileDeletable(org.apache.hadoop.fs.FileStatus)"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.BaseLogCleanerDelegate.isLogDeletable(org.apache.hadoop.fs.FileStatus)"], ["org.apache.hadoop.hbase.master.cleaner.ReplicationZKLockCleanerChore", "org.apache.hadoop.hbase.master.cleaner.ReplicationZKLockCleanerChore(org.apache.hadoop.hbase.Stoppable, org.apache.hadoop.hbase.Abortable, int, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleanerChore", "org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleanerChore(org.apache.hadoop.hbase.Stoppable, int, org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner)"], ["int", "org.apache.hadoop.hbase.master.DeadServer$1.compare(org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.ServerName, java.lang.Long>, org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.ServerName, java.lang.Long>)"], ["int", "org.apache.hadoop.hbase.master.DeadServer$1.compare(java.lang.Object, java.lang.Object)"], ["void", "org.apache.hadoop.hbase.master.GeneralBulkAssigner$1.uncaughtException(java.lang.Thread, java.lang.Throwable)"], ["void", "org.apache.hadoop.hbase.master.GeneralBulkAssigner$SingleServerBulkAssigner.run()"], ["org.apache.hadoop.hbase.master.HMaster$PeriodicDoMetrics", "org.apache.hadoop.hbase.master.HMaster$PeriodicDoMetrics(int, org.apache.hadoop.hbase.master.HMaster)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$10.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$105.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$107.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$113.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$15.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$17.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$23.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$30.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$38.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$45.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$49.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$5.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$52.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$53.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$63.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$76.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$83.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$84.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$98.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["boolean", "org.apache.hadoop.hbase.master.MasterFileSystem$2.accept(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.master.MetricsSnapshot", "org.apache.hadoop.hbase.master.MetricsSnapshot()"], ["void", "org.apache.hadoop.hbase.master.MetricsSnapshot.addSnapshot(long)"], ["void", "org.apache.hadoop.hbase.master.MetricsSnapshot.addSnapshotRestore(long)"], ["void", "org.apache.hadoop.hbase.master.MetricsSnapshot.addSnapshotClone(long)"], ["org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure()"], ["org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, byte[])"], ["boolean", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.deserializeStateData(java.io.InputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.abort(java.lang.Object)"], ["org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure()"], ["org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["void", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.deserializeStateData(java.io.InputStream)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.abort(java.lang.Object)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv(org.apache.hadoop.hbase.master.MasterServices)"], ["org.apache.hadoop.hbase.security.User", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.getRequestUser()"], ["org.apache.hadoop.hbase.master.MasterServices", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.getMasterServices()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.getMasterConfiguration()"], ["org.apache.hadoop.hbase.master.MasterCoprocessorHost", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.getMasterCoprocessorHost()"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.getProcedureQueue()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.isRunning()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.isInitialized()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.waitInitialized(org.apache.hadoop.hbase.procedure2.Procedure)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.waitServerCrashProcessingEnabled(org.apache.hadoop.hbase.procedure2.Procedure)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.wake(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.suspend(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.setEventReady(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent, boolean)"], ["org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure()"], ["org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.deserializeStateData(java.io.InputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.abort(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait$2.evaluate()"], ["org.apache.hadoop.hbase.master.procedure.ServerProcedureInterface$ServerOperationType[]", "org.apache.hadoop.hbase.master.procedure.ServerProcedureInterface$ServerOperationType.values()"], ["org.apache.hadoop.hbase.master.procedure.ServerProcedureInterface$ServerOperationType", "org.apache.hadoop.hbase.master.procedure.ServerProcedureInterface$ServerOperationType.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor, boolean)"], ["org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.prepare()"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.isFinished()"], ["long", "org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.getCompletionTimestamp()"], ["org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription", "org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.getSnapshot()"], ["void", "org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.cancel(java.lang.String)"], ["org.apache.hadoop.hbase.errorhandling.ForeignException", "org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.getExceptionIfFailed()"], ["void", "org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.rethrowExceptionIfFailed()"], ["org.apache.hadoop.hbase.master.handler.CreateTableHandler", "org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.prepare()"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.prepare()"], ["org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$RefreshCacheTask", "org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$RefreshCacheTask(org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache)"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$RefreshCacheTask.run()"], ["org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner", "org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner()"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.setConf(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.isStopped()"], ["org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache", "org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.getFileCacheForTesting()"], ["boolean", "org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta$1.visit(org.apache.hadoop.hbase.client.Result)"], ["org.apache.hadoop.hbase.master.SplitLogManager$TerminationStatus[]", "org.apache.hadoop.hbase.master.SplitLogManager$TerminationStatus.values()"], ["org.apache.hadoop.hbase.master.SplitLogManager$TerminationStatus", "org.apache.hadoop.hbase.master.SplitLogManager$TerminationStatus.valueOf(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.master.SplitLogManager$TerminationStatus.toString()"], ["org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager$TableLockImpl", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager$TableLockImpl(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.ServerName, long, boolean, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager$TableLockImpl.acquire()"], ["void", "org.apache.hadoop.hbase.master.TableLockManager$ZKTableLockManager$TableLockImpl.release()"], ["org.apache.hadoop.hbase.monitoring.LogMonitoring", "org.apache.hadoop.hbase.monitoring.LogMonitoring()"], ["void", "org.apache.hadoop.hbase.monitoring.LogMonitoring.dumpTailOfLogs(java.io.PrintWriter, long)"], ["org.apache.hadoop.hbase.monitoring.TaskMonitor$PassthroughInvocationHandler", "org.apache.hadoop.hbase.monitoring.TaskMonitor$PassthroughInvocationHandler(T)"], ["java.lang.Object", "org.apache.hadoop.hbase.monitoring.TaskMonitor$PassthroughInvocationHandler.invoke(java.lang.Object, java.lang.reflect.Method, java.lang.Object[])"], ["org.apache.hadoop.hbase.procedure.MasterProcedureManager", "org.apache.hadoop.hbase.procedure.MasterProcedureManager()"], ["void", "org.apache.hadoop.hbase.procedure.MasterProcedureManager.execProcedure(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$ProcedureDescription)"], ["byte[]", "org.apache.hadoop.hbase.procedure.MasterProcedureManager.execProcedureWithRet(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$ProcedureDescription)"], ["org.apache.hadoop.hbase.procedure.ProcedureManagerHost", "org.apache.hadoop.hbase.procedure.ProcedureManagerHost()"], ["E", "org.apache.hadoop.hbase.procedure.ProcedureManagerHost.loadInstance(java.lang.Class<?>)"], ["void", "org.apache.hadoop.hbase.procedure.ProcedureManagerHost.register(E)"], ["org.apache.hadoop.hbase.procedure.ZKProcedureUtil", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.close()"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.getAcquiredBarrierNode(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.getReachedBarrierNode(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.getAbortZNode(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.getAbortZnode()"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.getBaseZnode()"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.getAcquiredBarrier()"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.getAcquireBarrierNode(org.apache.hadoop.hbase.procedure.ZKProcedureUtil, java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.getReachedBarrierNode(org.apache.hadoop.hbase.procedure.ZKProcedureUtil, java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.getAbortNode(org.apache.hadoop.hbase.procedure.ZKProcedureUtil, java.lang.String)"], ["org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.getWatcher()"], ["boolean", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.isAbortPathNode(java.lang.String)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.clearChildZNodes()"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureUtil.clearZNodes(java.lang.String)"], ["org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$4.fetch()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$4.update(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$4.delete()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$4.preApply(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$4.postApply(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["org.apache.hadoop.hbase.quotas.OperationQuota$OperationType[]", "org.apache.hadoop.hbase.quotas.OperationQuota$OperationType.values()"], ["org.apache.hadoop.hbase.quotas.OperationQuota$OperationType", "org.apache.hadoop.hbase.quotas.OperationQuota$OperationType.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.quotas.QuotaUtil$2.getKeyFromRow(byte[])"], ["java.lang.Object", "org.apache.hadoop.hbase.quotas.QuotaUtil$2.getKeyFromRow(byte[])"], ["org.apache.hadoop.hbase.regionserver.AbstractMultiFileWriter", "org.apache.hadoop.hbase.regionserver.AbstractMultiFileWriter()"], ["void", "org.apache.hadoop.hbase.regionserver.AbstractMultiFileWriter.init(org.apache.hadoop.hbase.regionserver.StoreScanner, org.apache.hadoop.hbase.regionserver.AbstractMultiFileWriter$WriterFactory)"], ["org.apache.hadoop.hbase.regionserver.CompactedHFilesDischarger", "org.apache.hadoop.hbase.regionserver.CompactedHFilesDischarger(int, org.apache.hadoop.hbase.Stoppable, org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["org.apache.hadoop.hbase.regionserver.CompactedHFilesDischarger", "org.apache.hadoop.hbase.regionserver.CompactedHFilesDischarger(int, org.apache.hadoop.hbase.Stoppable, org.apache.hadoop.hbase.regionserver.RegionServerServices, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactedHFilesDischarger.chore()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionContext", "org.apache.hadoop.hbase.regionserver.compactions.CompactionContext()"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionContext.forceSelect(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.CompactionContext.getRequest()"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.CompactionContext.hasSelection()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.updateFiles(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.beforeExecute()"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.afterExecute()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.combineWith(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["int", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.compareTo(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["int", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.hashCode()"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.equals(java.lang.Object)"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.setDescription(java.lang.String, java.lang.String)"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.getSize()"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.isAllFiles()"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.isMajor()"], ["int", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.getPriority()"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.setPriority(int)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.isOffPeak()"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.setOffPeak(boolean)"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.getSelectionTime()"], ["void", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.setIsMajor(boolean, boolean)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.toString()"], ["int", "org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress", "org.apache.hadoop.hbase.regionserver.compactions.Compactor.getProgress()"], ["org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor$1.createWriter(org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.compactions.Compactor$FileDetails, boolean)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor$1.createWriter(org.apache.hadoop.hbase.regionserver.InternalScanner, org.apache.hadoop.hbase.regionserver.compactions.Compactor$FileDetails, boolean)"], ["org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionWorker", "org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionWorker(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionWorker.compact(org.apache.hadoop.fs.Path, boolean, boolean)"], ["org.apache.hadoop.hbase.regionserver.DateTieredMultiFileWriter", "org.apache.hadoop.hbase.regionserver.DateTieredMultiFileWriter(java.util.List<java.lang.Long>, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.DateTieredMultiFileWriter.append(org.apache.hadoop.hbase.Cell)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.DefaultMemStore$MemStoreScanner.boolean seek(org.apache.hadoop.hbase.Cell)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.DefaultMemStore$MemStoreScanner.boolean reseek(org.apache.hadoop.hbase.Cell)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.DefaultMemStore$MemStoreScanner.org.apache.hadoop.hbase.Cell peek()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.DefaultMemStore$MemStoreScanner.org.apache.hadoop.hbase.Cell next()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.DefaultMemStore$MemStoreScanner.void close()"], ["long", "org.apache.hadoop.hbase.regionserver.DefaultMemStore$MemStoreScanner.getScannerOrder()"], ["boolean", "org.apache.hadoop.hbase.regionserver.DefaultMemStore$MemStoreScanner.shouldUseScanner(org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.Store, long)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.DefaultMemStore$MemStoreScanner.boolean backwardSeek(org.apache.hadoop.hbase.Cell)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.DefaultMemStore$MemStoreScanner.boolean seekToPreviousRow(org.apache.hadoop.hbase.Cell)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.DefaultMemStore$MemStoreScanner.boolean seekToLastRow()"], ["org.apache.hadoop.hbase.regionserver.FlushPolicyFactory", "org.apache.hadoop.hbase.regionserver.FlushPolicyFactory()"], ["org.apache.hadoop.hbase.regionserver.FlushPolicy", "org.apache.hadoop.hbase.regionserver.FlushPolicyFactory.create(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.conf.Configuration)"], ["java.lang.Class<? extends org.apache.hadoop.hbase.regionserver.FlushPolicy>", "org.apache.hadoop.hbase.regionserver.FlushPolicyFactory.getFlushPolicyClass(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.handler.ParallelSeekHandler", "org.apache.hadoop.hbase.regionserver.handler.ParallelSeekHandler(org.apache.hadoop.hbase.regionserver.KeyValueScanner, org.apache.hadoop.hbase.Cell, long, java.util.concurrent.CountDownLatch)"], ["void", "org.apache.hadoop.hbase.regionserver.handler.ParallelSeekHandler.process()"], ["java.lang.Throwable", "org.apache.hadoop.hbase.regionserver.handler.ParallelSeekHandler.getErr()"], ["void", "org.apache.hadoop.hbase.regionserver.handler.ParallelSeekHandler.setErr(java.lang.Throwable)"], ["org.apache.hadoop.hbase.regionserver.HeapMemoryManager", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.FlushRequester, org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerAccounting)"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager.start(org.apache.hadoop.hbase.ChoreService)"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager.stop()"], ["float", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager.getHeapOccupancyPercent()"], ["org.apache.hadoop.hbase.regionserver.HRegion$BatchOperationInProgress", "org.apache.hadoop.hbase.regionserver.HRegion$BatchOperationInProgress(T[])"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion$BatchOperationInProgress.isDone()"], ["int", "org.apache.hadoop.hbase.regionserver.HRegionServer$4.compare(java.lang.Long, java.lang.Long)"], ["int", "org.apache.hadoop.hbase.regionserver.HRegionServer$4.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.HRegionServer$PeriodicMemstoreFlusher", "org.apache.hadoop.hbase.regionserver.HRegionServer$PeriodicMemstoreFlusher(int, org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.regionserver.HStore$4.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.HStore$4.run()"], ["org.apache.hadoop.hbase.regionserver.Leases", "org.apache.hadoop.hbase.regionserver.Leases(int)"], ["void", "org.apache.hadoop.hbase.regionserver.Leases.run()"], ["void", "org.apache.hadoop.hbase.regionserver.Leases.closeAfterLeasesExpire()"], ["void", "org.apache.hadoop.hbase.regionserver.Leases.close()"], ["void", "org.apache.hadoop.hbase.regionserver.Leases.createLease(java.lang.String, int, org.apache.hadoop.hbase.regionserver.LeaseListener)"], ["void", "org.apache.hadoop.hbase.regionserver.Leases.addLease(org.apache.hadoop.hbase.regionserver.Leases$Lease)"], ["void", "org.apache.hadoop.hbase.regionserver.Leases.renewLease(java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.Leases.cancelLease(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.MemStoreChunkPool$StatisticsThread", "org.apache.hadoop.hbase.regionserver.MemStoreChunkPool$StatisticsThread(org.apache.hadoop.hbase.regionserver.MemStoreChunkPool)"], ["void", "org.apache.hadoop.hbase.regionserver.MemStoreChunkPool$StatisticsThread.run()"], ["boolean", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry.isMaximumWait(long)"], ["int", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry.getRequeueCount()"], ["boolean", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry.isForceFlushAllStores()"], ["org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry.requeue(long)"], ["long", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry.getDelay(java.util.concurrent.TimeUnit)"], ["int", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry.compareTo(java.util.concurrent.Delayed)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry.toString()"], ["int", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry.hashCode()"], ["boolean", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl$HRegionMetricsWrapperRunnable", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl$HRegionMetricsWrapperRunnable(org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl)"], ["void", "org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl$HRegionMetricsWrapperRunnable.run()"], ["void", "org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl$1.run()"], ["org.apache.hadoop.hbase.regionserver.NoOpHeapMemoryTuner", "org.apache.hadoop.hbase.regionserver.NoOpHeapMemoryTuner()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.regionserver.NoOpHeapMemoryTuner.getConf()"], ["void", "org.apache.hadoop.hbase.regionserver.NoOpHeapMemoryTuner.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerResult", "org.apache.hadoop.hbase.regionserver.NoOpHeapMemoryTuner.tune(org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerContext)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker", "org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker(java.util.NavigableSet<byte[]>, int, int, long)"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker.done()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount", "org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker.getColumnHint()"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker.checkColumn(byte[], int, int, byte)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker.checkVersions(byte[], int, int, long, byte, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker.reset()"], ["void", "org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker.doneWithColumn(byte[], int, int)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher$MatchCode", "org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker.getNextRowOrNextColumn(byte[], int, int)"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker.isDone(long)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.ScanDeleteTracker", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanDeleteTracker()"], ["void", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanDeleteTracker.add(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.DeleteTracker$DeleteResult", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanDeleteTracker.isDeleted(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanDeleteTracker.isEmpty()"], ["void", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanDeleteTracker.reset()"], ["void", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanDeleteTracker.update()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.getStartKey()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.currentRow()"], ["void", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.clearCurrentRow()"], ["void", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.setToNewRow(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.getKeyForNextColumn(org.apache.hadoop.hbase.Cell)"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.compareKeyForNextRow(org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.Cell)"], ["int", "org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.compareKeyForNextColumn(org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher.hasNullColumnInQuery()"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher.isUserScan()"], ["org.apache.hadoop.hbase.filter.Filter", "org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher.getFilter()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher.getNextKeyHint(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher.moreRowsMayExistAfter(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher", "org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher.create(org.apache.hadoop.hbase.client.Scan, org.apache.hadoop.hbase.regionserver.ScanInfo, java.util.NavigableSet<byte[]>, long, long, org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$13.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$16.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$23.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$25.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$32.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$4.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$47.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$49.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$60.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$68.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$EndpointOperation.hasCall(org.apache.hadoop.hbase.Coprocessor)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$EndpointOperation.call(org.apache.hadoop.hbase.Coprocessor, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$5.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$5.run()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$1.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$1.postEnvCall(org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$RegionServerEnvironment)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$4.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$7.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$9.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.regionserver.RegionServerServices$RegionStateTransitionContext", "org.apache.hadoop.hbase.regionserver.RegionServerServices$RegionStateTransitionContext(org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionStateTransition$TransitionCode, long, long, org.apache.hadoop.hbase.HRegionInfo...)"], ["org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionStateTransition$TransitionCode", "org.apache.hadoop.hbase.regionserver.RegionServerServices$RegionStateTransitionContext.getCode()"], ["long", "org.apache.hadoop.hbase.regionserver.RegionServerServices$RegionStateTransitionContext.getOpenSeqNum()"], ["long", "org.apache.hadoop.hbase.regionserver.RegionServerServices$RegionStateTransitionContext.getMasterSystemTime()"], ["org.apache.hadoop.hbase.HRegionInfo[]", "org.apache.hadoop.hbase.regionserver.RegionServerServices$RegionStateTransitionContext.getHris()"], ["void", "org.apache.hadoop.hbase.regionserver.RSRpcServices$1.logBatchWarning(java.lang.String, int, int)"], ["org.apache.hadoop.hbase.regionserver.ScanInfo", "org.apache.hadoop.hbase.regionserver.ScanInfo(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HColumnDescriptor, long, long, org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["org.apache.hadoop.hbase.regionserver.ScanInfo", "org.apache.hadoop.hbase.regionserver.ScanInfo(org.apache.hadoop.conf.Configuration, byte[], int, int, long, org.apache.hadoop.hbase.KeepDeletedCells, long, org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.regionserver.ScanInfo.getConfiguration()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.ScanInfo.getFamily()"], ["int", "org.apache.hadoop.hbase.regionserver.ScanInfo.getMinVersions()"], ["int", "org.apache.hadoop.hbase.regionserver.ScanInfo.getMaxVersions()"], ["long", "org.apache.hadoop.hbase.regionserver.ScanInfo.getTtl()"], ["org.apache.hadoop.hbase.KeepDeletedCells", "org.apache.hadoop.hbase.regionserver.ScanInfo.getKeepDeletedCells()"], ["long", "org.apache.hadoop.hbase.regionserver.ScanInfo.getTimeToPurgeDeletes()"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.regionserver.ScanInfo.getComparator()"], ["org.apache.hadoop.hbase.regionserver.ScannerIdGenerator", "org.apache.hadoop.hbase.regionserver.ScannerIdGenerator(org.apache.hadoop.hbase.ServerName)"], ["long", "org.apache.hadoop.hbase.regionserver.ScannerIdGenerator.generateNewScannerId()"], ["boolean", "org.apache.hadoop.hbase.regionserver.ShutdownHook$DoNothingStoppable.isStopped()"], ["void", "org.apache.hadoop.hbase.regionserver.ShutdownHook$DoNothingStoppable.stop(java.lang.String)"], ["org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure", "org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure(org.apache.hadoop.hbase.procedure.ProcedureMember, org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher, long, long, java.util.List<org.apache.hadoop.hbase.regionserver.Region>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager$SnapshotSubprocedurePool)"], ["void", "org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.acquireBarrier()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.insideBarrier()"], ["void", "org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.cleanup(java.lang.Exception)"], ["void", "org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.releaseBarrier()"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$5.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$5.run()"], ["org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy", "org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy()"], ["java.lang.Long", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators$GetMaxTimestamp.apply(org.apache.hadoop.hbase.regionserver.StoreFile)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators$GetMaxTimestamp.apply(java.lang.Object)"], ["java.lang.Long", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators$GetSeqId.apply(org.apache.hadoop.hbase.regionserver.StoreFile)"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.StoreFile$Comparators$GetSeqId.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.regionserver.StoreFlusher", "org.apache.hadoop.hbase.regionserver.StoreFlusher(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.Store)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StripeStoreEngine$StripeCompaction.select(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>, boolean, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.StripeStoreEngine$StripeCompaction.forceSelect(org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.StripeStoreFileManager", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager(org.apache.hadoop.hbase.KeyValue$KVComparator, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.StripeStoreConfig)"], ["void", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.loadFiles(java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["void", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.insertNewFiles(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["int", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.getStorefileCount()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.getSplitPoint()"], ["void", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.addCompactionResults(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["void", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.removeCompactedFiles(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["int", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.getStoreCompactionPriority()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.getStartRow(int)"], ["byte[]", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.getEndRow(int)"], ["int", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.getStripeCount()"], ["double", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.getCompactionPressure()"], ["java.util.Collection", "org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.clearCompactedFiles()"], ["org.apache.hadoop.hbase.regionserver.wal.Compressor", "org.apache.hadoop.hbase.regionserver.wal.Compressor()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.Compressor.main(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.registerWALActionsListener(org.apache.hadoop.hbase.regionserver.wal.WALActionsListener)"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.unregisterWALActionsListener(org.apache.hadoop.hbase.regionserver.wal.WALActionsListener)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.getCoprocessorHost()"], ["org.apache.hadoop.hbase.regionserver.wal.FSHLog", "org.apache.hadoop.hbase.regionserver.wal.FSHLog(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, java.lang.String, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.wal.FSHLog", "org.apache.hadoop.hbase.regionserver.wal.FSHLog(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, java.lang.String, java.lang.String, org.apache.hadoop.conf.Configuration, java.util.List<org.apache.hadoop.hbase.regionserver.wal.WALActionsListener>, boolean, java.lang.String, java.lang.String)"], ["byte[][]", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter()"], ["byte[][]", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(boolean)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.getWALArchivePath(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.getCurrentFileName()"], ["long", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.getFilenum()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.toString()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.close()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.shutdown()"], ["long", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.checkLogRoll()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.sync()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.sync(long)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.requestLogRoll()"], ["int", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.getNumRolledLogFiles()"], ["int", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.getNumLogFiles()"], ["long", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.getLogFileSize()"], ["java.lang.Long", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.startCacheFlush(byte[], java.util.Set<byte[]>)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.completeCacheFlush(byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.abortCacheFlush(byte[])"], ["long", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.getEarliestMemstoreSeqNum(byte[])"], ["long", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.getEarliestMemstoreSeqNum(byte[], byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.main(java.lang.String[])"], ["long", "org.apache.hadoop.hbase.regionserver.wal.FSHLog.getLastTimeCheckLowReplication()"], ["org.apache.hadoop.hbase.regionserver.wal.WriterBase", "org.apache.hadoop.hbase.regionserver.wal.WriterBase()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WriterBase.init(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.WriterBase.initializeCompressionContext(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.replication.ClusterMarkingEntryFilter", "org.apache.hadoop.hbase.replication.ClusterMarkingEntryFilter(java.util.UUID, java.util.UUID, org.apache.hadoop.hbase.replication.ReplicationEndpoint)"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.replication.ClusterMarkingEntryFilter.filter(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner$WarnOnlyAbortable", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner$WarnOnlyAbortable()"], ["void", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner$WarnOnlyAbortable.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner$WarnOnlyAbortable.isAborted()"], ["org.apache.hadoop.hbase.replication.master.TableCFsUpdater", "org.apache.hadoop.hbase.replication.master.TableCFsUpdater(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["void", "org.apache.hadoop.hbase.replication.master.TableCFsUpdater.update()"], ["boolean", "org.apache.hadoop.hbase.replication.master.TableCFsUpdater.update(java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.master.TableCFsUpdater.main(java.lang.String[])"], ["org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaSinkWriter", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaSinkWriter(org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaOutputSink, org.apache.hadoop.hbase.client.ClusterConnection, java.util.concurrent.ExecutorService, int)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaSinkWriter.append(org.apache.hadoop.hbase.TableName, byte[], byte[], java.util.List<org.apache.hadoop.hbase.wal.WAL$Entry>)"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager(org.apache.hadoop.hbase.client.HConnection, java.lang.String, org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint, org.apache.hadoop.conf.Configuration)"], ["synchronized", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager$SinkPeer getReplicationSink()"], ["synchronized", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.void reportBadSink(org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager$SinkPeer)"], ["synchronized", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.void reportSinkSuccess(org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager$SinkPeer)"], ["synchronized", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.void chooseSinks()"], ["synchronized", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.int getNumSinks()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceShipperThread", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceShipperThread(java.lang.String, java.util.concurrent.PriorityBlockingQueue<org.apache.hadoop.fs.Path>, org.apache.hadoop.hbase.replication.ReplicationQueueInfo, org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceShipperThread.run()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceShipperThread.startup()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceShipperThread.getCurrentPath()"], ["long", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceShipperThread.getCurrentPosition()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceShipperThread.setWorkerState(org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$WorkerState)"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$WorkerState", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceShipperThread.getWorkerState()"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.getConfiguration()"], ["org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.getZooKeeper()"], ["org.apache.hadoop.hbase.CoordinatedStateManager", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.getCoordinatedStateManager()"], ["org.apache.hadoop.hbase.zookeeper.MetaTableLocator", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.getMetaTableLocator()"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.getServerName()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.isAborted()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.isStopped()"], ["org.apache.hadoop.hbase.client.ClusterConnection", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.getConnection()"], ["org.apache.hadoop.hbase.ChoreService", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp$DummyServer.getChoreService()"], ["org.apache.hadoop.hbase.replication.regionserver.WALEntryStream", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream(java.util.concurrent.PriorityBlockingQueue<org.apache.hadoop.fs.Path>, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.replication.regionserver.MetricsSource)"], ["org.apache.hadoop.hbase.replication.regionserver.WALEntryStream", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream(java.util.concurrent.PriorityBlockingQueue<org.apache.hadoop.fs.Path>, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration, long, org.apache.hadoop.hbase.replication.regionserver.MetricsSource)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.hasNext()"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.next()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.remove()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.close()"], ["long", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.getPosition()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.getCurrentPath()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.reset()"], ["java.lang.Object", "org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.next()"], ["java.lang.Void", "org.apache.hadoop.hbase.security.access.AccessController$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$1.run()"], ["java.lang.Void", "org.apache.hadoop.hbase.security.access.AccessController$4.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$4.run()"], ["org.apache.hadoop.hbase.security.access.AccessControlLists", "org.apache.hadoop.hbase.security.access.AccessControlLists()"], ["com.google.common.collect.ListMultimap<java.lang.String, org.apache.hadoop.hbase.security.access.TablePermission>", "org.apache.hadoop.hbase.security.access.AccessControlLists.getTablePermissions(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.TableName)"], ["com.google.common.collect.ListMultimap<java.lang.String, org.apache.hadoop.hbase.security.access.TablePermission>", "org.apache.hadoop.hbase.security.access.AccessControlLists.getNamespacePermissions(org.apache.hadoop.conf.Configuration, java.lang.String)"], ["byte[]", "org.apache.hadoop.hbase.security.access.AccessControlLists.writePermissionsAsBytes(com.google.common.collect.ListMultimap<java.lang.String, org.apache.hadoop.hbase.security.access.TablePermission>, org.apache.hadoop.conf.Configuration)"], ["com.google.common.collect.ListMultimap<java.lang.String, org.apache.hadoop.hbase.security.access.TablePermission>", "org.apache.hadoop.hbase.security.access.AccessControlLists.readPermissions(byte[], org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessControlLists.isNamespaceEntry(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.security.access.AccessControlLists.isNamespaceEntry(byte[])"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.AccessControlLists.toNamespaceEntry(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.AccessControlLists.fromNamespaceEntry(java.lang.String)"], ["byte[]", "org.apache.hadoop.hbase.security.access.AccessControlLists.toNamespaceEntry(byte[])"], ["byte[]", "org.apache.hadoop.hbase.security.access.AccessControlLists.fromNamespaceEntry(byte[])"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher$2.run()"], ["org.apache.hadoop.hbase.security.HBaseSaslRpcServer$SaslDigestCallbackHandler", "org.apache.hadoop.hbase.security.HBaseSaslRpcServer$SaslDigestCallbackHandler(org.apache.hadoop.security.token.SecretManager<org.apache.hadoop.security.token.TokenIdentifier>, org.apache.hadoop.hbase.ipc.RpcServer$Connection)"], ["void", "org.apache.hadoop.hbase.security.HBaseSaslRpcServer$SaslDigestCallbackHandler.handle(javax.security.auth.callback.Callback[])"], ["org.apache.hadoop.hbase.security.visibility.DefinedSetFilterScanLabelGenerator", "org.apache.hadoop.hbase.security.visibility.DefinedSetFilterScanLabelGenerator()"], ["void", "org.apache.hadoop.hbase.security.visibility.DefinedSetFilterScanLabelGenerator.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.security.visibility.DefinedSetFilterScanLabelGenerator.getConf()"], ["org.apache.hadoop.hbase.security.visibility.FeedUserAuthScanLabelGenerator", "org.apache.hadoop.hbase.security.visibility.FeedUserAuthScanLabelGenerator()"], ["void", "org.apache.hadoop.hbase.security.visibility.FeedUserAuthScanLabelGenerator.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.security.visibility.FeedUserAuthScanLabelGenerator.getConf()"], ["org.apache.hadoop.hbase.security.visibility.SimpleScanLabelGenerator", "org.apache.hadoop.hbase.security.visibility.SimpleScanLabelGenerator()"], ["void", "org.apache.hadoop.hbase.security.visibility.SimpleScanLabelGenerator.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.security.visibility.SimpleScanLabelGenerator.getConf()"], ["synchronized", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache createAndGet(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.get()"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.refreshLabelsCache(byte[])"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.refreshUserAuthsCache(byte[])"], ["int", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.getLabelOrdinal(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.getLabel(int)"], ["int", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.getLabelsCount()"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.writeToZookeeper(byte[], boolean)"], ["void", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$1.storeFile(org.apache.hadoop.hbase.HRegionInfo, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile)"], ["void", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$2.editRegion(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.snapshot.SnapshotManifest, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher, org.apache.hadoop.hbase.monitoring.MonitoredTask)"], ["org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.snapshot.SnapshotManifest, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher, org.apache.hadoop.hbase.monitoring.MonitoredTask, boolean)"], ["org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$RestoreMetaChanges", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.restoreHdfsRegions()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.cloneRegionInfo(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.cloneRegionInfo(org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$RestoreMetaChanges", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.copySnapshotForScanner(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, java.lang.String)"], ["void", "org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.restoreSnapshotACL(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.TableName, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$Builder", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder.regionOpen(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder.regionClose(org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$Builder)"], ["org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$FamilyFiles$Builder", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder.familyOpen(org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$Builder, byte[])"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder.familyClose(org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$Builder, org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$FamilyFiles$Builder)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder.storeFile(org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$Builder, org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$FamilyFiles$Builder, org.apache.hadoop.hbase.regionserver.StoreFileInfo)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder.storeFile(java.lang.Object, java.lang.Object, org.apache.hadoop.hbase.regionserver.StoreFileInfo)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder.familyClose(java.lang.Object, java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder.familyOpen(java.lang.Object, byte[])"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder.regionClose(java.lang.Object)"], ["java.lang.Object", "org.apache.hadoop.hbase.snapshot.SnapshotManifestV2$ManifestBuilder.regionOpen(org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.SplitLogTask$Unassigned", "org.apache.hadoop.hbase.SplitLogTask$Unassigned(org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$SplitLogTask$RecoveryMode)"], ["void", "org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl$1.renderTo(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmplImpl", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmplImpl(org.jamon.TemplateManager, org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl$ImplData)"], ["void", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmplImpl.renderNoFlush(java.io.Writer)"], ["void", "org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl$1.renderTo(java.io.Writer)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl$1.renderTo(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl(org.jamon.TemplateManager)"], ["org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl()"], ["org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.setBcv(java.lang.String)"], ["org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.setFormat(java.lang.String)"], ["org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.setBcn(java.lang.String)"], ["org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.setFilter(java.lang.String)"], ["org.jamon.AbstractTemplateImpl", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.constructImpl(java.lang.Class<? extends org.jamon.AbstractTemplateImpl>)"], ["org.jamon.Renderer", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.makeRenderer(org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.render(java.io.Writer, org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.renderNoFlush(java.io.Writer, org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["org.jamon.AbstractTemplateProxy$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.getImplData()"], ["org.apache.hadoop.hbase.tool.Canary$RegionMonitor", "org.apache.hadoop.hbase.tool.Canary$RegionMonitor(org.apache.hadoop.hbase.client.Connection, java.lang.String[], boolean, org.apache.hadoop.hbase.tool.Canary$StdOutSink, java.util.concurrent.ExecutorService, boolean, org.apache.hadoop.hbase.TableName, boolean, java.util.HashMap<java.lang.String, java.lang.Long>, long)"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionMonitor.run()"], ["org.apache.hadoop.hbase.tool.Canary$ZookeeperStdOutSink", "org.apache.hadoop.hbase.tool.Canary$ZookeeperStdOutSink()"], ["void", "org.apache.hadoop.hbase.tool.Canary$ZookeeperStdOutSink.publishReadFailure(java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.tool.Canary$ZookeeperStdOutSink.publishReadTiming(java.lang.String, java.lang.String, long)"], ["org.apache.hadoop.hbase.util.BloomFilter", "org.apache.hadoop.hbase.util.BloomFilterFactory.createFromMeta(java.io.DataInput, org.apache.hadoop.hbase.io.hfile.HFile$Reader)"], ["boolean", "org.apache.hadoop.hbase.util.BloomFilterFactory.isGeneralBloomEnabled(org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.util.BloomFilterFactory.isDeleteFamilyBloomEnabled(org.apache.hadoop.conf.Configuration)"], ["float", "org.apache.hadoop.hbase.util.BloomFilterFactory.getErrorRate(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.util.BloomFilterFactory.getMaxFold(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.util.BloomFilterFactory.getBloomBlockSize(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.util.BloomFilterFactory.getMaxKeys(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.util.BloomFilterWriter", "org.apache.hadoop.hbase.util.BloomFilterFactory.createGeneralBloomAtWrite(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.hbase.regionserver.BloomType, int, org.apache.hadoop.hbase.io.hfile.HFile$Writer)"], ["org.apache.hadoop.hbase.util.BloomFilterWriter", "org.apache.hadoop.hbase.util.BloomFilterFactory.createDeleteBloomAtWrite(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.hfile.CacheConfig, int, org.apache.hadoop.hbase.io.hfile.HFile$Writer)"], ["org.apache.hadoop.hbase.util.CollectionBackedScanner", "org.apache.hadoop.hbase.util.CollectionBackedScanner(java.util.SortedSet<org.apache.hadoop.hbase.Cell>)"], ["org.apache.hadoop.hbase.util.CollectionBackedScanner", "org.apache.hadoop.hbase.util.CollectionBackedScanner(java.util.SortedSet<org.apache.hadoop.hbase.Cell>, org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["org.apache.hadoop.hbase.util.CollectionBackedScanner", "org.apache.hadoop.hbase.util.CollectionBackedScanner(java.util.List<org.apache.hadoop.hbase.Cell>)"], ["org.apache.hadoop.hbase.util.CollectionBackedScanner", "org.apache.hadoop.hbase.util.CollectionBackedScanner(java.util.List<org.apache.hadoop.hbase.Cell>, org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["org.apache.hadoop.hbase.util.CollectionBackedScanner", "org.apache.hadoop.hbase.util.CollectionBackedScanner(org.apache.hadoop.hbase.KeyValue$KVComparator, org.apache.hadoop.hbase.Cell...)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.util.CollectionBackedScanner.peek()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.util.CollectionBackedScanner.next()"], ["boolean", "org.apache.hadoop.hbase.util.CollectionBackedScanner.seek(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.util.CollectionBackedScanner.reseek(org.apache.hadoop.hbase.Cell)"], ["long", "org.apache.hadoop.hbase.util.CollectionBackedScanner.getScannerOrder()"], ["void", "org.apache.hadoop.hbase.util.CollectionBackedScanner.close()"], ["org.apache.hadoop.hbase.util.CompressionTest", "org.apache.hadoop.hbase.util.CompressionTest()"], ["boolean", "org.apache.hadoop.hbase.util.CompressionTest.testCompression(java.lang.String)"], ["void", "org.apache.hadoop.hbase.util.CompressionTest.testCompression(org.apache.hadoop.hbase.io.compress.Compression$Algorithm)"], ["void", "org.apache.hadoop.hbase.util.CompressionTest.usage()"], ["void", "org.apache.hadoop.hbase.util.CompressionTest.doSmokeTest(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, java.lang.String)"], ["void", "org.apache.hadoop.hbase.util.CompressionTest.main(java.lang.String[])"], ["org.apache.hadoop.hbase.util.FSHDFSUtils", "org.apache.hadoop.hbase.util.FSHDFSUtils()"], ["boolean", "org.apache.hadoop.hbase.util.FSHDFSUtils.isSameHdfs(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.FileSystem)"], ["void", "org.apache.hadoop.hbase.util.FSHDFSUtils.recoverFileLease(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["org.apache.hadoop.hbase.util.FSUtils$HFileFilter", "org.apache.hadoop.hbase.util.FSUtils$HFileFilter(org.apache.hadoop.fs.FileSystem)"], ["void", "org.apache.hadoop.hbase.util.FSVisitor.visitTableStoreFiles(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.FSVisitor$StoreFileVisitor)"], ["void", "org.apache.hadoop.hbase.util.FSVisitor.visitRegionStoreFiles(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.FSVisitor$StoreFileVisitor)"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck$4$1.compare(org.apache.hadoop.hbase.Cell, org.apache.hadoop.hbase.Cell)"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck$4$1.compare(java.lang.Object, java.lang.Object)"], ["int", "org.apache.hadoop.hbase.util.HBaseFsck$HBaseFsckTool.run(java.lang.String[])"], ["java.lang.String", "org.apache.hadoop.hbase.util.HBaseFsck$RegionBoundariesInformation.toString()"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$HDFSIntegrityFixer.handleRegionStartKeyNotEmpty(org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo)"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$HDFSIntegrityFixer.handleRegionEndKeyNotEmpty(byte[])"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$HDFSIntegrityFixer.handleHoleInRegionChain(byte[], byte[])"], ["void", "org.apache.hadoop.hbase.util.HBaseFsck$TableInfo$HDFSIntegrityFixer.handleOverlapGroup(java.util.Collection<org.apache.hadoop.hbase.util.HBaseFsck$HbckInfo>)"], ["java.lang.Void", "org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker$RegionDirChecker.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker$RegionDirChecker.call()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.util.HFileV1Detector$1.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.util.HFileV1Detector$1.call()"], ["java.lang.String", "org.apache.hadoop.hbase.util.IdLock$Entry.toString()"], ["java.lang.String", "org.apache.hadoop.hbase.util.JvmPauseMonitor$GcTimes.toString()"], ["org.apache.hadoop.hbase.util.LeaseNotRecoveredException", "org.apache.hadoop.hbase.util.LeaseNotRecoveredException()"], ["org.apache.hadoop.hbase.util.LeaseNotRecoveredException", "org.apache.hadoop.hbase.util.LeaseNotRecoveredException(java.lang.String)"], ["org.apache.hadoop.hbase.util.LeaseNotRecoveredException", "org.apache.hadoop.hbase.util.LeaseNotRecoveredException(java.lang.String, java.lang.Throwable)"], ["org.apache.hadoop.hbase.util.LeaseNotRecoveredException", "org.apache.hadoop.hbase.util.LeaseNotRecoveredException(java.lang.Throwable)"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.util.ModifyRegionUtils$1.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.util.ModifyRegionUtils$1.call()"], ["org.apache.hadoop.hbase.HRegionInfo[]", "org.apache.hadoop.hbase.util.ModifyRegionUtils.createHRegionInfos(org.apache.hadoop.hbase.HTableDescriptor, byte[][])"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.util.ModifyRegionUtils.createRegion(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.util.ModifyRegionUtils$RegionFillTask)"], ["void", "org.apache.hadoop.hbase.util.ModifyRegionUtils.editRegions(java.util.concurrent.ThreadPoolExecutor, java.util.Collection<org.apache.hadoop.hbase.HRegionInfo>, org.apache.hadoop.hbase.util.ModifyRegionUtils$RegionEditTask)"], ["void", "org.apache.hadoop.hbase.util.ModifyRegionUtils.assignRegions(org.apache.hadoop.hbase.master.AssignmentManager, java.util.List<org.apache.hadoop.hbase.HRegionInfo>)"], ["org.apache.hadoop.hbase.util.RegionSplitter$HexStringSplit", "org.apache.hadoop.hbase.util.RegionSplitter$HexStringSplit()"], ["org.apache.hadoop.hbase.util.ShutdownHookManager", "org.apache.hadoop.hbase.util.ShutdownHookManager()"], ["void", "org.apache.hadoop.hbase.util.ShutdownHookManager.affixShutdownHook(java.lang.Thread, int)"], ["boolean", "org.apache.hadoop.hbase.util.ShutdownHookManager.deleteShutdownHook(java.lang.Runnable)"], ["org.apache.hadoop.hbase.util.ZKDataMigrator", "org.apache.hadoop.hbase.util.ZKDataMigrator()"], ["int", "org.apache.hadoop.hbase.util.ZKDataMigrator.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.util.ZKDataMigrator.main(java.lang.String[])"], ["org.apache.hadoop.hbase.wal.RegionGroupingProvider", "org.apache.hadoop.hbase.wal.RegionGroupingProvider()"], ["void", "org.apache.hadoop.hbase.wal.RegionGroupingProvider.init(org.apache.hadoop.hbase.wal.WALFactory, org.apache.hadoop.conf.Configuration, java.util.List<org.apache.hadoop.hbase.regionserver.wal.WALActionsListener>, java.lang.String)"], ["org.apache.hadoop.hbase.wal.WAL", "org.apache.hadoop.hbase.wal.RegionGroupingProvider.getWAL(byte[], byte[])"], ["void", "org.apache.hadoop.hbase.wal.RegionGroupingProvider.shutdown()"], ["void", "org.apache.hadoop.hbase.wal.RegionGroupingProvider.close()"], ["long", "org.apache.hadoop.hbase.wal.RegionGroupingProvider.getNumLogFiles()"], ["long", "org.apache.hadoop.hbase.wal.RegionGroupingProvider.getLogFileSize()"], ["boolean", "org.apache.hadoop.hbase.wal.WALSplitter$1.accept(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink", "org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink(org.apache.hadoop.hbase.wal.WALSplitter, org.apache.hadoop.hbase.wal.WALSplitter$PipelineController, org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers, int)"], ["void", "org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink.append(org.apache.hadoop.hbase.wal.WALSplitter$RegionEntryBuffer)"], ["boolean", "org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink.keepRegionEvent(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["java.util.Map<byte[], java.lang.Long>", "org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink.getOutputCounts()"], ["int", "org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink.getNumberOfRecoveredRegions()"], ["org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker", "org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.Abortable)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.isClusterUp()"], ["void", "org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.setClusterUp()"], ["void", "org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.setClusterDown()"], ["org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase$AcquiredLock", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase$AcquiredLock(java.lang.String, int)"], ["java.lang.String", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase$AcquiredLock.getPath()"], ["int", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase$AcquiredLock.getVersion()"], ["java.lang.String", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase$AcquiredLock.toString()"], ["org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessWriteLock", "org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessWriteLock(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, java.lang.String, byte[], org.apache.hadoop.hbase.InterProcessLock$MetadataHandler)"], ["org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker", "org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Abortable)"], ["void", "org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker.start()"], ["boolean", "org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker.isSplitOrMergeEnabled(org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["void", "org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker.setSplitOrMergeEnabled(boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["void", "org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.start()"], ["void", "org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.nodeChildrenChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.nodeDeleted(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.keepHFiles(java.lang.String)"], ["org.apache.hadoop.hbase.backup.example.HFileArchiveTableMonitor", "org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.getMonitor()"], ["org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker", "org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.create(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher", "org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.getZooKeeperWatcher()"], ["void", "org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.stop()"], ["org.apache.hadoop.hbase.client.coprocessor.RowProcessorClient", "org.apache.hadoop.hbase.client.coprocessor.RowProcessorClient()"], ["<S extends com.google.protobuf.Message, T extends com.google.protobuf.Message> org.apache.hadoop.hbase.protobuf.generated.RowProcessorProtos$ProcessRequest", "org.apache.hadoop.hbase.client.coprocessor.RowProcessorClient.getRowProcessorPB(org.apache.hadoop.hbase.regionserver.RowProcessor<S, T>)"], ["void", "org.apache.hadoop.hbase.codec.MessageCodec$MessageEncoder.write(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.constraint.ConstraintProcessor", "org.apache.hadoop.hbase.constraint.ConstraintProcessor()"], ["void", "org.apache.hadoop.hbase.constraint.ConstraintProcessor.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.constraint.ConstraintProcessor.prePut(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, org.apache.hadoop.hbase.client.Put, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.client.Durability)"], ["org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination$SplitLogManagerDetails", "org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination$SplitLogManagerDetails(java.util.concurrent.ConcurrentMap<java.lang.String, org.apache.hadoop.hbase.master.SplitLogManager$Task>, org.apache.hadoop.hbase.master.MasterServices, java.util.Set<java.lang.String>, org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.master.MasterServices", "org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination$SplitLogManagerDetails.getMaster()"], ["java.util.concurrent.ConcurrentMap<java.lang.String, org.apache.hadoop.hbase.master.SplitLogManager$Task>", "org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination$SplitLogManagerDetails.getTasks()"], ["org.apache.hadoop.hbase.ServerName", "org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination$SplitLogManagerDetails.getServerName()"], ["org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination$ZkRegionMergeDetails", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination$ZkRegionMergeDetails()"], ["int", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination$ZkRegionMergeDetails.getZnodeVersion()"], ["void", "org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination$ZkRegionMergeDetails.setZnodeVersion(int)"], ["boolean", "org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination$1.progress()"], ["org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver()"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preCreateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postCreateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preDispatchMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postDispatchMerge(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preGetClusterStatus(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postGetClusterStatus(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.ClusterStatus)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preClearDeadServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postClearDeadServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.ServerName>, java.util.List<org.apache.hadoop.hbase.ServerName>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preCreateTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postCreateTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preDeleteTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postDeleteTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preDeleteTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postDeleteTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preTruncateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postTruncateTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preTruncateTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postTruncateTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preModifyTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postModifyTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preModifyTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postModifyTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preCreateNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postCreateNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preDeleteNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postDeleteNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preModifyNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postModifyNamespace(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preGetNamespaceDescriptor(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postGetNamespaceDescriptor(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preListNamespaceDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.NamespaceDescriptor>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postListNamespaceDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.NamespaceDescriptor>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preAddColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postAddColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preAddColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postAddColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preModifyColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postModifyColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preModifyColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postModifyColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preDeleteColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postDeleteColumn(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preDeleteColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postDeleteColumnHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, byte[])"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preEnableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postEnableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preEnableTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postEnableTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preDisableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postDisableTable(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preDisableTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postDisableTableHandler(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preAbortProcedure(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.procedure2.ProcedureExecutor<org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv>, long)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postAbortProcedure(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preListProcedures(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postListProcedures(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.ProcedureInfo>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preAssign(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postAssign(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preUnassign(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postUnassign(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preRegionOffline(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postRegionOffline(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preBalance(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postBalance(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.master.RegionPlan>)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preSetSplitOrMergeEnabled(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postSetSplitOrMergeEnabled(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean, org.apache.hadoop.hbase.client.Admin$MasterSwitchType)"], ["boolean", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preBalanceSwitch(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postBalanceSwitch(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preShutdown(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preStopMaster(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postStartMaster(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preMasterInitialization(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preMove(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postMove(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preListSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postListSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preCloneSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postCloneSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preRestoreSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postRestoreSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preDeleteSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postDeleteSnapshot(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preGetTableDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postGetTableDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preGetTableDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postGetTableDescriptors(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.TableName>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preGetTableNames(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postGetTableNames(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.List<org.apache.hadoop.hbase.HTableDescriptor>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preTableFlush(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postTableFlush(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postSetUserQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preSetTableQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postSetTableQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preSetNamespaceQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postSetNamespaceQuota(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos$Quotas)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postAddRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postBalanceRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String, boolean)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postMoveServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postMoveTables(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preMoveServersAndTables(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postMoveServersAndTables(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postRemoveRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preAddRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preBalanceRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preMoveServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preMoveTables(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.TableName>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preRemoveRSGroup(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.lang.String)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.preRemoveServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>)"], ["void", "org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.postRemoveServers(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>, java.util.Set<org.apache.hadoop.hbase.net.Address>)"], ["int", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$1.compare(java.lang.Class<? extends org.apache.hadoop.hbase.Coprocessor>, java.lang.Class<? extends org.apache.hadoop.hbase.Coprocessor>)"], ["int", "org.apache.hadoop.hbase.coprocessor.CoprocessorHost$1.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint", "org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint()"], ["void", "org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.mutateRows(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.MultiRowMutationProtos$MutateRowsRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.MultiRowMutationProtos$MutateRowsResponse>)"], ["com.google.protobuf.Service", "org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.getService()"], ["void", "org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector$1.run()"], ["void", "org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks.reorderBlocks(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.protocol.LocatedBlocks, java.lang.String)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$1.compare(java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>, java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$1.compare(java.lang.Object, java.lang.Object)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$6.compare(java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>, java.util.Map$Entry<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.RegionLoad>)"], ["int", "org.apache.hadoop.hbase.generated.master.table_jsp$6.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.generated.master.zk_jsp", "org.apache.hadoop.hbase.generated.master.zk_jsp()"], ["java.lang.Object", "org.apache.hadoop.hbase.generated.master.zk_jsp.getDependants()"], ["void", "org.apache.hadoop.hbase.generated.master.zk_jsp._jspService(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"], ["org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus[]", "org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus.values()"], ["org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus", "org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.http.FilterInitializer", "org.apache.hadoop.hbase.http.FilterInitializer()"], ["org.apache.hadoop.hbase.http.HtmlQuoting", "org.apache.hadoop.hbase.http.HtmlQuoting()"], ["boolean", "org.apache.hadoop.hbase.http.HtmlQuoting.needsQuoting(byte[], int, int)"], ["boolean", "org.apache.hadoop.hbase.http.HtmlQuoting.needsQuoting(java.lang.String)"], ["void", "org.apache.hadoop.hbase.http.HtmlQuoting.quoteHtmlChars(java.io.OutputStream, byte[], int, int)"], ["java.lang.String", "org.apache.hadoop.hbase.http.HtmlQuoting.quoteHtmlChars(java.lang.String)"], ["java.io.OutputStream", "org.apache.hadoop.hbase.http.HtmlQuoting.quoteOutputStream(java.io.OutputStream)"], ["java.lang.String", "org.apache.hadoop.hbase.http.HtmlQuoting.unquoteHtmlChars(java.lang.String)"], ["void", "org.apache.hadoop.hbase.http.HtmlQuoting.main(java.lang.String[])"], ["org.apache.hadoop.hbase.http.HttpConfig", "org.apache.hadoop.hbase.http.HttpConfig(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.http.HttpConfig.setPolicy(org.apache.hadoop.hbase.http.HttpConfig$Policy)"], ["boolean", "org.apache.hadoop.hbase.http.HttpConfig.isSecure()"], ["java.lang.String", "org.apache.hadoop.hbase.http.HttpConfig.getSchemePrefix()"], ["java.lang.String", "org.apache.hadoop.hbase.http.HttpConfig.getScheme(org.apache.hadoop.hbase.http.HttpConfig$Policy)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder()"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.addEndpoint(java.net.URI)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.hostName(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.trustStore(java.lang.String, java.lang.String, java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.keyStore(java.lang.String, java.lang.String, java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.keyPassword(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.needsClientAuth(boolean)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setName(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setBindAddress(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setPort(int)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setFindPort(boolean)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setConnector(org.mortbay.jetty.Connector)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setPathSpec(java.lang.String[])"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setACL(org.apache.hadoop.security.authorize.AccessControlList)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setSecurityEnabled(boolean)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setUsernameConfKey(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setKeytabConfKey(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setKerberosNameRulesKey(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setSignatureSecretFileKey(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setAppDir(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer$Builder", "org.apache.hadoop.hbase.http.HttpServer$Builder.setLogDir(java.lang.String)"], ["org.apache.hadoop.hbase.http.HttpServer", "org.apache.hadoop.hbase.http.HttpServer$Builder.build()"], ["org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter()"], ["void", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter.destroy()"], ["void", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(javax.servlet.ServletRequest, javax.servlet.ServletResponse, javax.servlet.FilterChain)"], ["void", "org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter.init(javax.servlet.FilterConfig)"], ["java.io.OutputStream", "org.apache.hadoop.hbase.io.DataOutputOutputStream.constructOutputStream(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.io.DataOutputOutputStream.write(int)"], ["void", "org.apache.hadoop.hbase.io.DataOutputOutputStream.write(byte[], int, int)"], ["void", "org.apache.hadoop.hbase.io.DataOutputOutputStream.write(byte[])"], ["java.nio.ByteBuffer", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.getKey()"], ["java.lang.String", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.getKeyString()"], ["java.nio.ByteBuffer", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.getValue()"], ["java.lang.String", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.getValueString()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.getKeyValue()"], ["boolean", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.next()"], ["boolean", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekBefore(byte[])"], ["boolean", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekBefore(byte[], int, int)"], ["boolean", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo()"], ["int", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo(byte[])"], ["int", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo(byte[], int, int)"], ["int", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.reseekTo(byte[])"], ["int", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.reseekTo(byte[], int, int)"], ["org.apache.hadoop.hbase.io.hfile.HFile$Reader", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.getReader()"], ["boolean", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.isSeeked()"], ["int", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo(org.apache.hadoop.hbase.Cell)"], ["int", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.reseekTo(org.apache.hadoop.hbase.Cell)"], ["boolean", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekBefore(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.getNextIndexedKey()"], ["void", "org.apache.hadoop.hbase.io.HalfStoreFileReader$1.close()"], ["org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter", "org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter(org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.fs.FSDataOutputStream, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.KeyValue$KVComparator, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["void", "org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.appendFileInfo(byte[], byte[])"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.getPath()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.toString()"], ["org.apache.hadoop.hbase.io.compress.Compression$Algorithm", "org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.compressionByName(java.lang.String)"], ["int", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlockCountsPerFile.getCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlockCountsPerFile.getSize()"], ["int", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlockCountsPerFile.getCountData()"], ["long", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlockCountsPerFile.getSizeData()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.BlockCacheUtil$CachedBlockCountsPerFile.getFilename()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics.freeCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics.usedCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics.totalCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics.freeBytes()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics.usedBytes()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics.totalBytes()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics.itemSize()"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics(long, long, long)"], ["org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator$IndexStatistics.setTo(long, long, long)"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry.getLength()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry.access(long)"], ["org.apache.hadoop.hbase.io.hfile.BlockPriority", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry.getPriority()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry.getCachedTime()"], ["org.apache.hadoop.hbase.io.hfile.bucket.CachedEntryQueue", "org.apache.hadoop.hbase.io.hfile.bucket.CachedEntryQueue(long, long)"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.CachedEntryQueue.add(java.util.Map$Entry<org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry>)"], ["java.util.Map$Entry<org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry>", "org.apache.hadoop.hbase.io.hfile.bucket.CachedEntryQueue.poll()"], ["java.util.Map$Entry<org.apache.hadoop.hbase.io.hfile.BlockCacheKey, org.apache.hadoop.hbase.io.hfile.bucket.BucketCache$BucketEntry>", "org.apache.hadoop.hbase.io.hfile.bucket.CachedEntryQueue.pollLast()"], ["long", "org.apache.hadoop.hbase.io.hfile.bucket.CachedEntryQueue.cacheSize()"], ["org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine", "org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine(long, java.lang.String...)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.toString()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.isPersistent()"], ["int", "org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.read(java.nio.ByteBuffer, long)"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.write(java.nio.ByteBuffer, long)"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.sync()"], ["void", "org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.shutdown()"], ["org.apache.hadoop.hbase.io.hfile.CorruptHFileException", "org.apache.hadoop.hbase.io.hfile.CorruptHFileException(java.lang.String, java.lang.Throwable)"], ["org.apache.hadoop.hbase.io.hfile.CorruptHFileException", "org.apache.hadoop.hbase.io.hfile.CorruptHFileException(java.lang.String)"], ["org.apache.hadoop.hbase.io.hfile.HFile", "org.apache.hadoop.hbase.io.hfile.HFile()"], ["long", "org.apache.hadoop.hbase.io.hfile.HFile.getAndResetChecksumFailuresCount()"], ["long", "org.apache.hadoop.hbase.io.hfile.HFile.getChecksumFailuresCount()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFile.updateReadLatency(long, boolean)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFile.updateWriteLatency(long)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFile.getFormatVersion(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory", "org.apache.hadoop.hbase.io.hfile.HFile.getWriterFactoryNoCache(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory", "org.apache.hadoop.hbase.io.hfile.HFile.getWriterFactory(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.io.hfile.CacheConfig)"], ["org.apache.hadoop.hbase.io.hfile.HFile$Reader", "org.apache.hadoop.hbase.io.hfile.HFile.createReader(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.FSDataInputStreamWrapper, long, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.io.hfile.HFile$Reader", "org.apache.hadoop.hbase.io.hfile.HFile.createReader(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFile.isHFileFormat(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFile.isHFileFormat(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.FileStatus)"], ["boolean", "org.apache.hadoop.hbase.io.hfile.HFile.isReservedFileInfoKey(byte[])"], ["java.lang.String[]", "org.apache.hadoop.hbase.io.hfile.HFile.getSupportedCompressionAlgorithms()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFile.checkFormatVersion(int)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFile.main(java.lang.String[])"], ["org.apache.hadoop.hbase.io.hfile.HFileBlock$Writer", "org.apache.hadoop.hbase.io.hfile.HFileBlock$Writer(org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoder, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["int", "org.apache.hadoop.hbase.io.hfile.HFileBlock$Writer.encodedBlockSizeWritten()"], ["void", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter$KeyValueStatsCollector.collect(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter$KeyValueStatsCollector.finish()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter$KeyValueStatsCollector.toString()"], ["org.apache.hadoop.hbase.io.hfile.HFileReaderV3$EncodedScannerV3", "org.apache.hadoop.hbase.io.hfile.HFileReaderV3$EncodedScannerV3(org.apache.hadoop.hbase.io.hfile.HFileReaderV3, boolean, boolean, boolean, org.apache.hadoop.hbase.io.hfile.HFileContext)"], ["void", "org.apache.hadoop.hbase.io.hfile.HFileUtil.seekOnMultipleSources(org.apache.hadoop.fs.FSDataInputStream, long)"], ["org.apache.hadoop.hbase.io.hfile.InvalidHFileException", "org.apache.hadoop.hbase.io.hfile.InvalidHFileException()"], ["org.apache.hadoop.hbase.io.hfile.InvalidHFileException", "org.apache.hadoop.hbase.io.hfile.InvalidHFileException(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.toString()"], ["org.apache.hadoop.hbase.io.hfile.BlockPriority", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.getBlockPriority()"], ["org.apache.hadoop.hbase.io.hfile.BlockType", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.getBlockType()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.getOffset()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.getSize()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.getCachedTime()"], ["java.lang.String", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.getFilename()"], ["int", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.compareTo(org.apache.hadoop.hbase.io.hfile.CachedBlock)"], ["int", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.hashCode()"], ["boolean", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.io.hfile.LruBlockCache$1$1.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.io.hfile.LruCachedBlockQueue", "org.apache.hadoop.hbase.io.hfile.LruCachedBlockQueue(long, long)"], ["void", "org.apache.hadoop.hbase.io.hfile.LruCachedBlockQueue.add(org.apache.hadoop.hbase.io.hfile.LruCachedBlock)"], ["org.apache.hadoop.hbase.io.hfile.LruCachedBlock", "org.apache.hadoop.hbase.io.hfile.LruCachedBlockQueue.poll()"], ["org.apache.hadoop.hbase.io.hfile.LruCachedBlock", "org.apache.hadoop.hbase.io.hfile.LruCachedBlockQueue.pollLast()"], ["long", "org.apache.hadoop.hbase.io.hfile.LruCachedBlockQueue.heapSize()"], ["org.apache.hadoop.hbase.io.HFileLink", "org.apache.hadoop.hbase.io.HFileLink(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.io.HFileLink", "org.apache.hadoop.hbase.io.HFileLink.buildFromHFileLinkPattern(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.io.HFileLink", "org.apache.hadoop.hbase.io.HFileLink.buildFromHFileLinkPattern(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.io.HFileLink.createPath(org.apache.hadoop.hbase.TableName, java.lang.String, java.lang.String, java.lang.String)"], ["org.apache.hadoop.hbase.io.HFileLink", "org.apache.hadoop.hbase.io.HFileLink.build(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.TableName, java.lang.String, java.lang.String, java.lang.String)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.io.HFileLink.getOriginPath()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.io.HFileLink.getArchivePath()"], ["boolean", "org.apache.hadoop.hbase.io.HFileLink.isHFileLink(org.apache.hadoop.fs.Path)"], ["boolean", "org.apache.hadoop.hbase.io.HFileLink.isHFileLink(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.io.HFileLink.getReferencedHFileName(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.io.HFileLink.getReferencedRegionName(java.lang.String)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.io.HFileLink.getReferencedTableName(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.io.HFileLink.createHFileLinkName(org.apache.hadoop.hbase.HRegionInfo, java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.io.HFileLink.createHFileLinkName(org.apache.hadoop.hbase.TableName, java.lang.String, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.io.HFileLink.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.io.HFileLink.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo, java.lang.String, boolean)"], ["boolean", "org.apache.hadoop.hbase.io.HFileLink.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.TableName, java.lang.String, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.io.HFileLink.create(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.TableName, java.lang.String, java.lang.String, boolean)"], ["boolean", "org.apache.hadoop.hbase.io.HFileLink.createFromHFileLink(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.io.HFileLink.createFromHFileLink(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, java.lang.String, boolean)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.io.HFileLink.getHFileFromBackReference(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.io.HFileLink.getHFileFromBackReference(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path)"], ["long", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getTotalQueueSize()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getGeneralQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getReplicationQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getPriorityQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getNumOpenConnections()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getActiveRpcHandlerCount()"], ["long", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getNumGeneralCallsDropped()"], ["long", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getNumLifoModeSwitches()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getWriteQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getReadQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getScanQueueLength()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getActiveWriteRpcHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getActiveReadRpcHandlerCount()"], ["int", "org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.getActiveScanRpcHandlerCount()"], ["org.apache.hadoop.hbase.ipc.RpcExecutor$QueueBalancer", "org.apache.hadoop.hbase.ipc.RpcExecutor$QueueBalancer()"], ["org.apache.hadoop.hbase.ipc.RpcServer$BlockingServiceAndInterface", "org.apache.hadoop.hbase.ipc.RpcServer$BlockingServiceAndInterface(com.google.protobuf.BlockingService, java.lang.Class<?>)"], ["com.google.protobuf.BlockingService", "org.apache.hadoop.hbase.ipc.RpcServer$BlockingServiceAndInterface.getBlockingService()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer$Responder.run()"], ["void", "org.apache.hadoop.hbase.ipc.RpcServer$Responder.registerForWrite(org.apache.hadoop.hbase.ipc.RpcServer$Connection)"], ["org.apache.hadoop.hbase.mapred.GroupingTableMap", "org.apache.hadoop.hbase.mapred.GroupingTableMap()"], ["void", "org.apache.hadoop.hbase.mapred.GroupingTableMap.initJob(java.lang.String, java.lang.String, java.lang.String, java.lang.Class<? extends org.apache.hadoop.hbase.mapred.TableMap>, org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.GroupingTableMap.configure(org.apache.hadoop.mapred.JobConf)"], ["void", "org.apache.hadoop.hbase.mapred.GroupingTableMap.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapred.OutputCollector<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>, org.apache.hadoop.mapred.Reporter)"], ["void", "org.apache.hadoop.hbase.mapred.GroupingTableMap.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapred.OutputCollector, org.apache.hadoop.mapred.Reporter)"], ["org.apache.hadoop.hbase.mapred.IdentityTableReduce", "org.apache.hadoop.hbase.mapred.IdentityTableReduce()"], ["void", "org.apache.hadoop.hbase.mapred.IdentityTableReduce.reduce(org.apache.hadoop.hbase.io.ImmutableBytesWritable, java.util.Iterator<org.apache.hadoop.hbase.client.Put>, org.apache.hadoop.mapred.OutputCollector<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Put>, org.apache.hadoop.mapred.Reporter)"], ["void", "org.apache.hadoop.hbase.mapred.IdentityTableReduce.reduce(java.lang.Object, java.util.Iterator, org.apache.hadoop.mapred.OutputCollector, org.apache.hadoop.mapred.Reporter)"], ["org.apache.hadoop.hbase.mapred.TableInputFormatBase", "org.apache.hadoop.hbase.mapred.TableInputFormatBase()"], ["org.apache.hadoop.mapred.RecordReader<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>", "org.apache.hadoop.hbase.mapred.TableInputFormatBase.getRecordReader(org.apache.hadoop.mapred.InputSplit, org.apache.hadoop.mapred.JobConf, org.apache.hadoop.mapred.Reporter)"], ["org.apache.hadoop.mapred.InputSplit[]", "org.apache.hadoop.hbase.mapred.TableInputFormatBase.getSplits(org.apache.hadoop.mapred.JobConf, int)"], ["org.apache.hadoop.hbase.mapred.TableSplit", "org.apache.hadoop.hbase.mapred.TableSplit()"], ["org.apache.hadoop.hbase.mapred.TableSplit", "org.apache.hadoop.hbase.mapred.TableSplit(org.apache.hadoop.hbase.TableName, byte[], byte[], java.lang.String)"], ["org.apache.hadoop.hbase.mapred.TableSplit", "org.apache.hadoop.hbase.mapred.TableSplit(byte[], byte[], byte[], java.lang.String)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.mapred.TableSplit.getTable()"], ["byte[]", "org.apache.hadoop.hbase.mapred.TableSplit.getTableName()"], ["byte[]", "org.apache.hadoop.hbase.mapred.TableSplit.getStartRow()"], ["byte[]", "org.apache.hadoop.hbase.mapred.TableSplit.getEndRow()"], ["java.lang.String", "org.apache.hadoop.hbase.mapred.TableSplit.getRegionLocation()"], ["java.lang.String[]", "org.apache.hadoop.hbase.mapred.TableSplit.getLocations()"], ["long", "org.apache.hadoop.hbase.mapred.TableSplit.getLength()"], ["void", "org.apache.hadoop.hbase.mapred.TableSplit.readFields(java.io.DataInput)"], ["void", "org.apache.hadoop.hbase.mapred.TableSplit.write(java.io.DataOutput)"], ["java.lang.String", "org.apache.hadoop.hbase.mapred.TableSplit.toString()"], ["int", "org.apache.hadoop.hbase.mapred.TableSplit.compareTo(org.apache.hadoop.hbase.mapred.TableSplit)"], ["boolean", "org.apache.hadoop.hbase.mapred.TableSplit.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.mapred.TableSplit.hashCode()"], ["int", "org.apache.hadoop.hbase.mapred.TableSplit.compareTo(java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.Driver", "org.apache.hadoop.hbase.mapreduce.Driver()"], ["void", "org.apache.hadoop.hbase.mapreduce.Driver.main(java.lang.String[])"], ["boolean", "org.apache.hadoop.hbase.mapreduce.HashTable$TableHash$Reader.next()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.HashTable$TableHash$Reader.getCurrentKey()"], ["org.apache.hadoop.hbase.io.ImmutableBytesWritable", "org.apache.hadoop.hbase.mapreduce.HashTable$TableHash$Reader.getCurrentHash()"], ["void", "org.apache.hadoop.hbase.mapreduce.HashTable$TableHash$Reader.close()"], ["org.apache.hadoop.hbase.regionserver.wal.HLogKey", "org.apache.hadoop.hbase.mapreduce.HLogInputFormat$HLogKeyRecordReader.getCurrentKey()"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.HLogInputFormat$HLogKeyRecordReader.getCurrentKey()"], ["org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable$KeyValueWritableComparator", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable$KeyValueWritableComparator()"], ["int", "org.apache.hadoop.hbase.mapreduce.Import$KeyValueWritableComparable$KeyValueWritableComparator.compare(byte[], int, int, byte[], int, int)"], ["org.apache.hadoop.hbase.mapreduce.ImportTsv", "org.apache.hadoop.hbase.mapreduce.ImportTsv()"], ["int", "org.apache.hadoop.hbase.mapreduce.ImportTsv.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.mapreduce.ImportTsv.main(java.lang.String[])"], ["org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase()"], ["org.apache.hadoop.mapreduce.RecordReader<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result>", "org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase.createRecordReader(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper()"], ["int", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper.getNumberOfThreads(org.apache.hadoop.mapreduce.JobContext)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper.setNumberOfThreads(org.apache.hadoop.mapreduce.Job, int)"], ["<K2, V2> java.lang.Class<org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, K2, V2>>", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper.getMapperClass(org.apache.hadoop.mapreduce.JobContext)"], ["<K2, V2> void", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper.setMapperClass(org.apache.hadoop.mapreduce.Job, java.lang.Class<? extends org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, K2, V2>>)"], ["void", "org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper.run(org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, K2, V2>.Context)"], ["java.lang.Void", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier$1.connect(org.apache.hadoop.hbase.client.HConnection)"], ["java.lang.Object", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier$1.connect(org.apache.hadoop.hbase.client.HConnection)"], ["org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier()"], ["void", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier.map(org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Result, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.client.Put>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$ResultSerializer.close()"], ["void", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$ResultSerializer.open(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$ResultSerializer.serialize(org.apache.hadoop.hbase.client.Result)"], ["void", "org.apache.hadoop.hbase.mapreduce.ResultSerialization$ResultSerializer.serialize(java.lang.Object)"], ["org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner", "org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner()"], ["void", "org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.setStartKey(org.apache.hadoop.conf.Configuration, byte[])"], ["void", "org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.setEndKey(org.apache.hadoop.conf.Configuration, byte[])"], ["int", "org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.getPartition(org.apache.hadoop.hbase.io.ImmutableBytesWritable, VALUE, int)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.getConf()"], ["void", "org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.setConf(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.getPartition(java.lang.Object, java.lang.Object, int)"], ["org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl()"], ["org.apache.hadoop.hbase.util.RegionSplitter$SplitAlgorithm", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl.getSplitAlgo(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.snapshot.SnapshotManifest", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl.getSnapshotManifest(org.apache.hadoop.conf.Configuration, java.lang.String, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FileSystem)"], ["org.apache.hadoop.hbase.client.Scan", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl.extractScanFromConf(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl.setInput(org.apache.hadoop.conf.Configuration, java.lang.String, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl.setInput(org.apache.hadoop.conf.Configuration, java.lang.String, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.util.RegionSplitter$SplitAlgorithm, int)"], ["void", "org.apache.hadoop.hbase.mapreduce.WALPlayer$WALKeyValueMapper.map(org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.KeyValue>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.WALPlayer$WALKeyValueMapper.setup(org.apache.hadoop.mapreduce.Mapper<org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit, org.apache.hadoop.hbase.io.ImmutableBytesWritable, org.apache.hadoop.hbase.KeyValue>.Context)"], ["void", "org.apache.hadoop.hbase.mapreduce.WALPlayer$WALKeyValueMapper.map(java.lang.Object, java.lang.Object, org.apache.hadoop.mapreduce.Mapper$Context)"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$1.run()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$3.process()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$6.run()"], ["void", "org.apache.hadoop.hbase.master.AssignmentManager$9.run()"], ["java.lang.String", "org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$DefaultRackManager.getRack(org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.master.balancer.ClusterStatusChore", "org.apache.hadoop.hbase.master.balancer.ClusterStatusChore(org.apache.hadoop.hbase.master.HMaster, org.apache.hadoop.hbase.master.LoadBalancer)"], ["org.apache.hadoop.hbase.master.balancer.LoadBalancerFactory", "org.apache.hadoop.hbase.master.balancer.LoadBalancerFactory()"], ["java.lang.Class<? extends org.apache.hadoop.hbase.master.LoadBalancer>", "org.apache.hadoop.hbase.master.balancer.LoadBalancerFactory.getDefaultLoadBalancerClass()"], ["org.apache.hadoop.hbase.master.LoadBalancer", "org.apache.hadoop.hbase.master.balancer.LoadBalancerFactory.getLoadBalancer(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.master.balancer.MetricsStochasticBalancer", "org.apache.hadoop.hbase.master.balancer.MetricsStochasticBalancer()"], ["void", "org.apache.hadoop.hbase.master.balancer.MetricsStochasticBalancer.balanceCluster(long)"], ["void", "org.apache.hadoop.hbase.master.balancer.MetricsStochasticBalancer.incrMiscInvocations()"], ["void", "org.apache.hadoop.hbase.master.balancer.MetricsStochasticBalancer.updateMetricsSize(int)"], ["void", "org.apache.hadoop.hbase.master.balancer.MetricsStochasticBalancer.updateStochasticCost(java.lang.String, java.lang.String, java.lang.String, java.lang.Double)"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder$1$1.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.balancer.RegionLocationFinder$1$1.call()"], ["org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer", "org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer()"], ["org.apache.hadoop.hbase.master.BulkReOpen", "org.apache.hadoop.hbase.master.BulkReOpen(org.apache.hadoop.hbase.Server, java.util.Map<org.apache.hadoop.hbase.ServerName, java.util.List<org.apache.hadoop.hbase.HRegionInfo>>, org.apache.hadoop.hbase.master.AssignmentManager)"], ["boolean", "org.apache.hadoop.hbase.master.BulkReOpen.bulkReOpen()"], ["boolean", "org.apache.hadoop.hbase.master.cleaner.CleanerChore$CleanerTask$1.accept(org.apache.hadoop.fs.FileStatus)"], ["java.lang.Void", "org.apache.hadoop.hbase.master.handler.CreateTableHandler$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.handler.CreateTableHandler$1.run()"], ["org.apache.hadoop.hbase.master.handler.OpenedRegionHandler", "org.apache.hadoop.hbase.master.handler.OpenedRegionHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.master.AssignmentManager, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.coordination.OpenRegionCoordination, org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails)"], ["int", "org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.getPriority()"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.getHRegionInfo()"], ["java.lang.String", "org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.toString()"], ["void", "org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.process()"], ["org.apache.hadoop.hbase.master.HMasterCommandLine", "org.apache.hadoop.hbase.master.HMasterCommandLine(java.lang.Class<? extends org.apache.hadoop.hbase.master.HMaster>)"], ["int", "org.apache.hadoop.hbase.master.HMasterCommandLine.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$106.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$108.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$114.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$116.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$18.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$24.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$26.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$33.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$46.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$48.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$6.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$62.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$64.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$71.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$79.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$81.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$89.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterCoprocessorHost$9.call(org.apache.hadoop.hbase.coprocessor.MasterObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.master.MasterRpcServices$1.run(com.google.protobuf.Message)"], ["void", "org.apache.hadoop.hbase.master.MasterRpcServices$1.run(java.lang.Object)"], ["org.apache.hadoop.hbase.master.MasterRpcServices$BalanceSwitchMode[]", "org.apache.hadoop.hbase.master.MasterRpcServices$BalanceSwitchMode.values()"], ["org.apache.hadoop.hbase.master.MasterRpcServices$BalanceSwitchMode", "org.apache.hadoop.hbase.master.MasterRpcServices$BalanceSwitchMode.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.master.normalizer.NormalizationPlan$PlanType[]", "org.apache.hadoop.hbase.master.normalizer.NormalizationPlan$PlanType.values()"], ["org.apache.hadoop.hbase.master.normalizer.NormalizationPlan$PlanType", "org.apache.hadoop.hbase.master.normalizer.NormalizationPlan$PlanType.valueOf(java.lang.String)"], ["org.apache.hadoop.hbase.master.normalizer.RegionNormalizer", "org.apache.hadoop.hbase.master.normalizer.RegionNormalizerFactory.getRegionNormalizer(org.apache.hadoop.conf.Configuration)"], ["int", "org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer$1.compare(org.apache.hadoop.hbase.master.normalizer.NormalizationPlan, org.apache.hadoop.hbase.master.normalizer.NormalizationPlan)"], ["int", "org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer$1.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure()"], ["org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HColumnDescriptor)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.deserializeStateData(java.io.InputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.abort(java.lang.Object)"], ["org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure", "org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure()"], ["org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure", "org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.deserializeStateData(java.io.InputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.abort(java.lang.Object)"], ["org.apache.hadoop.hbase.master.procedure.DisableTableProcedure", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure()"], ["org.apache.hadoop.hbase.master.procedure.DisableTableProcedure", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, boolean)"], ["org.apache.hadoop.hbase.master.procedure.DisableTableProcedure", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, org.apache.hadoop.hbase.TableName, boolean, org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.abort(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv)"], ["void", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.serializeStateData(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.deserializeStateData(java.io.InputStream)"], ["void", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.toStringClassDetails(java.lang.StringBuilder)"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.getTableName()"], ["org.apache.hadoop.hbase.master.procedure.TableProcedureInterface$TableOperationType", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.getTableOperationType()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.abort(java.lang.Object)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$FairQueue", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$FairQueue()"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$FairQueue", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$FairQueue(int)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$FairQueue.add(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$FairQueue.remove(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$Queue<T>)"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$NamespaceQueue", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$NamespaceQueue(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$NamespaceQueue.requireExclusiveLock(org.apache.hadoop.hbase.procedure2.Procedure)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$NamespaceQueue.add(org.apache.hadoop.hbase.procedure2.Procedure, boolean)"], ["org.apache.hadoop.hbase.procedure2.Procedure", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$NamespaceQueue.peek()"], ["org.apache.hadoop.hbase.procedure2.Procedure", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$NamespaceQueue.poll()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$NamespaceQueue.isEmpty()"], ["int", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$NamespaceQueue.size()"], ["org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.master.TableLockManager)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.addFront(org.apache.hadoop.hbase.procedure2.Procedure)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.addBack(org.apache.hadoop.hbase.procedure2.Procedure)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.yield(org.apache.hadoop.hbase.procedure2.Procedure)"], ["org.apache.hadoop.hbase.procedure2.Procedure", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.poll()"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.clear()"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.signalAll()"], ["int", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.size()"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.completionCleanup(org.apache.hadoop.hbase.procedure2.Procedure)"], ["long", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.getPollCalls()"], ["long", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.getNullPollCalls()"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.waitEvent(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent, org.apache.hadoop.hbase.procedure2.Procedure)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.waitEvent(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent, org.apache.hadoop.hbase.procedure2.Procedure, boolean)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.suspend(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.wake(org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler$ProcedureEvent)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.tryAcquireTableExclusiveLock(org.apache.hadoop.hbase.procedure2.Procedure, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.releaseTableExclusiveLock(org.apache.hadoop.hbase.procedure2.Procedure, org.apache.hadoop.hbase.TableName)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.tryAcquireTableSharedLock(org.apache.hadoop.hbase.procedure2.Procedure, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.releaseTableSharedLock(org.apache.hadoop.hbase.procedure2.Procedure, org.apache.hadoop.hbase.TableName)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.tryAcquireNamespaceExclusiveLock(org.apache.hadoop.hbase.procedure2.Procedure, java.lang.String)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.releaseNamespaceExclusiveLock(org.apache.hadoop.hbase.procedure2.Procedure, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.tryAcquireServerExclusiveLock(org.apache.hadoop.hbase.procedure2.Procedure, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.releaseServerExclusiveLock(org.apache.hadoop.hbase.procedure2.Procedure, org.apache.hadoop.hbase.ServerName)"], ["boolean", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.tryAcquireServerSharedLock(org.apache.hadoop.hbase.procedure2.Procedure, org.apache.hadoop.hbase.ServerName)"], ["void", "org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.releaseServerSharedLock(org.apache.hadoop.hbase.procedure2.Procedure, org.apache.hadoop.hbase.ServerName)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait$3.evaluate()"], ["java.lang.Object", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait$3.evaluate()"], ["byte[]", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.submitAndWaitProcedure(org.apache.hadoop.hbase.procedure2.ProcedureExecutor<org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv>, org.apache.hadoop.hbase.procedure2.Procedure)"], ["byte[]", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.waitForProcedureToComplete(org.apache.hadoop.hbase.procedure2.ProcedureExecutor<org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv>, long)"], ["<T> T", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.waitFor(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, java.lang.String, org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait$Predicate<T>)"], ["<T> T", "org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.waitFor(org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv, long, long, java.lang.String, org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait$Predicate<T>)"], ["org.apache.hadoop.hbase.master.RackManager", "org.apache.hadoop.hbase.master.RackManager()"], ["org.apache.hadoop.hbase.master.RackManager", "org.apache.hadoop.hbase.master.RackManager(org.apache.hadoop.conf.Configuration)"], ["java.lang.String", "org.apache.hadoop.hbase.master.RackManager.getRack(org.apache.hadoop.hbase.ServerName)"], ["int", "org.apache.hadoop.hbase.master.RegionStates$RegionStateStampComparator.compare(org.apache.hadoop.hbase.master.RegionState, org.apache.hadoop.hbase.master.RegionState)"], ["int", "org.apache.hadoop.hbase.master.RegionStates$RegionStateStampComparator.compare(java.lang.Object, java.lang.Object)"], ["org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.master.MasterServices)"], ["org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.prepare()"], ["void", "org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.snapshotRegions(java.util.List<org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.ServerName>>)"], ["org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler", "org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.prepare()"], ["org.apache.hadoop.hbase.executor.EventHandler", "org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.prepare()"], ["org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache", "org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache(org.apache.hadoop.conf.Configuration, long, java.lang.String, org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$SnapshotFileInspector)"], ["org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache", "org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, long, long, java.lang.String, org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$SnapshotFileInspector)"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.triggerCacheRefreshForTesting()"], ["void", "org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.isStopped()"], ["org.apache.hadoop.hbase.master.SplitLogManager$TaskBatch", "org.apache.hadoop.hbase.master.SplitLogManager$TaskBatch()"], ["java.lang.String", "org.apache.hadoop.hbase.master.SplitLogManager$TaskBatch.toString()"], ["org.apache.hadoop.hbase.master.SplitLogManager$TimeoutMonitor", "org.apache.hadoop.hbase.master.SplitLogManager$TimeoutMonitor(org.apache.hadoop.hbase.master.SplitLogManager, int, org.apache.hadoop.hbase.Stoppable)"], ["org.apache.hadoop.hbase.master.TableLockManager", "org.apache.hadoop.hbase.master.TableLockManager()"], ["org.apache.hadoop.hbase.master.TableLockManager", "org.apache.hadoop.hbase.master.TableLockManager.createTableLockManager(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.ServerName)"], ["org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos$TableLock", "org.apache.hadoop.hbase.master.TableLockManager.fromBytes(byte[])"], ["void", "org.apache.hadoop.hbase.migration.UpgradeTo96$1.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.migration.UpgradeTo96$1.isAborted()"], ["org.apache.hadoop.hbase.namespace.NamespaceStateManager", "org.apache.hadoop.hbase.namespace.NamespaceStateManager(org.apache.hadoop.hbase.master.MasterServices, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceStateManager.start()"], ["org.apache.hadoop.hbase.namespace.NamespaceTableAndRegionInfo", "org.apache.hadoop.hbase.namespace.NamespaceStateManager.getState(java.lang.String)"], ["synchronized", "org.apache.hadoop.hbase.namespace.NamespaceStateManager.void removeRegionFromTable(org.apache.hadoop.hbase.HRegionInfo)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceStateManager.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.namespace.NamespaceStateManager.nodeChildrenChanged(java.lang.String)"], ["org.apache.hadoop.hbase.procedure.ProcedureCoordinator", "org.apache.hadoop.hbase.procedure.ProcedureCoordinator(org.apache.hadoop.hbase.procedure.ProcedureCoordinatorRpcs, java.util.concurrent.ThreadPoolExecutor)"], ["org.apache.hadoop.hbase.procedure.ProcedureCoordinator", "org.apache.hadoop.hbase.procedure.ProcedureCoordinator(org.apache.hadoop.hbase.procedure.ProcedureCoordinatorRpcs, java.util.concurrent.ThreadPoolExecutor, long, long)"], ["java.util.concurrent.ThreadPoolExecutor", "org.apache.hadoop.hbase.procedure.ProcedureCoordinator.defaultPool(java.lang.String, int)"], ["java.util.concurrent.ThreadPoolExecutor", "org.apache.hadoop.hbase.procedure.ProcedureCoordinator.defaultPool(java.lang.String, int, long)"], ["void", "org.apache.hadoop.hbase.procedure.ProcedureCoordinator.close()"], ["void", "org.apache.hadoop.hbase.procedure.ProcedureCoordinator.abortProcedure(java.lang.String, org.apache.hadoop.hbase.errorhandling.ForeignException)"], ["org.apache.hadoop.hbase.procedure.Procedure", "org.apache.hadoop.hbase.procedure.ProcedureCoordinator.startProcedure(org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher, java.lang.String, byte[], java.util.List<java.lang.String>)"], ["org.apache.hadoop.hbase.procedure.Procedure", "org.apache.hadoop.hbase.procedure.ProcedureCoordinator.getProcedure(java.lang.String)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs$1.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs$1.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs$1.nodeChildrenChanged(java.lang.String)"], ["org.apache.hadoop.hbase.quotas.FixedIntervalRateLimiter", "org.apache.hadoop.hbase.quotas.FixedIntervalRateLimiter()"], ["long", "org.apache.hadoop.hbase.quotas.FixedIntervalRateLimiter.refill(long)"], ["long", "org.apache.hadoop.hbase.quotas.FixedIntervalRateLimiter.getWaitInterval(long, long, long)"], ["void", "org.apache.hadoop.hbase.quotas.FixedIntervalRateLimiter.setNextRefillTime(long)"], ["long", "org.apache.hadoop.hbase.quotas.FixedIntervalRateLimiter.getNextRefillTime()"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$NamedLock.lock(T)"], ["void", "org.apache.hadoop.hbase.quotas.MasterQuotaManager$NamedLock.unlock(T)"], ["org.apache.hadoop.hbase.client.Get", "org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore$1.makeGet(java.util.Map$Entry<java.lang.String, org.apache.hadoop.hbase.quotas.QuotaState>)"], ["java.util.Map<java.lang.String, org.apache.hadoop.hbase.quotas.QuotaState>", "org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore$1.fetchEntries(java.util.List<org.apache.hadoop.hbase.client.Get>)"], ["org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore", "org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore(org.apache.hadoop.hbase.quotas.QuotaCache, int, org.apache.hadoop.hbase.Stoppable)"], ["org.apache.hadoop.hbase.regionserver.BaseRowProcessor", "org.apache.hadoop.hbase.regionserver.BaseRowProcessor()"], ["void", "org.apache.hadoop.hbase.regionserver.BaseRowProcessor.preProcess(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.BaseRowProcessor.preBatchMutate(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.BaseRowProcessor.postBatchMutate(org.apache.hadoop.hbase.regionserver.HRegion)"], ["void", "org.apache.hadoop.hbase.regionserver.BaseRowProcessor.postProcess(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.wal.WALEdit, boolean)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.BaseRowProcessor.getName()"], ["org.apache.hadoop.hbase.client.Durability", "org.apache.hadoop.hbase.regionserver.BaseRowProcessor.useDurability()"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Writer", "org.apache.hadoop.hbase.regionserver.compactions.AbstractMultiOutputCompactor$1.createWriter()"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionWindowFactory", "org.apache.hadoop.hbase.regionserver.compactions.CompactionWindowFactory()"], ["org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy", "org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.StoreConfigInformation)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.needsCompaction(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.shouldPerformMajorCompaction(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.selectMajorCompaction(java.util.ArrayList<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.selectMinorCompaction(java.util.ArrayList<org.apache.hadoop.hbase.regionserver.StoreFile>, boolean, boolean)"], ["org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours", "org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours()"], ["org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours", "org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours.getInstance(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours", "org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours.getInstance(int, int)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.StoreConfigInformation, org.apache.hadoop.hbase.regionserver.StripeStoreConfig)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeCompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.createEmptyRequest(org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeInformationProvider, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.StripeStoreFlusher$StripeFlushRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.selectFlush(org.apache.hadoop.hbase.KeyValue$KVComparator, org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeInformationProvider, int)"], ["org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeCompactionRequest", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.selectCompaction(org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeInformationProvider, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.needsCompactions(org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy$StripeInformationProvider, java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.shouldPerformMajorCompaction(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["boolean", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.throttleCompaction(long)"], ["long", "org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.getTotalFileSize(java.util.Collection<org.apache.hadoop.hbase.regionserver.StoreFile>)"], ["java.lang.Thread", "org.apache.hadoop.hbase.regionserver.CompactSplitThread$1.newThread(java.lang.Runnable)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.toString()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.dumpQueue()"], ["synchronized", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.void requestRegionsMerge(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Region, boolean, long, org.apache.hadoop.hbase.security.User)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.boolean requestSplit(org.apache.hadoop.hbase.regionserver.Region)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.void requestSplit(org.apache.hadoop.hbase.regionserver.Region, byte[])"], ["synchronized", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.void requestSplit(org.apache.hadoop.hbase.regionserver.Region, byte[], org.apache.hadoop.hbase.security.User)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest requestCompaction(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Store, java.lang.String, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)"], ["org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.requestCompaction(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Store, java.lang.String, int, org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest, org.apache.hadoop.hbase.security.User)"], ["synchronized", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.void requestSystemCompaction(org.apache.hadoop.hbase.regionserver.Region, java.lang.String)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.requestSystemCompaction(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.regionserver.Store, java.lang.String)"], ["int", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.getCompactionQueueSize()"], ["int", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.getLargeCompactionQueueSize()"], ["int", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.getSmallCompactionQueueSize()"], ["int", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.getSplitQueueSize()"], ["int", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.getRegionSplitLimit()"], ["void", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.registerChildren(org.apache.hadoop.hbase.conf.ConfigurationManager)"], ["void", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.deregisterChildren(org.apache.hadoop.hbase.conf.ConfigurationManager)"], ["org.apache.hadoop.hbase.regionserver.throttle.ThroughputController", "org.apache.hadoop.hbase.regionserver.CompactSplitThread.getCompactionThroughputController()"], ["org.apache.hadoop.hbase.regionserver.DelimitedKeyPrefixRegionSplitPolicy", "org.apache.hadoop.hbase.regionserver.DelimitedKeyPrefixRegionSplitPolicy()"], ["org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler", "org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler(org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, long, org.apache.hadoop.hbase.coordination.OpenRegionCoordination, org.apache.hadoop.hbase.coordination.OpenRegionCoordination$OpenRegionDetails)"], ["org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerResult", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerResult(boolean)"], ["float", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerResult.getMemstoreSize()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerResult.setMemstoreSize(float)"], ["float", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerResult.getBlockCacheSize()"], ["void", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerResult.setBlockCacheSize(float)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HeapMemoryManager$TunerResult.needsTuning()"], ["java.lang.Thread", "org.apache.hadoop.hbase.regionserver.HRegion$3.newThread(java.lang.Runnable)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion$5.run(com.google.protobuf.Message)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion$5.run(java.lang.Object)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getSmallestReadPoint()"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion(org.apache.hadoop.hbase.regionserver.HRegionFileSystem, org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.initialize()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.hasReferences()"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.regionserver.HRegion.getHDFSBlocksDistribution()"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.regionserver.HRegion.computeHDFSBlocksDistribution(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo)"], ["org.apache.hadoop.hbase.HDFSBlocksDistribution", "org.apache.hadoop.hbase.regionserver.HRegion.computeHDFSBlocksDistribution(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.fs.Path)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.addAndGetGlobalMemstoreSize(long)"], ["org.apache.hadoop.hbase.HRegionInfo", "org.apache.hadoop.hbase.regionserver.HRegion.getRegionInfo()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getReadRequestsCount()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.updateReadRequestsCount(long)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getWriteRequestsCount()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.updateWriteRequestsCount(long)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getMemstoreSize()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getNumMutationsWithoutWAL()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getDataInMemoryWithoutWAL()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getBlockedRequestsCount()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getCheckAndMutateChecksPassed()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getCheckAndMutateChecksFailed()"], ["org.apache.hadoop.hbase.regionserver.MetricsRegion", "org.apache.hadoop.hbase.regionserver.HRegion.getMetrics()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.isClosed()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.isClosing()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.isReadOnly()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.setRecovering(boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.isRecovering()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.isAvailable()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.isSplittable()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.isMergeable()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.areWritesEnabled()"], ["org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl", "org.apache.hadoop.hbase.regionserver.HRegion.getMVCC()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getMaxFlushedSeqId()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getReadpoint(org.apache.hadoop.hbase.client.IsolationLevel)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.isLoadingCfsOnDemandDefault()"], ["java.util.Map<byte[], java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>>", "org.apache.hadoop.hbase.regionserver.HRegion.close()"], ["java.util.Map<byte[], java.util.List<org.apache.hadoop.hbase.regionserver.StoreFile>>", "org.apache.hadoop.hbase.regionserver.HRegion.close(boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.setClosing(boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.waitForFlushesAndCompactions()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.waitForFlushes()"], ["org.apache.hadoop.hbase.HTableDescriptor", "org.apache.hadoop.hbase.regionserver.HRegion.getTableDesc()"], ["org.apache.hadoop.hbase.wal.WAL", "org.apache.hadoop.hbase.regionserver.HRegion.getWAL()"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.regionserver.HRegion.getFilesystem()"], ["org.apache.hadoop.hbase.regionserver.HRegionFileSystem", "org.apache.hadoop.hbase.regionserver.HRegion.getRegionFileSystem()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getEarliestFlushTimeForAllStores()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getOldestHfileTs(boolean)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getLargestHStoreSize()"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.regionserver.HRegion.getComparator()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.triggerMajorCompaction()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.compact(boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.compactStores()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.compact(org.apache.hadoop.hbase.regionserver.compactions.CompactionContext, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.throttle.ThroughputController)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.compact(org.apache.hadoop.hbase.regionserver.compactions.CompactionContext, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.throttle.ThroughputController, org.apache.hadoop.hbase.security.User)"], ["org.apache.hadoop.hbase.regionserver.Region$FlushResult", "org.apache.hadoop.hbase.regionserver.HRegion.flush(boolean)"], ["org.apache.hadoop.hbase.regionserver.Region$FlushResult", "org.apache.hadoop.hbase.regionserver.HRegion.flushcache(boolean, boolean)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(byte[], byte[])"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.regionserver.HRegion.getScanner(org.apache.hadoop.hbase.client.Scan)"], ["org.apache.hadoop.hbase.regionserver.RegionScanner", "org.apache.hadoop.hbase.regionserver.HRegion.getScanner(org.apache.hadoop.hbase.client.Scan, java.util.List<org.apache.hadoop.hbase.regionserver.KeyValueScanner>)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.prepareDelete(org.apache.hadoop.hbase.client.Delete)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.delete(org.apache.hadoop.hbase.client.Delete)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.prepareDeleteTimestamps(org.apache.hadoop.hbase.client.Mutation, java.util.Map<byte[], java.util.List<org.apache.hadoop.hbase.Cell>>, byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.put(org.apache.hadoop.hbase.client.Put)"], ["org.apache.hadoop.hbase.regionserver.OperationStatus[]", "org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(org.apache.hadoop.hbase.client.Mutation[], long, long)"], ["org.apache.hadoop.hbase.regionserver.OperationStatus[]", "org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(org.apache.hadoop.hbase.client.Mutation[])"], ["org.apache.hadoop.hbase.regionserver.OperationStatus[]", "org.apache.hadoop.hbase.regionserver.HRegion.batchReplay(org.apache.hadoop.hbase.wal.WALSplitter$MutationReplay[], long)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.checkAndMutate(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.Mutation, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.checkAndRowMutate(byte[], byte[], byte[], org.apache.hadoop.hbase.filter.CompareFilter$CompareOp, org.apache.hadoop.hbase.filter.ByteArrayComparable, org.apache.hadoop.hbase.client.RowMutations, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.addRegionToSnapshot(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$SnapshotDescription, org.apache.hadoop.hbase.errorhandling.ForeignExceptionSnare)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.updateCellTimestamps(java.lang.Iterable<java.util.List<org.apache.hadoop.hbase.Cell>>, byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.setReadsEnabled(boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.checkFamilies(java.util.Collection<byte[]>)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.checkTimestamps(java.util.Map<byte[], java.util.List<org.apache.hadoop.hbase.Cell>>, long)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.refreshStoreFiles()"], ["org.apache.hadoop.hbase.regionserver.Store", "org.apache.hadoop.hbase.regionserver.HRegion.getStore(byte[])"], ["org.apache.hadoop.hbase.regionserver.Region$RowLock", "org.apache.hadoop.hbase.regionserver.HRegion.getRowLock(byte[])"], ["org.apache.hadoop.hbase.regionserver.Region$RowLock", "org.apache.hadoop.hbase.regionserver.HRegion.getRowLock(byte[], boolean)"], ["org.apache.hadoop.hbase.regionserver.Region$RowLock", "org.apache.hadoop.hbase.regionserver.HRegion.getRowLock(byte[], boolean, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.releaseRowLocks(java.util.List<org.apache.hadoop.hbase.regionserver.Region$RowLock>)"], ["java.util.concurrent.ConcurrentHashMap<org.apache.hadoop.hbase.util.HashedBytes, org.apache.hadoop.hbase.regionserver.HRegion$RowLockContext>", "org.apache.hadoop.hbase.regionserver.HRegion.getLockedRows()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(java.util.Collection<org.apache.hadoop.hbase.util.Pair<byte[], java.lang.String>>, boolean, org.apache.hadoop.hbase.regionserver.Region$BulkLoadListener)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.equals(java.lang.Object)"], ["int", "org.apache.hadoop.hbase.regionserver.HRegion.hashCode()"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.HRegion.toString()"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.closeHRegion(org.apache.hadoop.hbase.regionserver.HRegion)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL, boolean)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL, boolean, boolean)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL, boolean, boolean)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["org.apache.hadoop.hbase.regionserver.Region", "org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.openReadOnlyFileSystemHRegion(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.warmupHRegion(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.HTableDescriptor, org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.RegionServerServices, org.apache.hadoop.hbase.util.CancelableProgressable)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.addRegionToMETA(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HRegion.getRegionDir(org.apache.hadoop.fs.Path, java.lang.String)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.regionserver.HRegion.getRegionDir(org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.HRegionInfo)"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.rowIsInRange(org.apache.hadoop.hbase.HRegionInfo, byte[])"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.rowIsInRange(org.apache.hadoop.hbase.HRegionInfo, byte[], int, short)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.mergeAdjacent(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion)"], ["org.apache.hadoop.hbase.regionserver.HRegion", "org.apache.hadoop.hbase.regionserver.HRegion.merge(org.apache.hadoop.hbase.regionserver.HRegion, org.apache.hadoop.hbase.regionserver.HRegion)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.HRegion.get(org.apache.hadoop.hbase.client.Get)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.mutateRow(org.apache.hadoop.hbase.client.RowMutations)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.mutateRowsWithLocks(java.util.Collection<org.apache.hadoop.hbase.client.Mutation>, java.util.Collection<byte[]>)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.mutateRowsWithLocks(java.util.Collection<org.apache.hadoop.hbase.client.Mutation>, java.util.Collection<byte[]>, long, long)"], ["org.apache.hadoop.hbase.protobuf.generated.ClientProtos$RegionLoadStats", "org.apache.hadoop.hbase.regionserver.HRegion.getLoadStatistics()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.processRowsWithLocks(org.apache.hadoop.hbase.regionserver.RowProcessor<?, ?>)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.processRowsWithLocks(org.apache.hadoop.hbase.regionserver.RowProcessor<?, ?>, long, long)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.processRowsWithLocks(org.apache.hadoop.hbase.regionserver.RowProcessor<?, ?>, long, long, long)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.HRegion.append(org.apache.hadoop.hbase.client.Append)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.HRegion.append(org.apache.hadoop.hbase.client.Append, long, long)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.HRegion.increment(org.apache.hadoop.hbase.client.Increment)"], ["org.apache.hadoop.hbase.client.Result", "org.apache.hadoop.hbase.regionserver.HRegion.increment(org.apache.hadoop.hbase.client.Increment, long, long)"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.heapSize()"], ["boolean", "org.apache.hadoop.hbase.regionserver.HRegion.registerService(com.google.protobuf.Service)"], ["com.google.protobuf.Message", "org.apache.hadoop.hbase.regionserver.HRegion.execService(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$CoprocessorServiceCall)"], ["byte[]", "org.apache.hadoop.hbase.regionserver.HRegion.checkSplit()"], ["int", "org.apache.hadoop.hbase.regionserver.HRegion.getCompactPriority()"], ["org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost", "org.apache.hadoop.hbase.regionserver.HRegion.getCoprocessorHost()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.setCoprocessorHost(org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.startRegionOperation()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.startRegionOperation(org.apache.hadoop.hbase.regionserver.Region$Operation)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.closeRegionOperation()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.closeRegionOperation(org.apache.hadoop.hbase.regionserver.Region$Operation)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.main(java.lang.String[])"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getOpenSeqNum()"], ["java.util.Map<byte[], java.lang.Long>", "org.apache.hadoop.hbase.regionserver.HRegion.getMaxStoreSeqId()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getOldestSeqIdOfStore(byte[])"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$GetRegionInfoResponse$CompactionState", "org.apache.hadoop.hbase.regionserver.HRegion.getCompactionState()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.reportCompactionRequestStart(boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.reportCompactionRequestEnd(boolean, int, long)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.reportCompactionRequestFailure()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.incrementCompactionsQueuedCount()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.decrementCompactionsQueuedCount()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.incrementFlushesQueuedCount()"], ["long", "org.apache.hadoop.hbase.regionserver.HRegion.getSequenceId()"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.onConfigurationChange(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.registerChildren(org.apache.hadoop.hbase.conf.ConfigurationManager)"], ["void", "org.apache.hadoop.hbase.regionserver.HRegion.deregisterChildren(org.apache.hadoop.hbase.conf.ConfigurationManager)"], ["org.apache.hadoop.hbase.regionserver.RegionSplitPolicy", "org.apache.hadoop.hbase.regionserver.HRegion.getSplitPolicy()"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$15.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$22.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$24.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$31.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$33.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$40.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$48.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$55.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$62.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost$7.call(org.apache.hadoop.hbase.coprocessor.RegionObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.regionserver.RegionMergeTransaction$RegionMergeTransactionPhase[]", "org.apache.hadoop.hbase.regionserver.RegionMergeTransaction$RegionMergeTransactionPhase.values()"], ["org.apache.hadoop.hbase.regionserver.RegionMergeTransaction$RegionMergeTransactionPhase", "org.apache.hadoop.hbase.regionserver.RegionMergeTransaction$RegionMergeTransactionPhase.valueOf(java.lang.String)"], ["java.lang.Boolean", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$4.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl$4.run()"], ["org.apache.hadoop.hbase.regionserver.RegionServerAccounting", "org.apache.hadoop.hbase.regionserver.RegionServerAccounting()"], ["long", "org.apache.hadoop.hbase.regionserver.RegionServerAccounting.getGlobalMemstoreSize()"], ["long", "org.apache.hadoop.hbase.regionserver.RegionServerAccounting.addAndGetGlobalMemstoreSize(long)"], ["long", "org.apache.hadoop.hbase.regionserver.RegionServerAccounting.addAndGetRegionReplayEditsSize(byte[], long)"], ["long", "org.apache.hadoop.hbase.regionserver.RegionServerAccounting.rollbackRegionReplayEditsSize(byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerAccounting.clearRegionReplayEditsSize(byte[])"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$3.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["void", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$6.call(org.apache.hadoop.hbase.coprocessor.RegionServerObserver, org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessorEnvironment>)"], ["org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$RegionServerEnvironment", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$RegionServerEnvironment(java.lang.Class<?>, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.RegionServerServices)"], ["org.apache.hadoop.hbase.regionserver.RegionServerServices", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$RegionServerEnvironment.getRegionServerServices()"], ["org.apache.hadoop.hbase.metrics.MetricRegistry", "org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost$RegionServerEnvironment.getMetricRegistryForRegionServer()"], ["void", "org.apache.hadoop.hbase.regionserver.RSRpcServices$ScannerListener.leaseExpired()"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$NextState[]", "org.apache.hadoop.hbase.regionserver.ScannerContext$NextState.values()"], ["org.apache.hadoop.hbase.regionserver.ScannerContext$NextState", "org.apache.hadoop.hbase.regionserver.ScannerContext$NextState.valueOf(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ScannerContext$NextState.hasMoreValues()"], ["boolean", "org.apache.hadoop.hbase.regionserver.ScannerContext$NextState.limitReached()"], ["boolean", "org.apache.hadoop.hbase.regionserver.ScannerContext$NextState.isValidState(org.apache.hadoop.hbase.regionserver.ScannerContext$NextState)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ScannerContext$NextState.hasMoreValues(org.apache.hadoop.hbase.regionserver.ScannerContext$NextState)"], ["org.apache.hadoop.hbase.regionserver.ServerNonceManager", "org.apache.hadoop.hbase.regionserver.ServerNonceManager(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.regionserver.ServerNonceManager.setConflictWaitIterationMs(int)"], ["boolean", "org.apache.hadoop.hbase.regionserver.ServerNonceManager.startOperation(long, long, org.apache.hadoop.hbase.Stoppable)"], ["void", "org.apache.hadoop.hbase.regionserver.ServerNonceManager.endOperation(long, long, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.ServerNonceManager.addMvccToOperationContext(long, long, long)"], ["long", "org.apache.hadoop.hbase.regionserver.ServerNonceManager.getMvccFromOperationContext(long, long)"], ["void", "org.apache.hadoop.hbase.regionserver.ServerNonceManager.reportOperationFromWal(long, long, long)"], ["org.apache.hadoop.hbase.ScheduledChore", "org.apache.hadoop.hbase.regionserver.ServerNonceManager.createCleanupScheduledChore(org.apache.hadoop.hbase.Stoppable)"], ["java.lang.Void", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$1.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$1.run()"], ["org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$JournalEntryImpl", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$JournalEntryImpl(org.apache.hadoop.hbase.regionserver.SplitTransaction$SplitTransactionPhase)"], ["org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$JournalEntryImpl", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$JournalEntryImpl(org.apache.hadoop.hbase.regionserver.SplitTransaction$SplitTransactionPhase, long)"], ["java.lang.String", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$JournalEntryImpl.toString()"], ["org.apache.hadoop.hbase.regionserver.SplitTransaction$SplitTransactionPhase", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$JournalEntryImpl.getPhase()"], ["long", "org.apache.hadoop.hbase.regionserver.SplitTransactionImpl$JournalEntryImpl.getTimeStamp()"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Reader", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.StoreFile$Reader", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.hbase.io.FSDataInputStreamWrapper, long, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.setReplicaStoreFile(boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.isPrimaryReplicaReader()"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getComparator()"], ["org.apache.hadoop.hbase.regionserver.StoreFileScanner", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getStoreFileScanner(boolean, boolean, boolean, long, long, boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.isReferencedInReads()"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.isCompactedAway()"], ["org.apache.hadoop.hbase.io.hfile.HFileScanner", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getScanner(boolean, boolean)"], ["org.apache.hadoop.hbase.io.hfile.HFileScanner", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getScanner(boolean, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.close(boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.passesDeleteFamilyBloomFilter(byte[], int, int)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.passesGeneralBloomFilter(byte[], int, int, byte[], int, int)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.passesKeyRangeFilter(org.apache.hadoop.hbase.client.Scan)"], ["java.util.Map<byte[], byte[]>", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.loadFileInfo()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.loadBloomfilter()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getFilterEntries()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.setGeneralBloomFilterFaulty()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.setDeleteFamilyBloomFilterFaulty()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getLastKey()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getLastRowKey()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.midkey()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.length()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getTotalUncompressedBytes()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getEntries()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getDeleteFamilyCnt()"], ["byte[]", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getFirstKey()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.indexSize()"], ["org.apache.hadoop.hbase.regionserver.BloomType", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getBloomFilterType()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getSequenceID()"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.setSequenceID(long)"], ["void", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.setBulkLoaded(boolean)"], ["boolean", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.isBulkLoaded()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getTotalBloomSize()"], ["int", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getHFileVersion()"], ["int", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getHFileMinorVersion()"], ["org.apache.hadoop.hbase.io.hfile.HFile$Reader", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getHFileReader()"], ["long", "org.apache.hadoop.hbase.regionserver.StoreFile$Reader.getMaxTimestamp()"], ["org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter", "org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter(org.apache.hadoop.hbase.KeyValue$KVComparator)"], ["void", "org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter.setNoStripeMetadata()"], ["org.apache.hadoop.hbase.regionserver.StripeStoreFlusher", "org.apache.hadoop.hbase.regionserver.StripeStoreFlusher(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.Store, org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy, org.apache.hadoop.hbase.regionserver.StripeStoreFileManager)"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.FSHLog$2.accept(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.regionserver.wal.HLogKey", "org.apache.hadoop.hbase.regionserver.wal.HLogKey()"], ["org.apache.hadoop.hbase.regionserver.wal.HLogKey", "org.apache.hadoop.hbase.regionserver.wal.HLogKey(byte[], org.apache.hadoop.hbase.TableName, long, long, java.util.UUID)"], ["org.apache.hadoop.hbase.regionserver.wal.HLogKey", "org.apache.hadoop.hbase.regionserver.wal.HLogKey(byte[], org.apache.hadoop.hbase.TableName)"], ["org.apache.hadoop.hbase.regionserver.wal.HLogKey", "org.apache.hadoop.hbase.regionserver.wal.HLogKey(byte[], org.apache.hadoop.hbase.TableName, long)"], ["org.apache.hadoop.hbase.regionserver.wal.HLogKey", "org.apache.hadoop.hbase.regionserver.wal.HLogKey(byte[], org.apache.hadoop.hbase.TableName, long, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["org.apache.hadoop.hbase.regionserver.wal.HLogKey", "org.apache.hadoop.hbase.regionserver.wal.HLogKey(byte[], org.apache.hadoop.hbase.TableName, long, long, java.util.List<java.util.UUID>, long, long, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["org.apache.hadoop.hbase.regionserver.wal.HLogKey", "org.apache.hadoop.hbase.regionserver.wal.HLogKey(byte[], org.apache.hadoop.hbase.TableName, long, java.util.List<java.util.UUID>, long, long, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["org.apache.hadoop.hbase.regionserver.wal.HLogKey", "org.apache.hadoop.hbase.regionserver.wal.HLogKey(byte[], org.apache.hadoop.hbase.TableName, long, long, long, org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.HLogKey.write(java.io.DataOutput)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.HLogKey.readFields(java.io.DataInput)"], ["org.apache.hadoop.hbase.regionserver.wal.ReaderBase", "org.apache.hadoop.hbase.regionserver.wal.ReaderBase()"], ["void", "org.apache.hadoop.hbase.regionserver.wal.ReaderBase.init(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FSDataInputStream)"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.regionserver.wal.ReaderBase.next()"], ["org.apache.hadoop.hbase.wal.WAL$Entry", "org.apache.hadoop.hbase.regionserver.wal.ReaderBase.next(org.apache.hadoop.hbase.wal.WAL$Entry)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.ReaderBase.seek(long)"], ["org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec$EncryptedKvDecoder", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec$EncryptedKvDecoder(java.io.InputStream)"], ["org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec$EncryptedKvDecoder", "org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec$EncryptedKvDecoder(java.io.InputStream, org.apache.hadoop.hbase.io.crypto.Decryptor)"], ["long", "org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader$WALReader$WALReaderFSDataInputStream.getPos()"], ["org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$EnsureKvEncoder", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$EnsureKvEncoder(java.io.OutputStream)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec$EnsureKvEncoder.write(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost", "org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost(org.apache.hadoop.hbase.wal.WAL, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost$WALEnvironment", "org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost.createEnvironment(java.lang.Class<?>, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration)"], ["boolean", "org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost.preWALWrite(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost.postWALWrite(org.apache.hadoop.hbase.HRegionInfo, org.apache.hadoop.hbase.wal.WALKey, org.apache.hadoop.hbase.regionserver.wal.WALEdit)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost.preWALRoll(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["void", "org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost.postWALRoll(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.CoprocessorEnvironment", "org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost.createEnvironment(java.lang.Class, org.apache.hadoop.hbase.Coprocessor, int, int, org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.hbase.replication.BulkLoadCellFilter", "org.apache.hadoop.hbase.replication.BulkLoadCellFilter()"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.replication.BulkLoadCellFilter.filterCell(org.apache.hadoop.hbase.Cell, com.google.common.base.Predicate<byte[]>)"], ["org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner()"], ["void", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner.setConf(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner.setConf(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["void", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner.setConf(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.replication.ReplicationQueuesClient)"], ["void", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner.stop(java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner.isStopped()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues$WarnOnlyAbortable.abort(java.lang.String, java.lang.Throwable)"], ["boolean", "org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues$WarnOnlyAbortable.isAborted()"], ["org.apache.hadoop.hbase.replication.regionserver.MetricsSink", "org.apache.hadoop.hbase.replication.regionserver.MetricsSink()"], ["long", "org.apache.hadoop.hbase.replication.regionserver.MetricsSink.setAgeOfLastAppliedOp(long)"], ["long", "org.apache.hadoop.hbase.replication.regionserver.MetricsSink.refreshAgeOfLastAppliedOp()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSink.applyBatch(long)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.MetricsSink.applyBatch(long, long)"], ["long", "org.apache.hadoop.hbase.replication.regionserver.MetricsSink.getAgeOfLastAppliedOp()"], ["long", "org.apache.hadoop.hbase.replication.regionserver.MetricsSink.getTimeStampOfLastAppliedOp()"], ["org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaReplayCallable", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaReplayCallable(org.apache.hadoop.hbase.client.ClusterConnection, org.apache.hadoop.hbase.ipc.RpcControllerFactory, org.apache.hadoop.hbase.TableName, org.apache.hadoop.hbase.HRegionLocation, org.apache.hadoop.hbase.HRegionInfo, byte[], java.util.List<org.apache.hadoop.hbase.wal.WAL$Entry>, java.util.concurrent.atomic.AtomicLong)"], ["org.apache.hadoop.hbase.protobuf.generated.AdminProtos$ReplicateWALEntryResponse", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaReplayCallable.call(int)"], ["java.lang.Object", "org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint$RegionReplicaReplayCallable.call(int)"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationObserver", "org.apache.hadoop.hbase.replication.regionserver.ReplicationObserver()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationObserver.preCommitStoreFile(org.apache.hadoop.hbase.coprocessor.ObserverContext<org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment>, byte[], java.util.List<org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path>>)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceShipperThread$1.uncaughtException(java.lang.Thread, java.lang.Throwable)"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager(org.apache.hadoop.hbase.replication.ReplicationQueues, org.apache.hadoop.hbase.replication.ReplicationPeers, org.apache.hadoop.hbase.replication.ReplicationTracker, org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.Server, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, java.util.UUID)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.logPositionAndCleanOldLogs(org.apache.hadoop.fs.Path, java.lang.String, long, boolean, boolean)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.cleanOldLogs(java.lang.String, java.lang.String, boolean)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.deleteSource(java.lang.String, boolean)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.join()"], ["org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.getSource(java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.closeRecoveredQueue(org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.closeQueue(org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.removePeer(java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.regionServerRemoved(java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.peerRemoved(java.lang.String)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.peerListChanged(java.util.List<java.lang.String>)"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.getOldLogDir()"], ["org.apache.hadoop.fs.Path", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.getLogDir()"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.getFs()"], ["org.apache.hadoop.hbase.replication.ReplicationPeers", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.getReplicationPeers()"], ["java.lang.String", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.getStats()"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.addHFileRefs(org.apache.hadoop.hbase.TableName, byte[], java.util.List<org.apache.hadoop.hbase.util.Pair<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path>>)"], ["void", "org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.cleanUpHFileRefs(java.lang.String, java.util.List<java.lang.String>)"], ["boolean", "org.apache.hadoop.hbase.replication.TableCfWALEntryFilter$1.apply(byte[])"], ["boolean", "org.apache.hadoop.hbase.replication.TableCfWALEntryFilter$1.apply(java.lang.Object)"], ["org.apache.hadoop.hbase.filter.Filter$ReturnCode", "org.apache.hadoop.hbase.security.access.AccessControlFilter.filterKeyValue(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.security.access.AccessControlFilter.transformCell(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.security.access.AccessControlFilter.reset()"], ["byte[]", "org.apache.hadoop.hbase.security.access.AccessControlFilter.toByteArray()"], ["org.apache.hadoop.hbase.security.access.AccessControlFilter", "org.apache.hadoop.hbase.security.access.AccessControlFilter.parseFrom(byte[])"], ["java.lang.Void", "org.apache.hadoop.hbase.security.access.AccessController$6.run()"], ["java.lang.Object", "org.apache.hadoop.hbase.security.access.AccessController$6.run()"], ["org.apache.hadoop.hbase.security.access.AuthResult", "org.apache.hadoop.hbase.security.access.AuthResult(boolean, java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.security.access.Permission$Action, org.apache.hadoop.hbase.TableName, byte[], byte[])"], ["org.apache.hadoop.hbase.security.access.AuthResult", "org.apache.hadoop.hbase.security.access.AuthResult(boolean, java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.security.access.Permission$Action, org.apache.hadoop.hbase.TableName, java.util.Map<byte[], ? extends java.util.Collection<?>>)"], ["org.apache.hadoop.hbase.security.access.AuthResult", "org.apache.hadoop.hbase.security.access.AuthResult(boolean, java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.security.access.Permission$Action, java.lang.String)"], ["boolean", "org.apache.hadoop.hbase.security.access.AuthResult.isAllowed()"], ["org.apache.hadoop.hbase.security.User", "org.apache.hadoop.hbase.security.access.AuthResult.getUser()"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.AuthResult.getReason()"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.security.access.AuthResult.getTableName()"], ["byte[]", "org.apache.hadoop.hbase.security.access.AuthResult.getFamily()"], ["byte[]", "org.apache.hadoop.hbase.security.access.AuthResult.getQualifier()"], ["org.apache.hadoop.hbase.security.access.Permission$Action", "org.apache.hadoop.hbase.security.access.AuthResult.getAction()"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.AuthResult.getRequest()"], ["org.apache.hadoop.hbase.security.access.AuthResult$Params", "org.apache.hadoop.hbase.security.access.AuthResult.getParams()"], ["void", "org.apache.hadoop.hbase.security.access.AuthResult.setAllowed(boolean)"], ["void", "org.apache.hadoop.hbase.security.access.AuthResult.setReason(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.AuthResult.toContextString()"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.AuthResult.toString()"], ["org.apache.hadoop.hbase.security.access.AuthResult", "org.apache.hadoop.hbase.security.access.AuthResult.allow(java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.security.access.Permission$Action, java.lang.String)"], ["org.apache.hadoop.hbase.security.access.AuthResult", "org.apache.hadoop.hbase.security.access.AuthResult.allow(java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.security.access.Permission$Action, org.apache.hadoop.hbase.TableName, byte[], byte[])"], ["org.apache.hadoop.hbase.security.access.AuthResult", "org.apache.hadoop.hbase.security.access.AuthResult.allow(java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.security.access.Permission$Action, org.apache.hadoop.hbase.TableName, java.util.Map<byte[], ? extends java.util.Collection<?>>)"], ["org.apache.hadoop.hbase.security.access.AuthResult", "org.apache.hadoop.hbase.security.access.AuthResult.deny(java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.security.access.Permission$Action, java.lang.String)"], ["org.apache.hadoop.hbase.security.access.AuthResult", "org.apache.hadoop.hbase.security.access.AuthResult.deny(java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.security.access.Permission$Action, org.apache.hadoop.hbase.TableName, byte[], byte[])"], ["org.apache.hadoop.hbase.security.access.AuthResult", "org.apache.hadoop.hbase.security.access.AuthResult.deny(java.lang.String, java.lang.String, org.apache.hadoop.hbase.security.User, org.apache.hadoop.hbase.security.access.Permission$Action, org.apache.hadoop.hbase.TableName, java.util.Map<byte[], ? extends java.util.Collection<?>>)"], ["java.lang.String", "org.apache.hadoop.hbase.security.access.AuthResult.toFamilyString()"], ["void", "org.apache.hadoop.hbase.security.access.ZKPermissionWatcher$3.run()"], ["org.apache.hadoop.hbase.security.HBaseSaslRpcServer$SaslGssCallbackHandler", "org.apache.hadoop.hbase.security.HBaseSaslRpcServer$SaslGssCallbackHandler()"], ["void", "org.apache.hadoop.hbase.security.HBaseSaslRpcServer$SaslGssCallbackHandler.handle(javax.security.auth.callback.Callback[])"], ["org.apache.hadoop.hbase.security.token.FsDelegationToken", "org.apache.hadoop.hbase.security.token.FsDelegationToken(org.apache.hadoop.hbase.security.UserProvider, java.lang.String)"], ["void", "org.apache.hadoop.hbase.security.token.FsDelegationToken.acquireDelegationToken(org.apache.hadoop.fs.FileSystem)"], ["void", "org.apache.hadoop.hbase.security.token.FsDelegationToken.releaseDelegationToken()"], ["org.apache.hadoop.hbase.security.UserProvider", "org.apache.hadoop.hbase.security.token.FsDelegationToken.getUserProvider()"], ["java.lang.String", "org.apache.hadoop.hbase.security.token.FsDelegationToken.getRenewer()"], ["org.apache.hadoop.fs.FileSystem", "org.apache.hadoop.hbase.security.token.FsDelegationToken.getFileSystem()"], ["org.apache.hadoop.hbase.security.token.TokenProvider", "org.apache.hadoop.hbase.security.token.TokenProvider()"], ["void", "org.apache.hadoop.hbase.security.token.TokenProvider.start(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["void", "org.apache.hadoop.hbase.security.token.TokenProvider.stop(org.apache.hadoop.hbase.CoprocessorEnvironment)"], ["com.google.protobuf.Service", "org.apache.hadoop.hbase.security.token.TokenProvider.getService()"], ["void", "org.apache.hadoop.hbase.security.token.TokenProvider.getAuthenticationToken(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AuthenticationProtos$GetAuthenticationTokenRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AuthenticationProtos$GetAuthenticationTokenResponse>)"], ["void", "org.apache.hadoop.hbase.security.token.TokenProvider.whoAmI(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.AuthenticationProtos$WhoAmIRequest, com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AuthenticationProtos$WhoAmIResponse>)"], ["org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode", "org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode.getIdentifier()"], ["int", "org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode.hashCode()"], ["boolean", "org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode.equals(java.lang.Object)"], ["java.lang.String", "org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode.toString()"], ["boolean", "org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode.isSingleNode()"], ["org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode", "org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode.deepClone()"], ["org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode", "org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode.deepClone()"], ["org.apache.hadoop.hbase.security.visibility.VisibilityLabelFilter", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelFilter(org.apache.hadoop.hbase.security.visibility.VisibilityExpEvaluator, java.util.Map<org.apache.hadoop.hbase.util.ByteRange, java.lang.Integer>)"], ["org.apache.hadoop.hbase.filter.Filter$ReturnCode", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelFilter.filterKeyValue(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.Cell", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelFilter.transformCell(org.apache.hadoop.hbase.Cell)"], ["void", "org.apache.hadoop.hbase.security.visibility.VisibilityLabelFilter.reset()"], ["org.apache.hadoop.hbase.security.visibility.VisibilityUtils", "org.apache.hadoop.hbase.security.visibility.VisibilityUtils()"], ["byte[]", "org.apache.hadoop.hbase.security.visibility.VisibilityUtils.getDataToWriteToZooKeeper(java.util.Map<java.lang.String, java.lang.Integer>)"], ["byte[]", "org.apache.hadoop.hbase.security.visibility.VisibilityUtils.getUserAuthsDataToWriteToZooKeeper(java.util.Map<java.lang.String, java.util.List<java.lang.Integer>>)"], ["org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos$MultiUserAuthorizations", "org.apache.hadoop.hbase.security.visibility.VisibilityUtils.readUserAuthsFromZKData(byte[])"], ["java.lang.Byte", "org.apache.hadoop.hbase.security.visibility.VisibilityUtils.extractVisibilityTags(org.apache.hadoop.hbase.Cell, java.util.List<org.apache.hadoop.hbase.Tag>)"], ["java.lang.Byte", "org.apache.hadoop.hbase.security.visibility.VisibilityUtils.extractAndPartitionTags(org.apache.hadoop.hbase.Cell, java.util.List<org.apache.hadoop.hbase.Tag>, java.util.List<org.apache.hadoop.hbase.Tag>)"], ["boolean", "org.apache.hadoop.hbase.security.visibility.VisibilityUtils.isVisibilityTagsPresent(org.apache.hadoop.hbase.Cell)"], ["org.apache.hadoop.hbase.filter.Filter", "org.apache.hadoop.hbase.security.visibility.VisibilityUtils.createVisibilityLabelFilter(org.apache.hadoop.hbase.regionserver.Region, org.apache.hadoop.hbase.security.visibility.Authorizations)"], ["org.apache.hadoop.hbase.security.User", "org.apache.hadoop.hbase.security.visibility.VisibilityUtils.getActiveUser()"], ["org.apache.hadoop.mapreduce.RecordReader<org.apache.hadoop.io.BytesWritable, org.apache.hadoop.io.NullWritable>", "org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat.createRecordReader(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext)"], ["void", "org.apache.hadoop.hbase.snapshot.SnapshotInfo$3.storeFile(org.apache.hadoop.hbase.HRegionInfo, java.lang.String, org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile)"], ["org.apache.hadoop.hbase.SplitLogCounters", "org.apache.hadoop.hbase.SplitLogCounters()"], ["void", "org.apache.hadoop.hbase.SplitLogCounters.resetCounters()"], ["void", "org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl$1.renderTo(java.io.Writer)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmplImpl.formatZKString()"], ["org.apache.hadoop.hbase.tmpl.master.MasterStatusTmplImpl", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmplImpl(org.jamon.TemplateManager, org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl$ImplData)"], ["void", "org.apache.hadoop.hbase.tmpl.master.MasterStatusTmplImpl.renderNoFlush(java.io.Writer)"], ["org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl(org.jamon.TemplateManager)"], ["org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl()"], ["org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.getImplData()"], ["org.jamon.AbstractTemplateImpl", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.constructImpl(java.lang.Class<? extends org.jamon.AbstractTemplateImpl>)"], ["org.jamon.Renderer", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.makeRenderer(org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.conf.Configuration, java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.render(java.io.Writer, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.conf.Configuration, java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.renderNoFlush(java.io.Writer, org.apache.hadoop.hbase.io.hfile.CacheConfig, org.apache.hadoop.conf.Configuration, java.lang.String, java.lang.String)"], ["org.jamon.AbstractTemplateProxy$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.getImplData()"], ["org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.setRegionServer(org.apache.hadoop.hbase.regionserver.HRegionServer)"], ["org.apache.hadoop.hbase.regionserver.HRegionServer", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.getRegionServer()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.setBcv(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.getBcv()"], ["boolean", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.getBcv__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.setFormat(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.getFormat()"], ["boolean", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.getFormat__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.setBcn(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.getBcn()"], ["boolean", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.getBcn__IsNotDefault()"], ["void", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.setFilter(java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.getFilter()"], ["boolean", "org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl$ImplData.getFilter__IsNotDefault()"], ["org.apache.hadoop.hbase.tool.Canary$RegionServerStdOutSink", "org.apache.hadoop.hbase.tool.Canary$RegionServerStdOutSink()"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionServerStdOutSink.publishReadFailure(java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.tool.Canary$RegionServerStdOutSink.publishReadTiming(java.lang.String, java.lang.String, long)"], ["org.apache.hadoop.hbase.tool.Canary$StdOutSink", "org.apache.hadoop.hbase.tool.Canary$StdOutSink()"], ["long", "org.apache.hadoop.hbase.tool.Canary$StdOutSink.getReadFailureCount()"], ["long", "org.apache.hadoop.hbase.tool.Canary$StdOutSink.incReadFailureCount()"], ["java.util.Map<java.lang.String, java.lang.String>", "org.apache.hadoop.hbase.tool.Canary$StdOutSink.getReadFailures()"], ["void", "org.apache.hadoop.hbase.tool.Canary$StdOutSink.updateReadFailures(java.lang.String, java.lang.String)"], ["long", "org.apache.hadoop.hbase.tool.Canary$StdOutSink.getWriteFailureCount()"], ["long", "org.apache.hadoop.hbase.tool.Canary$StdOutSink.incWriteFailureCount()"], ["java.util.Map<java.lang.String, java.lang.String>", "org.apache.hadoop.hbase.tool.Canary$StdOutSink.getWriteFailures()"], ["void", "org.apache.hadoop.hbase.tool.Canary$StdOutSink.updateWriteFailures(java.lang.String, java.lang.String)"], ["void", "org.apache.hadoop.hbase.util.ByteBloomFilter$DataWriter.readFields(java.io.DataInput)"], ["void", "org.apache.hadoop.hbase.util.ByteBloomFilter$DataWriter.write(java.io.DataOutput)"], ["org.apache.hadoop.hbase.util.ByteBloomFilter", "org.apache.hadoop.hbase.util.ByteBloomFilter(java.io.DataInput)"], ["long", "org.apache.hadoop.hbase.util.ByteBloomFilter.computeBitSize(long, double)"], ["long", "org.apache.hadoop.hbase.util.ByteBloomFilter.idealMaxKeys(long, double)"], ["long", "org.apache.hadoop.hbase.util.ByteBloomFilter.computeMaxKeys(long, double, int)"], ["double", "org.apache.hadoop.hbase.util.ByteBloomFilter.actualErrorRate()"], ["double", "org.apache.hadoop.hbase.util.ByteBloomFilter.actualErrorRate(long, long, int)"], ["int", "org.apache.hadoop.hbase.util.ByteBloomFilter.computeFoldableByteSize(long, int)"], ["org.apache.hadoop.hbase.util.ByteBloomFilter", "org.apache.hadoop.hbase.util.ByteBloomFilter(int, double, int, int)"], ["org.apache.hadoop.hbase.util.ByteBloomFilter", "org.apache.hadoop.hbase.util.ByteBloomFilter.createBySize(int, double, int, int)"], ["org.apache.hadoop.hbase.util.ByteBloomFilter", "org.apache.hadoop.hbase.util.ByteBloomFilter.createAnother()"], ["void", "org.apache.hadoop.hbase.util.ByteBloomFilter.allocBloom()"], ["void", "org.apache.hadoop.hbase.util.ByteBloomFilter.add(byte[])"], ["void", "org.apache.hadoop.hbase.util.ByteBloomFilter.add(byte[], int, int)"], ["boolean", "org.apache.hadoop.hbase.util.ByteBloomFilter.contains(byte[], int, int, java.nio.ByteBuffer)"], ["boolean", "org.apache.hadoop.hbase.util.ByteBloomFilter.contains(byte[], int, int, java.nio.ByteBuffer, int, int, org.apache.hadoop.hbase.util.Hash, int)"], ["long", "org.apache.hadoop.hbase.util.ByteBloomFilter.getKeyCount()"], ["long", "org.apache.hadoop.hbase.util.ByteBloomFilter.getMaxKeys()"], ["long", "org.apache.hadoop.hbase.util.ByteBloomFilter.getByteSize()"], ["int", "org.apache.hadoop.hbase.util.ByteBloomFilter.getHashType()"], ["void", "org.apache.hadoop.hbase.util.ByteBloomFilter.compactBloom()"], ["void", "org.apache.hadoop.hbase.util.ByteBloomFilter.writeBloom(java.io.DataOutput)"], ["org.apache.hadoop.io.Writable", "org.apache.hadoop.hbase.util.ByteBloomFilter.getMetaWriter()"], ["org.apache.hadoop.io.Writable", "org.apache.hadoop.hbase.util.ByteBloomFilter.getDataWriter()"], ["int", "org.apache.hadoop.hbase.util.ByteBloomFilter.getHashCount()"], ["boolean", "org.apache.hadoop.hbase.util.ByteBloomFilter.supportsAutoLoading()"], ["void", "org.apache.hadoop.hbase.util.ByteBloomFilter.setFakeLookupMode(boolean)"], ["byte[]", "org.apache.hadoop.hbase.util.ByteBloomFilter.createBloomKey(byte[], int, int, byte[], int, int)"], ["org.apache.hadoop.hbase.KeyValue$KVComparator", "org.apache.hadoop.hbase.util.ByteBloomFilter.getComparator()"], ["java.lang.String", "org.apache.hadoop.hbase.util.ByteBloomFilter.formatStats(org.apache.hadoop.hbase.util.BloomFilterBase)"], ["java.lang.String", "org.apache.hadoop.hbase.util.ByteBloomFilter.toString()"], ["boolean", "org.apache.hadoop.hbase.util.FSTableDescriptors$2.accept(org.apache.hadoop.fs.Path)"], ["org.apache.hadoop.hbase.util.FSUtils$RegionDirFilter", "org.apache.hadoop.hbase.util.FSUtils$RegionDirFilter(org.apache.hadoop.fs.FileSystem)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$CheckRegionConsistencyWorkItem.java.lang.Void call()"], ["java.lang.Object", "org.apache.hadoop.hbase.util.HBaseFsck$CheckRegionConsistencyWorkItem.call()"], ["org.apache.hadoop.hbase.util.HBaseFsck$FileLockCallable", "org.apache.hadoop.hbase.util.HBaseFsck$FileLockCallable(org.apache.hadoop.hbase.util.HBaseFsck, org.apache.hadoop.hbase.util.RetryCounter)"], ["org.apache.hadoop.fs.FSDataOutputStream", "org.apache.hadoop.hbase.util.HBaseFsck$FileLockCallable.call()"], ["java.lang.Object", "org.apache.hadoop.hbase.util.HBaseFsck$FileLockCallable.call()"], ["org.apache.hadoop.hbase.util.HBaseFsck$RegionRepairException", "org.apache.hadoop.hbase.util.HBaseFsck$RegionRepairException(java.lang.String, java.io.IOException)"], ["synchronized", "org.apache.hadoop.hbase.util.HBaseFsck$WorkItemHdfsRegionInfo.java.lang.Void call()"], ["java.lang.Object", "org.apache.hadoop.hbase.util.HBaseFsck$WorkItemHdfsRegionInfo.call()"], ["org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker", "org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker(org.apache.hadoop.conf.Configuration, java.util.concurrent.ExecutorService, boolean)"], ["void", "org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker.checkTables(java.util.Collection<org.apache.hadoop.fs.Path>)"], ["int", "org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker.getHFilesChecked()"], ["void", "org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker.report(org.apache.hadoop.hbase.util.HBaseFsck$ErrorReporter)"], ["void", "org.apache.hadoop.hbase.util.HMerge.merge(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.TableName)"], ["void", "org.apache.hadoop.hbase.util.HMerge.merge(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hbase.TableName, boolean)"], ["org.apache.hadoop.hbase.util.IdLock", "org.apache.hadoop.hbase.util.IdLock()"], ["org.apache.hadoop.hbase.util.IdLock$Entry", "org.apache.hadoop.hbase.util.IdLock.getLockEntry(long)"], ["void", "org.apache.hadoop.hbase.util.IdLock.releaseLockEntry(org.apache.hadoop.hbase.util.IdLock$Entry)"], ["void", "org.apache.hadoop.hbase.util.IdLock.waitForWaiters(long, int)"], ["org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread", "org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread(org.apache.hadoop.hbase.regionserver.HRegionServer, int)"], ["org.apache.hadoop.hbase.regionserver.HRegionServer", "org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread.getRegionServer()"], ["void", "org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread.waitForServerOnline()"], ["org.apache.hadoop.hbase.util.JvmVersion", "org.apache.hadoop.hbase.util.JvmVersion()"], ["boolean", "org.apache.hadoop.hbase.util.JvmVersion.isBadJvmVersion()"], ["org.apache.hadoop.hbase.util.MapreduceDependencyClasspathTool", "org.apache.hadoop.hbase.util.MapreduceDependencyClasspathTool()"], ["void", "org.apache.hadoop.hbase.util.MapreduceDependencyClasspathTool.setConf(org.apache.hadoop.conf.Configuration)"], ["org.apache.hadoop.conf.Configuration", "org.apache.hadoop.hbase.util.MapreduceDependencyClasspathTool.getConf()"], ["int", "org.apache.hadoop.hbase.util.MapreduceDependencyClasspathTool.run(java.lang.String[])"], ["void", "org.apache.hadoop.hbase.util.MapreduceDependencyClasspathTool.main(java.lang.String[])"], ["org.apache.hadoop.hbase.util.MultiHConnection", "org.apache.hadoop.hbase.util.MultiHConnection(org.apache.hadoop.conf.Configuration, int)"], ["void", "org.apache.hadoop.hbase.util.MultiHConnection.close()"], ["<R> void", "org.apache.hadoop.hbase.util.MultiHConnection.processBatchCallback(java.util.List<? extends org.apache.hadoop.hbase.client.Row>, org.apache.hadoop.hbase.TableName, java.lang.Object[], org.apache.hadoop.hbase.client.coprocessor.Batch$Callback<R>)"], ["org.apache.hadoop.hbase.util.RegionSplitter$DecimalStringSplit", "org.apache.hadoop.hbase.util.RegionSplitter$DecimalStringSplit()"], ["org.apache.hadoop.hbase.util.RegionSplitter", "org.apache.hadoop.hbase.util.RegionSplitter()"], ["void", "org.apache.hadoop.hbase.util.RegionSplitter.main(java.lang.String[])"], ["org.apache.hadoop.hbase.util.RegionSplitter$SplitAlgorithm", "org.apache.hadoop.hbase.util.RegionSplitter.newSplitAlgoInstance(org.apache.hadoop.conf.Configuration, java.lang.String)"], ["void", "org.apache.hadoop.hbase.wal.RegionGroupingProvider$IdentityGroupingStrategy.init(org.apache.hadoop.conf.Configuration, java.lang.String)"], ["java.lang.String", "org.apache.hadoop.hbase.wal.RegionGroupingProvider$IdentityGroupingStrategy.group(byte[], byte[])"], ["java.lang.Thread", "org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink$1.newThread(java.lang.Runnable)"], ["long", "org.apache.hadoop.hbase.wal.WALSplitter$RegionEntryBuffer.heapSize()"], ["byte[]", "org.apache.hadoop.hbase.wal.WALSplitter$RegionEntryBuffer.getEncodedRegionName()"], ["org.apache.hadoop.hbase.TableName", "org.apache.hadoop.hbase.wal.WALSplitter$RegionEntryBuffer.getTableName()"], ["org.apache.hadoop.hbase.ZKNamespaceManager", "org.apache.hadoop.hbase.ZKNamespaceManager(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher)"], ["void", "org.apache.hadoop.hbase.ZKNamespaceManager.start()"], ["org.apache.hadoop.hbase.NamespaceDescriptor", "org.apache.hadoop.hbase.ZKNamespaceManager.get(java.lang.String)"], ["void", "org.apache.hadoop.hbase.ZKNamespaceManager.update(org.apache.hadoop.hbase.NamespaceDescriptor)"], ["void", "org.apache.hadoop.hbase.ZKNamespaceManager.remove(java.lang.String)"], ["void", "org.apache.hadoop.hbase.ZKNamespaceManager.nodeCreated(java.lang.String)"], ["void", "org.apache.hadoop.hbase.ZKNamespaceManager.nodeDeleted(java.lang.String)"], ["void", "org.apache.hadoop.hbase.ZKNamespaceManager.nodeDataChanged(java.lang.String)"], ["void", "org.apache.hadoop.hbase.ZKNamespaceManager.nodeChildrenChanged(java.lang.String)"], ["org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker", "org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker(org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher, org.apache.hadoop.hbase.Abortable)"], ["boolean", "org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker.isBalancerOn()"], ["void", "org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker.setBalancerOn(boolean)"], ["org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster()"], ["org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster(org.apache.hadoop.conf.Configuration)"], ["void", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.addClientPort(int)"], ["void", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.setDefaultClientPort(int)"], ["void", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.setTickTime(int)"], ["int", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.getBackupZooKeeperServerNum()"], ["int", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.getZooKeeperServerNum()"], ["int", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(java.io.File)"], ["int", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(java.io.File, int)"], ["void", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.shutdown()"], ["int", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.killCurrentActiveZooKeeperServer()"], ["void", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.killOneBackupZooKeeperServer()"], ["int", "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.getClientPort()"]]}