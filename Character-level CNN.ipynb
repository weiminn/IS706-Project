{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2881694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/uvipen/Character-level-cnn-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b85685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import shutil\n",
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b2447a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>redis.clients.jedis.JedisPoolConfig.setNumTest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>org.elasticsearch.common.settings.Settings.set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>org.apache.catalina.deploy.FilterMap.addURLPat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>org.apache.sshd.server.sftp.SftpSubsystem.proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>org.mockito.Matchers.notNull()__XX__org.mockit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>0</td>\n",
       "      <td>org.sonarqube.ws.client.qualitygates.Qualityga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>0</td>\n",
       "      <td>org.sonarqube.ws.client.qualitygates.Qualityga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>0</td>\n",
       "      <td>org.sonarqube.ws.client.qualitygates.Qualityga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>0</td>\n",
       "      <td>org.sonarqube.ws.client.qualitygates.ProjectSt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>0</td>\n",
       "      <td>org.sonarqube.ws.client.qualitygates.ProjectSt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1173 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0     1  redis.clients.jedis.JedisPoolConfig.setNumTest...\n",
       "1     1  org.elasticsearch.common.settings.Settings.set...\n",
       "2     1  org.apache.catalina.deploy.FilterMap.addURLPat...\n",
       "3     1  org.apache.sshd.server.sftp.SftpSubsystem.proc...\n",
       "4     1  org.mockito.Matchers.notNull()__XX__org.mockit...\n",
       "...  ..                                                ...\n",
       "1168  0  org.sonarqube.ws.client.qualitygates.Qualityga...\n",
       "1169  0  org.sonarqube.ws.client.qualitygates.Qualityga...\n",
       "1170  0  org.sonarqube.ws.client.qualitygates.Qualityga...\n",
       "1171  0  org.sonarqube.ws.client.qualitygates.ProjectSt...\n",
       "1172  0  org.sonarqube.ws.client.qualitygates.ProjectSt...\n",
       "\n",
       "[1173 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('dataset-cnn/cleaned/training.csv', header=None, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8e0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file, maxl=200, transform=None, target_transform=None):\n",
    "        self.vocabulary = list(\"\"\"abcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\"\")\n",
    "        self.identity_mat = np.identity(len(self.vocabulary))\n",
    "        self.arr = pd.read_csv(file, sep=';', header=None)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.max_length = maxl\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.arr)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.arr.iloc[idx, 0]\n",
    "        line = self.arr.iloc[idx, 1]\n",
    "        \n",
    "        line = np.array([self.identity_mat[self.vocabulary.index(i)] for i in list(line) if i in self.vocabulary],\n",
    "                        dtype=np.float32)\n",
    "        \n",
    "        if len(line) > self.max_length:\n",
    "            line = line[:self.max_length]\n",
    "        elif 0 < len(line) < self.max_length:\n",
    "            line = np.concatenate(\n",
    "                (line, np.zeros((self.max_length - len(line), len(self.vocabulary)), dtype=np.float32)))\n",
    "        elif len(line) == 0:\n",
    "            line = np.zeros((self.max_length, len(self.vocabulary)), dtype=np.float32)\n",
    "            \n",
    "    \n",
    "        return label, line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ac82cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = MyDataset('dataset-cnn/cleaned/training.csv')\n",
    "validation_dataset = MyDataset('dataset-cnn/cleaned/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16120227",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3033a2ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(training_dataloader)\n",
    "labels, lines = dataiter.next()\n",
    "\n",
    "print(type(labels))\n",
    "print(type(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aafd3709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe7e0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(lines[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16417832",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterLevelCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(200, 200, 15)\n",
    "#         self.pool = nn.MaxPool1d(2, 2)\n",
    "        self.conv2 = nn.Conv1d(200, 200, 15)\n",
    "        self.fc1 = nn.Linear(2400, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 840)\n",
    "        self.fc3 = nn.Linear(840, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(x)\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e80bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharacterLevelCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd02812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ad73045",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.014\n",
      "[2,     1] loss: 0.014\n",
      "[3,     1] loss: 0.014\n",
      "[4,     1] loss: 0.014\n",
      "[5,     1] loss: 0.014\n",
      "[6,     1] loss: 0.014\n",
      "[7,     1] loss: 0.014\n",
      "[8,     1] loss: 0.014\n",
      "[9,     1] loss: 0.014\n",
      "[10,     1] loss: 0.014\n",
      "[11,     1] loss: 0.014\n",
      "[12,     1] loss: 0.014\n",
      "[13,     1] loss: 0.014\n",
      "[14,     1] loss: 0.014\n",
      "[15,     1] loss: 0.014\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(training_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        labels, lines = data\n",
    "#         print(data)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(lines)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 0:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = 500\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output = evaluate(line_tensor)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = all_categories.index(category)\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd0038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
